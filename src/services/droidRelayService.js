const https = require('https')
const axios = require('axios')
const ProxyHelper = require('../utils/proxyHelper')
const droidScheduler = require('./droidScheduler')
const droidAccountService = require('./droidAccountService')
const apiKeyService = require('./apiKeyService')
const redis = require('../models/redis')
const { updateRateLimitCounters } = require('../utils/rateLimitHelper')
const logger = require('../utils/logger')

const SYSTEM_PROMPT = 'You are Droid, an AI software engineering agent built by Factory.'

const MODEL_REASONING_CONFIG = {
  'claude-opus-4-1-20250805': 'off',
  'claude-sonnet-4-20250514': 'medium',
  'claude-sonnet-4-5-20250929': 'high',
  'gpt-5-2025-08-07': 'high',
  'gpt-5-codex': 'off'
}

const VALID_REASONING_LEVELS = new Set(['low', 'medium', 'high'])

/**
 * Droid API ËΩ¨ÂèëÊúçÂä°
 */

class DroidRelayService {
  constructor() {
    this.factoryApiBaseUrl = 'https://app.factory.ai/api/llm'

    this.endpoints = {
      anthropic: '/a/v1/messages',
      openai: '/o/v1/responses'
    }

    this.userAgent = 'factory-cli/0.19.4'
    this.systemPrompt = SYSTEM_PROMPT
    this.modelReasoningMap = new Map()
    this.API_KEY_STICKY_PREFIX = 'droid_api_key'

    Object.entries(MODEL_REASONING_CONFIG).forEach(([modelId, level]) => {
      if (!modelId) {
        return
      }
      const normalized = typeof level === 'string' ? level.toLowerCase() : ''
      this.modelReasoningMap.set(modelId, normalized)
    })
  }

  _normalizeEndpointType(endpointType) {
    if (!endpointType) {
      return 'anthropic'
    }

    const normalized = String(endpointType).toLowerCase()
    if (normalized === 'openai' || normalized === 'common') {
      return 'openai'
    }

    if (normalized === 'anthropic') {
      return 'anthropic'
    }

    return 'anthropic'
  }

  _normalizeRequestBody(requestBody, endpointType) {
    if (!requestBody || typeof requestBody !== 'object') {
      return requestBody
    }

    const normalizedBody = { ...requestBody }

    if (endpointType === 'anthropic' && typeof normalizedBody.model === 'string') {
      const originalModel = normalizedBody.model
      const trimmedModel = originalModel.trim()
      const lowerModel = trimmedModel.toLowerCase()

      if (lowerModel.includes('haiku')) {
        const mappedModel = 'claude-sonnet-4-20250514'
        if (originalModel !== mappedModel) {
          logger.info(`üîÑ Â∞ÜËØ∑Ê±ÇÊ®°Âûã‰ªé ${originalModel} Êò†Â∞Ñ‰∏∫ ${mappedModel}`)
        }
        normalizedBody.model = mappedModel
        normalizedBody.__forceDisableThinking = true
      }
    }

    if (endpointType === 'openai' && typeof normalizedBody.model === 'string') {
      const originalModel = normalizedBody.model
      const trimmedModel = originalModel.trim()
      const lowerModel = trimmedModel.toLowerCase()

      if (lowerModel === 'gpt-5') {
        const mappedModel = 'gpt-5-2025-08-07'
        if (originalModel !== mappedModel) {
          logger.info(`üîÑ Â∞ÜËØ∑Ê±ÇÊ®°Âûã‰ªé ${originalModel} Êò†Â∞Ñ‰∏∫ ${mappedModel}`)
        }
        normalizedBody.model = mappedModel
      }
    }

    return normalizedBody
  }

  async _applyRateLimitTracking(rateLimitInfo, usageSummary, model, context = '') {
    if (!rateLimitInfo) {
      return
    }

    try {
      const { totalTokens, totalCost } = await updateRateLimitCounters(
        rateLimitInfo,
        usageSummary,
        model
      )

      if (totalTokens > 0) {
        logger.api(`üìä Updated rate limit token count${context}: +${totalTokens}`)
      }
      if (typeof totalCost === 'number' && totalCost > 0) {
        logger.api(`üí∞ Updated rate limit cost count${context}: +$${totalCost.toFixed(6)}`)
      }
    } catch (error) {
      logger.error(`‚ùå Failed to update rate limit counters${context}:`, error)
    }
  }

  _composeApiKeyStickyKey(accountId, endpointType, sessionHash) {
    if (!accountId || !sessionHash) {
      return null
    }

    const normalizedEndpoint = this._normalizeEndpointType(endpointType)
    return `${this.API_KEY_STICKY_PREFIX}:${accountId}:${normalizedEndpoint}:${sessionHash}`
  }

  async _selectApiKey(account, endpointType, sessionHash) {
    const entries = await droidAccountService.getDecryptedApiKeyEntries(account.id)
    if (!entries || entries.length === 0) {
      throw new Error(`Droid account ${account.id} Êú™ÈÖçÁΩÆ‰ªª‰Ωï API Key`)
    }

    const stickyKey = this._composeApiKeyStickyKey(account.id, endpointType, sessionHash)

    if (stickyKey) {
      const mappedKeyId = await redis.getSessionAccountMapping(stickyKey)
      if (mappedKeyId) {
        const mappedEntry = entries.find((entry) => entry.id === mappedKeyId)
        if (mappedEntry) {
          await redis.extendSessionAccountMappingTTL(stickyKey)
          await droidAccountService.touchApiKeyUsage(account.id, mappedEntry.id)
          logger.info(`üîê ‰ΩøÁî®Â∑≤ÁªëÂÆöÁöÑ Droid API Key ${mappedEntry.id}ÔºàAccount: ${account.id}Ôºâ`)
          return mappedEntry
        }

        await redis.deleteSessionAccountMapping(stickyKey)
      }
    }

    const selectedEntry = entries[Math.floor(Math.random() * entries.length)]
    if (!selectedEntry) {
      throw new Error(`Droid account ${account.id} Ê≤°ÊúâÂèØÁî®ÁöÑ API Key`)
    }

    if (stickyKey) {
      await redis.setSessionAccountMapping(stickyKey, selectedEntry.id)
    }

    await droidAccountService.touchApiKeyUsage(account.id, selectedEntry.id)

    logger.info(
      `üîê ÈöèÊú∫ÈÄâÂèñ Droid API Key ${selectedEntry.id}ÔºàAccount: ${account.id}, Keys: ${entries.length}Ôºâ`
    )

    return selectedEntry
  }

  async relayRequest(
    requestBody,
    apiKeyData,
    clientRequest,
    clientResponse,
    clientHeaders,
    options = {}
  ) {
    const {
      endpointType = 'anthropic',
      sessionHash = null,
      customPath = null,
      skipUsageRecord = false,
      disableStreaming = false
    } = options
    const keyInfo = apiKeyData || {}
    const clientApiKeyId = keyInfo.id || null
    const normalizedEndpoint = this._normalizeEndpointType(endpointType)
    const normalizedRequestBody = this._normalizeRequestBody(requestBody, normalizedEndpoint)
    let account = null
    let selectedApiKey = null
    let accessToken = null

    try {
      logger.info(
        `üì§ Processing Droid API request for key: ${
          keyInfo.name || keyInfo.id || 'unknown'
        }, endpoint: ${normalizedEndpoint}${sessionHash ? `, session: ${sessionHash}` : ''}`
      )

      // ÈÄâÊã©‰∏Ä‰∏™ÂèØÁî®ÁöÑ Droid Ë¥¶Êà∑ÔºàÊîØÊåÅÁ≤òÊÄß‰ºöËØùÂíåÂàÜÁªÑË∞ÉÂ∫¶Ôºâ
      account = await droidScheduler.selectAccount(keyInfo, normalizedEndpoint, sessionHash)

      if (!account) {
        throw new Error(`No available Droid account for endpoint type: ${normalizedEndpoint}`)
      }

      // Ëé∑ÂèñËÆ§ËØÅÂá≠ÊçÆÔºöÊîØÊåÅ Access Token Âíå API Key ‰∏§ÁßçÊ®°Âºè
      if (
        typeof account.authenticationMethod === 'string' &&
        account.authenticationMethod.toLowerCase().trim() === 'api_key'
      ) {
        selectedApiKey = await this._selectApiKey(account, normalizedEndpoint, sessionHash)
        accessToken = selectedApiKey.key
      } else {
        accessToken = await droidAccountService.getValidAccessToken(account.id)
      }

      // Ëé∑Âèñ Factory.ai API URL
      let endpointPath = this.endpoints[normalizedEndpoint]

      if (typeof customPath === 'string' && customPath.trim()) {
        endpointPath = customPath.startsWith('/') ? customPath : `/${customPath}`
      }

      const apiUrl = `${this.factoryApiBaseUrl}${endpointPath}`

      logger.info(`üåê Forwarding to Factory.ai: ${apiUrl}`)

      // Ëé∑Âèñ‰ª£ÁêÜÈÖçÁΩÆ
      const proxyConfig = account.proxy ? JSON.parse(account.proxy) : null
      const proxyAgent = proxyConfig ? ProxyHelper.createProxyAgent(proxyConfig) : null

      if (proxyAgent) {
        logger.info(`üåê Using proxy: ${ProxyHelper.getProxyDescription(proxyConfig)}`)
      }

      // ÊûÑÂª∫ËØ∑Ê±ÇÂ§¥
      const headers = this._buildHeaders(
        accessToken,
        normalizedRequestBody,
        normalizedEndpoint,
        clientHeaders
      )

      if (selectedApiKey) {
        logger.info(
          `üîë Forwarding request with Droid API Key ${selectedApiKey.id} (Account: ${account.id})`
        )
      }

      // Â§ÑÁêÜËØ∑Ê±Ç‰ΩìÔºàÊ≥®ÂÖ• system prompt Á≠âÔºâ
      const streamRequested = !disableStreaming && this._isStreamRequested(normalizedRequestBody)

      const processedBody = this._processRequestBody(normalizedRequestBody, normalizedEndpoint, {
        disableStreaming,
        streamRequested
      })

      // ÂèëÈÄÅËØ∑Ê±Ç
      const isStreaming = streamRequested

      // Ê†πÊçÆÊòØÂê¶ÊµÅÂºèÈÄâÊã©‰∏çÂêåÁöÑÂ§ÑÁêÜÊñπÂºè
      if (isStreaming) {
        // ÊµÅÂºèÂìçÂ∫îÔºö‰ΩøÁî®ÂéüÁîü https Ê®°Âùó‰ª•Êõ¥Â•ΩÂú∞ÊéßÂà∂ÊµÅ
        return await this._handleStreamRequest(
          apiUrl,
          headers,
          processedBody,
          proxyAgent,
          clientRequest,
          clientResponse,
          account,
          keyInfo,
          normalizedRequestBody,
          normalizedEndpoint,
          skipUsageRecord,
          selectedApiKey,
          sessionHash,
          clientApiKeyId
        )
      } else {
        // ÈùûÊµÅÂºèÂìçÂ∫îÔºö‰ΩøÁî® axios
        const requestOptions = {
          method: 'POST',
          url: apiUrl,
          headers,
          data: processedBody,
          timeout: 600 * 1000, // 10ÂàÜÈíüË∂ÖÊó∂
          responseType: 'json',
          ...(proxyAgent && {
            httpAgent: proxyAgent,
            httpsAgent: proxyAgent
          })
        }

        const response = await axios(requestOptions)

        logger.info(`‚úÖ Factory.ai response status: ${response.status}`)

        // Â§ÑÁêÜÈùûÊµÅÂºèÂìçÂ∫î
        return this._handleNonStreamResponse(
          response,
          account,
          keyInfo,
          normalizedRequestBody,
          clientRequest,
          normalizedEndpoint,
          skipUsageRecord
        )
      }
    } catch (error) {
      logger.error(`‚ùå Droid relay error: ${error.message}`, error)

      const status = error?.response?.status
      if (status >= 400 && status < 500) {
        try {
          await this._handleUpstreamClientError(status, {
            account,
            selectedAccountApiKey: selectedApiKey,
            endpointType: normalizedEndpoint,
            sessionHash,
            clientApiKeyId
          })
        } catch (handlingError) {
          logger.error('‚ùå Â§ÑÁêÜ Droid 4xx ÂºÇÂ∏∏Â§±Ë¥•:', handlingError)
        }
      }

      if (error.response) {
        // HTTP ÈîôËØØÂìçÂ∫î
        return {
          statusCode: error.response.status,
          headers: { 'Content-Type': 'application/json' },
          body: JSON.stringify(
            error.response.data || {
              error: 'upstream_error',
              message: error.message
            }
          )
        }
      }

      // ÁΩëÁªúÈîôËØØÊàñÂÖ∂‰ªñÈîôËØØÔºàÁªü‰∏ÄËøîÂõû 4xxÔºâ
      const mappedStatus = this._mapNetworkErrorStatus(error)
      return {
        statusCode: mappedStatus,
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify(this._buildNetworkErrorBody(error))
      }
    }
  }

  /**
   * Â§ÑÁêÜÊµÅÂºèËØ∑Ê±Ç
   */
  async _handleStreamRequest(
    apiUrl,
    headers,
    processedBody,
    proxyAgent,
    clientRequest,
    clientResponse,
    account,
    apiKeyData,
    requestBody,
    endpointType,
    skipUsageRecord = false,
    selectedAccountApiKey = null,
    sessionHash = null,
    clientApiKeyId = null
  ) {
    return new Promise((resolve, reject) => {
      const url = new URL(apiUrl)
      const bodyString = JSON.stringify(processedBody)
      const contentLength = Buffer.byteLength(bodyString)
      const requestHeaders = {
        ...headers,
        'content-length': contentLength.toString()
      }

      let responseStarted = false
      let responseCompleted = false
      let settled = false
      let upstreamResponse = null
      let completionWindow = ''
      let hasForwardedData = false

      const resolveOnce = (value) => {
        if (settled) {
          return
        }
        settled = true
        resolve(value)
      }

      const rejectOnce = (error) => {
        if (settled) {
          return
        }
        settled = true
        reject(error)
      }

      const handleStreamError = (error) => {
        if (responseStarted) {
          const isConnectionReset =
            error && (error.code === 'ECONNRESET' || error.message === 'aborted')
          const upstreamComplete =
            responseCompleted || upstreamResponse?.complete || clientResponse.writableEnded

          if (isConnectionReset && (upstreamComplete || hasForwardedData)) {
            logger.debug('üîÅ Droid streamËøûÊé•Âú®ÂìçÂ∫îÈò∂ÊÆµË¢´ÈáçÁΩÆÔºåËßÜ‰∏∫Ê≠£Â∏∏ÁªìÊùü:', {
              message: error?.message,
              code: error?.code
            })
            if (!clientResponse.destroyed && !clientResponse.writableEnded) {
              clientResponse.end()
            }
            resolveOnce({ statusCode: 200, streaming: true })
            return
          }

          logger.error('‚ùå Droid stream error:', error)
          const mappedStatus = this._mapNetworkErrorStatus(error)
          const errorBody = this._buildNetworkErrorBody(error)

          if (!clientResponse.destroyed) {
            if (!clientResponse.writableEnded) {
              const canUseJson =
                !hasForwardedData &&
                typeof clientResponse.status === 'function' &&
                typeof clientResponse.json === 'function'

              if (canUseJson) {
                clientResponse.status(mappedStatus).json(errorBody)
              } else {
                const errorPayload = JSON.stringify(errorBody)

                if (!hasForwardedData) {
                  if (typeof clientResponse.setHeader === 'function') {
                    clientResponse.setHeader('Content-Type', 'application/json')
                  }
                  clientResponse.write(errorPayload)
                  clientResponse.end()
                } else {
                  clientResponse.write(`event: error\ndata: ${errorPayload}\n\n`)
                  clientResponse.end()
                }
              }
            }
          }

          resolveOnce({ statusCode: mappedStatus, streaming: true, error })
        } else {
          rejectOnce(error)
        }
      }

      const options = {
        hostname: url.hostname,
        port: url.port || 443,
        path: url.pathname,
        method: 'POST',
        headers: requestHeaders,
        agent: proxyAgent,
        timeout: 600 * 1000
      }

      const req = https.request(options, (res) => {
        upstreamResponse = res
        logger.info(`‚úÖ Factory.ai stream response status: ${res.statusCode}`)

        // ÈîôËØØÂìçÂ∫î
        if (res.statusCode !== 200) {
          const chunks = []

          res.on('data', (chunk) => {
            chunks.push(chunk)
            logger.info(`üì¶ got ${chunk.length} bytes of data`)
          })

          res.on('end', () => {
            logger.info('‚úÖ res.end() reached')
            const body = Buffer.concat(chunks).toString()
            logger.error(`‚ùå Factory.ai error response body: ${body || '(empty)'}`)
            if (res.statusCode >= 400 && res.statusCode < 500) {
              this._handleUpstreamClientError(res.statusCode, {
                account,
                selectedAccountApiKey,
                endpointType,
                sessionHash,
                clientApiKeyId
              }).catch((handlingError) => {
                logger.error('‚ùå Â§ÑÁêÜ Droid ÊµÅÂºè4xx ÂºÇÂ∏∏Â§±Ë¥•:', handlingError)
              })
            }
            if (!clientResponse.headersSent) {
              clientResponse.status(res.statusCode).json({
                error: 'upstream_error',
                details: body
              })
            }
            resolveOnce({ statusCode: res.statusCode, streaming: true })
          })

          res.on('close', () => {
            logger.warn('‚ö†Ô∏è response closed before end event')
          })

          res.on('error', handleStreamError)

          return
        }

        responseStarted = true

        // ËÆæÁΩÆÊµÅÂºèÂìçÂ∫îÂ§¥
        clientResponse.setHeader('Content-Type', 'text/event-stream')
        clientResponse.setHeader('Cache-Control', 'no-cache')
        clientResponse.setHeader('Connection', 'keep-alive')

        // Usage Êï∞ÊçÆÊî∂ÈõÜ
        let buffer = ''
        const currentUsageData = {}
        const model = requestBody.model || 'unknown'

        // Â§ÑÁêÜ SSE ÊµÅ
        res.on('data', (chunk) => {
          const chunkStr = chunk.toString()
          completionWindow = (completionWindow + chunkStr).slice(-1024)
          hasForwardedData = true

          // ËΩ¨ÂèëÊï∞ÊçÆÂà∞ÂÆ¢Êà∑Á´Ø
          clientResponse.write(chunk)
          hasForwardedData = true

          // Ëß£Êûê usage Êï∞ÊçÆÔºàÊ†πÊçÆÁ´ØÁÇπÁ±ªÂûãÔºâ
          if (endpointType === 'anthropic') {
            // Anthropic Messages API Ê†ºÂºè
            this._parseAnthropicUsageFromSSE(chunkStr, buffer, currentUsageData)
          } else if (endpointType === 'openai') {
            // OpenAI Chat Completions Ê†ºÂºè
            this._parseOpenAIUsageFromSSE(chunkStr, buffer, currentUsageData)
          }

          if (!responseCompleted && this._detectStreamCompletion(completionWindow, endpointType)) {
            responseCompleted = true
          }

          buffer += chunkStr
        })

        res.on('end', async () => {
          responseCompleted = true
          clientResponse.end()

          // ËÆ∞ÂΩï usage Êï∞ÊçÆ
          if (!skipUsageRecord) {
            const normalizedUsage = await this._recordUsageFromStreamData(
              currentUsageData,
              apiKeyData,
              account,
              model
            )

            const usageSummary = {
              inputTokens: normalizedUsage.input_tokens || 0,
              outputTokens: normalizedUsage.output_tokens || 0,
              cacheCreateTokens: normalizedUsage.cache_creation_input_tokens || 0,
              cacheReadTokens: normalizedUsage.cache_read_input_tokens || 0
            }

            await this._applyRateLimitTracking(
              clientRequest?.rateLimitInfo,
              usageSummary,
              model,
              ' [stream]'
            )

            logger.success(`‚úÖ Droid stream completed - Account: ${account.name}`)
          } else {
            logger.success(
              `‚úÖ Droid stream completed - Account: ${account.name}, usage recording skipped`
            )
          }
          resolveOnce({ statusCode: 200, streaming: true })
        })

        res.on('error', handleStreamError)

        res.on('close', () => {
          if (settled) {
            return
          }

          if (responseCompleted) {
            if (!clientResponse.destroyed && !clientResponse.writableEnded) {
              clientResponse.end()
            }
            resolveOnce({ statusCode: 200, streaming: true })
          } else {
            handleStreamError(new Error('Upstream stream closed unexpectedly'))
          }
        })
      })

      // ÂÆ¢Êà∑Á´ØÊñ≠ÂºÄËøûÊé•Êó∂Ê∏ÖÁêÜ
      clientResponse.on('close', () => {
        if (req && !req.destroyed) {
          req.destroy()
        }
      })

      req.on('error', handleStreamError)

      req.on('timeout', () => {
        req.destroy()
        logger.error('‚ùå Droid request timeout')
        handleStreamError(new Error('Request timeout'))
      })

      // ÂÜôÂÖ•ËØ∑Ê±Ç‰Ωì
      req.end(bodyString)
    })
  }

  /**
   * ‰ªé SSE ÊµÅ‰∏≠Ëß£Êûê Anthropic usage Êï∞ÊçÆ
   */
  _parseAnthropicUsageFromSSE(chunkStr, buffer, currentUsageData) {
    try {
      // ÂàÜÂâ≤ÊàêË°å
      const lines = (buffer + chunkStr).split('\n')

      for (const line of lines) {
        if (line.startsWith('data: ') && line.length > 6) {
          try {
            const jsonStr = line.slice(6)
            const data = JSON.parse(jsonStr)

            // message_start ÂåÖÂê´ input tokens Âíå cache tokens
            if (data.type === 'message_start' && data.message && data.message.usage) {
              currentUsageData.input_tokens = data.message.usage.input_tokens || 0
              currentUsageData.cache_creation_input_tokens =
                data.message.usage.cache_creation_input_tokens || 0
              currentUsageData.cache_read_input_tokens =
                data.message.usage.cache_read_input_tokens || 0

              // ËØ¶ÁªÜÁöÑÁºìÂ≠òÁ±ªÂûã
              if (data.message.usage.cache_creation) {
                currentUsageData.cache_creation = {
                  ephemeral_5m_input_tokens:
                    data.message.usage.cache_creation.ephemeral_5m_input_tokens || 0,
                  ephemeral_1h_input_tokens:
                    data.message.usage.cache_creation.ephemeral_1h_input_tokens || 0
                }
              }

              logger.debug('üìä Droid Anthropic input usage:', currentUsageData)
            }

            // message_delta ÂåÖÂê´ output tokens
            if (data.type === 'message_delta' && data.usage) {
              currentUsageData.output_tokens = data.usage.output_tokens || 0
              logger.debug('üìä Droid Anthropic output usage:', currentUsageData.output_tokens)
            }
          } catch (parseError) {
            // ÂøΩÁï•Ëß£ÊûêÈîôËØØ
          }
        }
      }
    } catch (error) {
      logger.debug('Error parsing Anthropic usage:', error)
    }
  }

  /**
   * ‰ªé SSE ÊµÅ‰∏≠Ëß£Êûê OpenAI usage Êï∞ÊçÆ
   */
  _parseOpenAIUsageFromSSE(chunkStr, buffer, currentUsageData) {
    try {
      // OpenAI Chat Completions ÊµÅÂºèÊ†ºÂºè
      const lines = (buffer + chunkStr).split('\n')

      for (const line of lines) {
        if (line.startsWith('data: ') && line.length > 6) {
          try {
            const jsonStr = line.slice(6)
            if (jsonStr === '[DONE]') {
              continue
            }

            const data = JSON.parse(jsonStr)

            // ÂÖºÂÆπ‰º†Áªü Chat Completions usage Â≠óÊÆµ
            if (data.usage) {
              currentUsageData.input_tokens = data.usage.prompt_tokens || 0
              currentUsageData.output_tokens = data.usage.completion_tokens || 0
              currentUsageData.total_tokens = data.usage.total_tokens || 0

              logger.debug('üìä Droid OpenAI usage:', currentUsageData)
            }

            // Êñ∞ Response API Âú® response.usage ‰∏≠ËøîÂõûÁªüËÆ°
            if (data.response && data.response.usage) {
              const { usage } = data.response
              currentUsageData.input_tokens =
                usage.input_tokens || usage.prompt_tokens || usage.total_tokens || 0
              currentUsageData.output_tokens = usage.output_tokens || usage.completion_tokens || 0
              currentUsageData.total_tokens = usage.total_tokens || 0

              logger.debug('üìä Droid OpenAI response usage:', currentUsageData)
            }
          } catch (parseError) {
            // ÂøΩÁï•Ëß£ÊûêÈîôËØØ
          }
        }
      }
    } catch (error) {
      logger.debug('Error parsing OpenAI usage:', error)
    }
  }

  /**
   * Ê£ÄÊµãÊµÅÂºèÂìçÂ∫îÊòØÂê¶Â∑≤ÁªèÂåÖÂê´ÁªàÊ≠¢Ê†áËÆ∞
   */
  _detectStreamCompletion(windowStr, endpointType) {
    if (!windowStr) {
      return false
    }

    const lower = windowStr.toLowerCase()
    const compact = lower.replace(/\s+/g, '')

    if (endpointType === 'anthropic') {
      if (lower.includes('event: message_stop')) {
        return true
      }
      if (compact.includes('"type":"message_stop"')) {
        return true
      }
      return false
    }

    if (endpointType === 'openai') {
      if (lower.includes('data: [done]')) {
        return true
      }

      if (compact.includes('"finish_reason"')) {
        return true
      }

      if (lower.includes('event: response.done') || lower.includes('event: response.completed')) {
        return true
      }

      if (
        compact.includes('"type":"response.done"') ||
        compact.includes('"type":"response.completed"')
      ) {
        return true
      }
    }

    return false
  }

  /**
   * ËÆ∞ÂΩï‰ªéÊµÅ‰∏≠Ëß£ÊûêÁöÑ usage Êï∞ÊçÆ
   */
  async _recordUsageFromStreamData(usageData, apiKeyData, account, model) {
    const normalizedUsage = this._normalizeUsageSnapshot(usageData)
    await this._recordUsage(apiKeyData, account, model, normalizedUsage)
    return normalizedUsage
  }

  /**
   * Ê†áÂáÜÂåñ usage Êï∞ÊçÆÔºåÁ°Æ‰øùÂ≠óÊÆµÂÆåÊï¥‰∏î‰∏∫Êï∞Â≠ó
   */
  _normalizeUsageSnapshot(usageData = {}) {
    const toNumber = (value) => {
      if (value === undefined || value === null || value === '') {
        return 0
      }
      const num = Number(value)
      if (!Number.isFinite(num)) {
        return 0
      }
      return Math.max(0, num)
    }

    const inputTokens = toNumber(
      usageData.input_tokens ??
        usageData.prompt_tokens ??
        usageData.inputTokens ??
        usageData.total_input_tokens
    )
    const outputTokens = toNumber(
      usageData.output_tokens ?? usageData.completion_tokens ?? usageData.outputTokens
    )
    const cacheReadTokens = toNumber(
      usageData.cache_read_input_tokens ??
        usageData.cacheReadTokens ??
        usageData.input_tokens_details?.cached_tokens
    )

    const rawCacheCreateTokens =
      usageData.cache_creation_input_tokens ??
      usageData.cacheCreateTokens ??
      usageData.cache_tokens ??
      0
    let cacheCreateTokens = toNumber(rawCacheCreateTokens)

    const ephemeral5m = toNumber(
      usageData.cache_creation?.ephemeral_5m_input_tokens ?? usageData.ephemeral_5m_input_tokens
    )
    const ephemeral1h = toNumber(
      usageData.cache_creation?.ephemeral_1h_input_tokens ?? usageData.ephemeral_1h_input_tokens
    )

    if (cacheCreateTokens === 0 && (ephemeral5m > 0 || ephemeral1h > 0)) {
      cacheCreateTokens = ephemeral5m + ephemeral1h
    }

    const normalized = {
      input_tokens: inputTokens,
      output_tokens: outputTokens,
      cache_creation_input_tokens: cacheCreateTokens,
      cache_read_input_tokens: cacheReadTokens
    }

    if (ephemeral5m > 0 || ephemeral1h > 0) {
      normalized.cache_creation = {
        ephemeral_5m_input_tokens: ephemeral5m,
        ephemeral_1h_input_tokens: ephemeral1h
      }
    }

    return normalized
  }

  /**
   * ËÆ°ÁÆó usage ÂØπË±°ÁöÑÊÄª token Êï∞
   */
  _getTotalTokens(usageObject = {}) {
    const toNumber = (value) => {
      if (value === undefined || value === null || value === '') {
        return 0
      }
      const num = Number(value)
      if (!Number.isFinite(num)) {
        return 0
      }
      return Math.max(0, num)
    }

    return (
      toNumber(usageObject.input_tokens) +
      toNumber(usageObject.output_tokens) +
      toNumber(usageObject.cache_creation_input_tokens) +
      toNumber(usageObject.cache_read_input_tokens)
    )
  }

  /**
   * ÊèêÂèñË¥¶Êà∑ ID
   */
  _extractAccountId(account) {
    if (!account || typeof account !== 'object') {
      return null
    }
    return account.id || account.accountId || account.account_id || null
  }

  /**
   * ÊûÑÂª∫ËØ∑Ê±ÇÂ§¥
   */
  _buildHeaders(accessToken, requestBody, endpointType, clientHeaders = {}) {
    const headers = {
      'content-type': 'application/json',
      authorization: `Bearer ${accessToken}`,
      'user-agent': this.userAgent,
      'x-factory-client': 'cli',
      connection: 'keep-alive'
    }

    // Anthropic ÁâπÂÆöÂ§¥
    if (endpointType === 'anthropic') {
      headers['accept'] = 'application/json'
      headers['anthropic-version'] = '2023-06-01'
      headers['x-api-key'] = 'placeholder'
      headers['x-api-provider'] = 'anthropic'

      // Â§ÑÁêÜ anthropic-beta Â§¥
      const reasoningLevel = this._getReasoningLevel(requestBody)
      if (reasoningLevel) {
        headers['anthropic-beta'] = 'interleaved-thinking-2025-05-14'
      }
    }

    // OpenAI ÁâπÂÆöÂ§¥
    if (endpointType === 'openai') {
      headers['x-api-provider'] = 'azure_openai'
    }

    // ÁîüÊàê‰ºöËØù IDÔºàÂ¶ÇÊûúÂÆ¢Êà∑Á´ØÊ≤°ÊúâÊèê‰æõÔºâ
    headers['x-session-id'] = clientHeaders['x-session-id'] || this._generateUUID()

    return headers
  }

  /**
   * Âà§Êñ≠ËØ∑Ê±ÇÊòØÂê¶Ë¶ÅÊ±ÇÊµÅÂºèÂìçÂ∫î
   */
  _isStreamRequested(requestBody) {
    if (!requestBody || typeof requestBody !== 'object') {
      return false
    }

    const value = requestBody.stream

    if (value === true) {
      return true
    }

    if (typeof value === 'string') {
      return value.toLowerCase() === 'true'
    }

    return false
  }

  /**
   * Â§ÑÁêÜËØ∑Ê±Ç‰ΩìÔºàÊ≥®ÂÖ• system prompt Á≠âÔºâ
   */
  _processRequestBody(requestBody, endpointType, options = {}) {
    const { disableStreaming = false, streamRequested = false } = options
    const processedBody = { ...requestBody }

    const hasStreamField =
      requestBody && Object.prototype.hasOwnProperty.call(requestBody, 'stream')

    const shouldDisableThinking =
      endpointType === 'anthropic' && processedBody.__forceDisableThinking === true

    if ('__forceDisableThinking' in processedBody) {
      delete processedBody.__forceDisableThinking
    }

    if (requestBody && '__forceDisableThinking' in requestBody) {
      delete requestBody.__forceDisableThinking
    }

    if (processedBody && Object.prototype.hasOwnProperty.call(processedBody, 'metadata')) {
      delete processedBody.metadata
    }

    if (disableStreaming || !streamRequested) {
      if (hasStreamField) {
        processedBody.stream = false
      } else if ('stream' in processedBody) {
        delete processedBody.stream
      }
    } else {
      processedBody.stream = true
    }

    const hasTemperatureField = Object.prototype.hasOwnProperty.call(processedBody, 'temperature')

    // Anthropic Á´ØÁÇπÔºöÂ§ÑÁêÜ thinking Â≠óÊÆµ
    if (endpointType === 'anthropic') {
      if (this.systemPrompt) {
        const promptBlock = { type: 'text', text: this.systemPrompt }
        if (Array.isArray(processedBody.system)) {
          const hasPrompt = processedBody.system.some(
            (item) => item && item.type === 'text' && item.text === this.systemPrompt
          )
          if (!hasPrompt) {
            processedBody.system = [promptBlock, ...processedBody.system]
          }
        } else {
          processedBody.system = [promptBlock]
        }
      }

      const reasoningLevel = shouldDisableThinking ? null : this._getReasoningLevel(requestBody)
      if (reasoningLevel) {
        const budgetTokens = {
          low: 4096,
          medium: 12288,
          high: 24576
        }
        processedBody.thinking = {
          type: 'enabled',
          budget_tokens: budgetTokens[reasoningLevel]
        }
      } else {
        delete processedBody.thinking
      }

      if (shouldDisableThinking) {
        if ('thinking' in processedBody) {
          delete processedBody.thinking
        }
      } else if (
        processedBody.thinking &&
        processedBody.thinking.type === 'enabled' &&
        hasTemperatureField
      ) {
        const parsedTemperature =
          typeof processedBody.temperature === 'string'
            ? parseFloat(processedBody.temperature)
            : processedBody.temperature

        if (typeof parsedTemperature === 'number' && !Number.isNaN(parsedTemperature)) {
          if (parsedTemperature <= 0) {
            // ÂΩìÂºÄÂêØ thinking Êó∂Ôºåtemperature ‰∏çÂÖÅËÆ∏‰∏∫ 0
            processedBody.temperature = 1
          }
        } else {
          delete processedBody.temperature
        }
      }
    }

    // OpenAI Á´ØÁÇπÔºöÂ§ÑÁêÜ reasoning Â≠óÊÆµ
    if (endpointType === 'openai') {
      if (this.systemPrompt) {
        if (processedBody.instructions) {
          if (!processedBody.instructions.startsWith(this.systemPrompt)) {
            processedBody.instructions = `${this.systemPrompt}${processedBody.instructions}`
          }
        } else {
          processedBody.instructions = this.systemPrompt
        }
      }

      const reasoningLevel = this._getReasoningLevel(requestBody)
      if (reasoningLevel) {
        processedBody.reasoning = {
          effort: reasoningLevel,
          summary: 'auto'
        }
      } else {
        delete processedBody.reasoning
      }
    }

    // Â§ÑÁêÜ temperature Âíå top_p ÂèÇÊï∞
    const hasValidTemperature =
      processedBody.temperature !== undefined && processedBody.temperature !== null
    const hasValidTopP = processedBody.top_p !== undefined && processedBody.top_p !== null

    if (hasValidTemperature && hasValidTopP) {
      // ‰ªÖÂÖÅËÆ∏ temperature Êàñ top_p ÂÖ∂‰∏ÄÔºåÂêåÊó∂‰ºòÂÖà‰øùÁïô temperature
      delete processedBody.top_p
    }

    return processedBody
  }

  /**
   * Ëé∑ÂèñÊé®ÁêÜÁ∫ßÂà´ÔºàÂ¶ÇÊûúÂú® requestBody ‰∏≠ÈÖçÁΩÆÔºâ
   */
  _getReasoningLevel(requestBody) {
    if (!requestBody || !requestBody.model) {
      return null
    }

    const configured = this.modelReasoningMap.get(requestBody.model)
    if (!configured) {
      return null
    }

    if (!VALID_REASONING_LEVELS.has(configured)) {
      return null
    }

    return configured
  }

  /**
   * Â§ÑÁêÜÈùûÊµÅÂºèÂìçÂ∫î
   */
  async _handleNonStreamResponse(
    response,
    account,
    apiKeyData,
    requestBody,
    clientRequest,
    endpointType,
    skipUsageRecord = false
  ) {
    const { data } = response

    // ‰ªéÂìçÂ∫î‰∏≠ÊèêÂèñ usage Êï∞ÊçÆ
    const usage = data.usage || {}

    const model = requestBody.model || 'unknown'

    const normalizedUsage = this._normalizeUsageSnapshot(usage)

    if (!skipUsageRecord) {
      await this._recordUsage(apiKeyData, account, model, normalizedUsage)

      const totalTokens = this._getTotalTokens(normalizedUsage)

      const usageSummary = {
        inputTokens: normalizedUsage.input_tokens || 0,
        outputTokens: normalizedUsage.output_tokens || 0,
        cacheCreateTokens: normalizedUsage.cache_creation_input_tokens || 0,
        cacheReadTokens: normalizedUsage.cache_read_input_tokens || 0
      }

      await this._applyRateLimitTracking(
        clientRequest?.rateLimitInfo,
        usageSummary,
        model,
        endpointType === 'anthropic' ? ' [anthropic]' : ' [openai]'
      )

      logger.success(
        `‚úÖ Droid request completed - Account: ${account.name}, Tokens: ${totalTokens}`
      )
    } else {
      logger.success(
        `‚úÖ Droid request completed - Account: ${account.name}, usage recording skipped`
      )
    }

    return {
      statusCode: 200,
      headers: { 'Content-Type': 'application/json' },
      body: JSON.stringify(data)
    }
  }

  /**
   * ËÆ∞ÂΩï‰ΩøÁî®ÁªüËÆ°
   */
  async _recordUsage(apiKeyData, account, model, usageObject = {}) {
    const totalTokens = this._getTotalTokens(usageObject)

    if (totalTokens <= 0) {
      logger.debug('ü™ô Droid usage Êï∞ÊçÆ‰∏∫Á©∫ÔºåË∑≥ËøáËÆ∞ÂΩï')
      return
    }

    try {
      const keyId = apiKeyData?.id
      const accountId = this._extractAccountId(account)

      if (keyId) {
        await apiKeyService.recordUsageWithDetails(keyId, usageObject, model, accountId, 'droid')
      } else if (accountId) {
        await redis.incrementAccountUsage(
          accountId,
          totalTokens,
          usageObject.input_tokens || 0,
          usageObject.output_tokens || 0,
          usageObject.cache_creation_input_tokens || 0,
          usageObject.cache_read_input_tokens || 0,
          model,
          false
        )
      } else {
        logger.warn('‚ö†Ô∏è Êó†Ê≥ïËÆ∞ÂΩï Droid usageÔºöÁº∫Â∞ë API Key ÂíåË¥¶Êà∑Ê†áËØÜ')
        return
      }

      logger.debug(
        `üìä Droid usage recorded - Key: ${keyId || 'unknown'}, Account: ${accountId || 'unknown'}, Model: ${model}, Input: ${usageObject.input_tokens || 0}, Output: ${usageObject.output_tokens || 0}, Cache Create: ${usageObject.cache_creation_input_tokens || 0}, Cache Read: ${usageObject.cache_read_input_tokens || 0}, Total: ${totalTokens}`
      )
    } catch (error) {
      logger.error('‚ùå Failed to record Droid usage:', error)
    }
  }

  /**
   * Â§ÑÁêÜ‰∏äÊ∏∏ 4xx ÂìçÂ∫îÔºåÁßªÈô§ÈóÆÈ¢ò API Key ÊàñÂÅúÊ≠¢Ë¥¶Âè∑Ë∞ÉÂ∫¶
   */
  async _handleUpstreamClientError(statusCode, context = {}) {
    if (!statusCode || statusCode < 400 || statusCode >= 500) {
      return
    }

    const {
      account,
      selectedAccountApiKey = null,
      endpointType = null,
      sessionHash = null,
      clientApiKeyId = null
    } = context

    const accountId = this._extractAccountId(account)
    if (!accountId) {
      logger.warn('‚ö†Ô∏è ‰∏äÊ∏∏ 4xx Â§ÑÁêÜË¢´Ë∑≥ËøáÔºöÁº∫Â∞ëÊúâÊïàÁöÑË¥¶Êà∑‰ø°ÊÅØ')
      return
    }

    const normalizedEndpoint = this._normalizeEndpointType(
      endpointType || account?.endpointType || 'anthropic'
    )
    const authMethod =
      typeof account?.authenticationMethod === 'string'
        ? account.authenticationMethod.toLowerCase().trim()
        : ''

    if (authMethod === 'api_key') {
      if (selectedAccountApiKey?.id) {
        let removalResult = null

        try {
          removalResult = await droidAccountService.removeApiKeyEntry(
            accountId,
            selectedAccountApiKey.id
          )
        } catch (error) {
          logger.error(
            `‚ùå ÁßªÈô§ Droid API Key ${selectedAccountApiKey.id}ÔºàAccount: ${accountId}ÔºâÂ§±Ë¥•Ôºö`,
            error
          )
        }

        await this._clearApiKeyStickyMapping(accountId, normalizedEndpoint, sessionHash)

        if (removalResult?.removed) {
          logger.warn(
            `üö´ ‰∏äÊ∏∏ËøîÂõû ${statusCode}ÔºåÂ∑≤ÁßªÈô§ Droid API Key ${selectedAccountApiKey.id}ÔºàAccount: ${accountId}Ôºâ`
          )
        } else {
          logger.warn(
            `‚ö†Ô∏è ‰∏äÊ∏∏ËøîÂõû ${statusCode}Ôºå‰ΩÜÊú™ËÉΩÁßªÈô§ Droid API Key ${selectedAccountApiKey.id}ÔºàAccount: ${accountId}Ôºâ`
          )
        }

        if (!removalResult || removalResult.remainingCount === 0) {
          await this._stopDroidAccountScheduling(accountId, statusCode, 'API Key Â∑≤ÂÖ®ÈÉ®Â§±Êïà')
          await this._clearAccountStickyMapping(normalizedEndpoint, sessionHash, clientApiKeyId)
        } else {
          logger.info(
            `‚ÑπÔ∏è Droid Ë¥¶Âè∑ ${accountId} ‰ªçÊúâ ${removalResult.remainingCount} ‰∏™ API Key ÂèØÁî®`
          )
        }

        return
      }

      logger.warn(
        `‚ö†Ô∏è ‰∏äÊ∏∏ËøîÂõû ${statusCode}Ôºå‰ΩÜÊú™Ëé∑ÂèñÂà∞ÂØπÂ∫îÁöÑ Droid API KeyÔºàAccount: ${accountId}Ôºâ`
      )
      await this._stopDroidAccountScheduling(accountId, statusCode, 'Áº∫Â∞ëÂèØÁî® API Key')
      await this._clearAccountStickyMapping(normalizedEndpoint, sessionHash, clientApiKeyId)
      return
    }

    await this._stopDroidAccountScheduling(accountId, statusCode, 'Âá≠ËØÅ‰∏çÂèØÁî®')
    await this._clearAccountStickyMapping(normalizedEndpoint, sessionHash, clientApiKeyId)
  }

  /**
   * ÂÅúÊ≠¢ÊåáÂÆö Droid Ë¥¶Âè∑ÁöÑË∞ÉÂ∫¶
   */
  async _stopDroidAccountScheduling(accountId, statusCode, reason = '') {
    if (!accountId) {
      return
    }

    const message = reason ? `${reason}` : '‰∏äÊ∏∏ËøîÂõû 4xx ÈîôËØØ'

    try {
      await droidAccountService.updateAccount(accountId, {
        schedulable: 'false',
        status: 'error',
        errorMessage: `‰∏äÊ∏∏ËøîÂõû ${statusCode}Ôºö${message}`
      })
      logger.warn(`üö´ Â∑≤ÂÅúÊ≠¢Ë∞ÉÂ∫¶ Droid Ë¥¶Âè∑ ${accountId}ÔºàÁä∂ÊÄÅÁ†Å ${statusCode}ÔºåÂéüÂõ†Ôºö${message}Ôºâ`)
    } catch (error) {
      logger.error(`‚ùå ÂÅúÊ≠¢Ë∞ÉÂ∫¶ Droid Ë¥¶Âè∑Â§±Ë¥•Ôºö${accountId}`, error)
    }
  }

  /**
   * Ê∏ÖÁêÜË¥¶Âè∑Â±ÇÈù¢ÁöÑÁ≤òÊÄßË∞ÉÂ∫¶Êò†Â∞Ñ
   */
  async _clearAccountStickyMapping(endpointType, sessionHash, clientApiKeyId) {
    if (!sessionHash) {
      return
    }

    const normalizedEndpoint = this._normalizeEndpointType(endpointType)
    const apiKeyPart = clientApiKeyId || 'default'
    const stickyKey = `droid:${normalizedEndpoint}:${apiKeyPart}:${sessionHash}`

    try {
      await redis.deleteSessionAccountMapping(stickyKey)
      logger.debug(`üßπ Â∑≤Ê∏ÖÁêÜ Droid Á≤òÊÄß‰ºöËØùÊò†Â∞ÑÔºö${stickyKey}`)
    } catch (error) {
      logger.warn(`‚ö†Ô∏è Ê∏ÖÁêÜ Droid Á≤òÊÄß‰ºöËØùÊò†Â∞ÑÂ§±Ë¥•Ôºö${stickyKey}`, error)
    }
  }

  /**
   * Ê∏ÖÁêÜ API Key Á∫ßÂà´ÁöÑÁ≤òÊÄßÊò†Â∞Ñ
   */
  async _clearApiKeyStickyMapping(accountId, endpointType, sessionHash) {
    if (!accountId || !sessionHash) {
      return
    }

    try {
      const stickyKey = this._composeApiKeyStickyKey(accountId, endpointType, sessionHash)
      if (stickyKey) {
        await redis.deleteSessionAccountMapping(stickyKey)
        logger.debug(`üßπ Â∑≤Ê∏ÖÁêÜ Droid API Key Á≤òÊÄßÊò†Â∞ÑÔºö${stickyKey}`)
      }
    } catch (error) {
      logger.warn(
        `‚ö†Ô∏è Ê∏ÖÁêÜ Droid API Key Á≤òÊÄßÊò†Â∞ÑÂ§±Ë¥•Ôºö${accountId}Ôºàendpoint: ${endpointType}Ôºâ`,
        error
      )
    }
  }

  _mapNetworkErrorStatus(error) {
    const code = (error && error.code ? String(error.code) : '').toUpperCase()

    if (code === 'ECONNABORTED' || code === 'ETIMEDOUT') {
      return 408
    }

    if (code === 'ECONNRESET' || code === 'EPIPE') {
      return 424
    }

    if (code === 'ENOTFOUND' || code === 'EAI_AGAIN') {
      return 424
    }

    if (typeof error === 'object' && error !== null) {
      const message = (error.message || '').toLowerCase()
      if (message.includes('timeout')) {
        return 408
      }
    }

    return 424
  }

  _buildNetworkErrorBody(error) {
    const body = {
      error: 'relay_upstream_failure',
      message: error?.message || '‰∏äÊ∏∏ËØ∑Ê±ÇÂ§±Ë¥•'
    }

    if (error?.code) {
      body.code = error.code
    }

    if (error?.config?.url) {
      body.upstream = error.config.url
    }

    return body
  }

  /**
   * ÁîüÊàê UUID
   */
  _generateUUID() {
    return 'xxxxxxxx-xxxx-4xxx-yxxx-xxxxxxxxxxxx'.replace(/[xy]/g, (c) => {
      const r = (Math.random() * 16) | 0
      const v = c === 'x' ? r : (r & 0x3) | 0x8
      return v.toString(16)
    })
  }
}

// ÂØºÂá∫Âçï‰æã
module.exports = new DroidRelayService()
