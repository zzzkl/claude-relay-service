const https = require('https')
const axios = require('axios')
const ProxyHelper = require('../utils/proxyHelper')
const droidScheduler = require('./droidScheduler')
const droidAccountService = require('./droidAccountService')
const apiKeyService = require('./apiKeyService')
const redis = require('../models/redis')
const { updateRateLimitCounters } = require('../utils/rateLimitHelper')
const logger = require('../utils/logger')

const SYSTEM_PROMPT = 'You are Droid, an AI software engineering agent built by Factory.'

const MODEL_REASONING_CONFIG = {
  'claude-opus-4-1-20250805': 'off',
  'claude-sonnet-4-20250514': 'medium',
  'claude-sonnet-4-5-20250929': 'high',
  'gpt-5-2025-08-07': 'high',
  'gpt-5-codex': 'off'
}

const VALID_REASONING_LEVELS = new Set(['low', 'medium', 'high'])

/**
 * Droid API è½¬å‘æœåŠ¡
 */

class DroidRelayService {
  constructor() {
    this.factoryApiBaseUrl = 'https://app.factory.ai/api/llm'

    this.endpoints = {
      anthropic: '/a/v1/messages',
      openai: '/o/v1/responses'
    }

    this.userAgent = 'factory-cli/0.19.4'
    this.systemPrompt = SYSTEM_PROMPT
    this.modelReasoningMap = new Map()
    this.API_KEY_STICKY_PREFIX = 'droid_api_key'

    Object.entries(MODEL_REASONING_CONFIG).forEach(([modelId, level]) => {
      if (!modelId) {
        return
      }
      const normalized = typeof level === 'string' ? level.toLowerCase() : ''
      this.modelReasoningMap.set(modelId, normalized)
    })
  }

  _normalizeEndpointType(endpointType) {
    if (!endpointType) {
      return 'anthropic'
    }

    const normalized = String(endpointType).toLowerCase()
    if (normalized === 'openai' || normalized === 'common') {
      return 'openai'
    }

    if (normalized === 'anthropic') {
      return 'anthropic'
    }

    return 'anthropic'
  }

  _normalizeRequestBody(requestBody, endpointType) {
    if (!requestBody || typeof requestBody !== 'object') {
      return requestBody
    }

    const normalizedBody = { ...requestBody }

    if (endpointType === 'anthropic' && typeof normalizedBody.model === 'string') {
      const originalModel = normalizedBody.model
      const trimmedModel = originalModel.trim()
      const lowerModel = trimmedModel.toLowerCase()

      if (lowerModel.includes('haiku')) {
        const mappedModel = 'claude-sonnet-4-20250514'
        if (originalModel !== mappedModel) {
          logger.info(`ğŸ”„ å°†è¯·æ±‚æ¨¡å‹ä» ${originalModel} æ˜ å°„ä¸º ${mappedModel}`)
        }
        normalizedBody.model = mappedModel
        normalizedBody.__forceDisableThinking = true
      }
    }

    if (endpointType === 'openai' && typeof normalizedBody.model === 'string') {
      const originalModel = normalizedBody.model
      const trimmedModel = originalModel.trim()
      const lowerModel = trimmedModel.toLowerCase()

      if (lowerModel === 'gpt-5') {
        const mappedModel = 'gpt-5-2025-08-07'
        if (originalModel !== mappedModel) {
          logger.info(`ğŸ”„ å°†è¯·æ±‚æ¨¡å‹ä» ${originalModel} æ˜ å°„ä¸º ${mappedModel}`)
        }
        normalizedBody.model = mappedModel
      }
    }

    return normalizedBody
  }

  async _applyRateLimitTracking(rateLimitInfo, usageSummary, model, context = '') {
    if (!rateLimitInfo) {
      return
    }

    try {
      const { totalTokens, totalCost } = await updateRateLimitCounters(
        rateLimitInfo,
        usageSummary,
        model
      )

      if (totalTokens > 0) {
        logger.api(`ğŸ“Š Updated rate limit token count${context}: +${totalTokens}`)
      }
      if (typeof totalCost === 'number' && totalCost > 0) {
        logger.api(`ğŸ’° Updated rate limit cost count${context}: +$${totalCost.toFixed(6)}`)
      }
    } catch (error) {
      logger.error(`âŒ Failed to update rate limit counters${context}:`, error)
    }
  }

  _composeApiKeyStickyKey(accountId, endpointType, sessionHash) {
    if (!accountId || !sessionHash) {
      return null
    }

    const normalizedEndpoint = this._normalizeEndpointType(endpointType)
    return `${this.API_KEY_STICKY_PREFIX}:${accountId}:${normalizedEndpoint}:${sessionHash}`
  }

  async _selectApiKey(account, endpointType, sessionHash) {
    const entries = await droidAccountService.getDecryptedApiKeyEntries(account.id)
    if (!entries || entries.length === 0) {
      throw new Error(`Droid account ${account.id} æœªé…ç½®ä»»ä½• API Key`)
    }

    const stickyKey = this._composeApiKeyStickyKey(account.id, endpointType, sessionHash)

    if (stickyKey) {
      const mappedKeyId = await redis.getSessionAccountMapping(stickyKey)
      if (mappedKeyId) {
        const mappedEntry = entries.find((entry) => entry.id === mappedKeyId)
        if (mappedEntry) {
          await redis.extendSessionAccountMappingTTL(stickyKey)
          await droidAccountService.touchApiKeyUsage(account.id, mappedEntry.id)
          logger.info(`ğŸ” ä½¿ç”¨å·²ç»‘å®šçš„ Droid API Key ${mappedEntry.id}ï¼ˆAccount: ${account.id}ï¼‰`)
          return mappedEntry
        }

        await redis.deleteSessionAccountMapping(stickyKey)
      }
    }

    const selectedEntry = entries[Math.floor(Math.random() * entries.length)]
    if (!selectedEntry) {
      throw new Error(`Droid account ${account.id} æ²¡æœ‰å¯ç”¨çš„ API Key`)
    }

    if (stickyKey) {
      await redis.setSessionAccountMapping(stickyKey, selectedEntry.id)
    }

    await droidAccountService.touchApiKeyUsage(account.id, selectedEntry.id)

    logger.info(
      `ğŸ” éšæœºé€‰å– Droid API Key ${selectedEntry.id}ï¼ˆAccount: ${account.id}, Keys: ${entries.length}ï¼‰`
    )

    return selectedEntry
  }

  async relayRequest(
    requestBody,
    apiKeyData,
    clientRequest,
    clientResponse,
    clientHeaders,
    options = {}
  ) {
    const {
      endpointType = 'anthropic',
      sessionHash = null,
      customPath = null,
      skipUsageRecord = false,
      disableStreaming = false
    } = options
    const keyInfo = apiKeyData || {}
    const clientApiKeyId = keyInfo.id || null
    const normalizedEndpoint = this._normalizeEndpointType(endpointType)
    const normalizedRequestBody = this._normalizeRequestBody(requestBody, normalizedEndpoint)
    let account = null
    let selectedApiKey = null
    let accessToken = null

    try {
      logger.info(
        `ğŸ“¤ Processing Droid API request for key: ${
          keyInfo.name || keyInfo.id || 'unknown'
        }, endpoint: ${normalizedEndpoint}${sessionHash ? `, session: ${sessionHash}` : ''}`
      )

      // é€‰æ‹©ä¸€ä¸ªå¯ç”¨çš„ Droid è´¦æˆ·ï¼ˆæ”¯æŒç²˜æ€§ä¼šè¯å’Œåˆ†ç»„è°ƒåº¦ï¼‰
      account = await droidScheduler.selectAccount(keyInfo, normalizedEndpoint, sessionHash)

      if (!account) {
        throw new Error(`No available Droid account for endpoint type: ${normalizedEndpoint}`)
      }

      // è·å–è®¤è¯å‡­æ®ï¼šæ”¯æŒ Access Token å’Œ API Key ä¸¤ç§æ¨¡å¼
      if (
        typeof account.authenticationMethod === 'string' &&
        account.authenticationMethod.toLowerCase().trim() === 'api_key'
      ) {
        selectedApiKey = await this._selectApiKey(account, normalizedEndpoint, sessionHash)
        accessToken = selectedApiKey.key
      } else {
        accessToken = await droidAccountService.getValidAccessToken(account.id)
      }

      // è·å– Factory.ai API URL
      let endpointPath = this.endpoints[normalizedEndpoint]

      if (typeof customPath === 'string' && customPath.trim()) {
        endpointPath = customPath.startsWith('/') ? customPath : `/${customPath}`
      }

      const apiUrl = `${this.factoryApiBaseUrl}${endpointPath}`

      logger.info(`ğŸŒ Forwarding to Factory.ai: ${apiUrl}`)

      // è·å–ä»£ç†é…ç½®
      const proxyConfig = account.proxy ? JSON.parse(account.proxy) : null
      const proxyAgent = proxyConfig ? ProxyHelper.createProxyAgent(proxyConfig) : null

      if (proxyAgent) {
        logger.info(`ğŸŒ Using proxy: ${ProxyHelper.getProxyDescription(proxyConfig)}`)
      }

      // æ„å»ºè¯·æ±‚å¤´
      const headers = this._buildHeaders(
        accessToken,
        normalizedRequestBody,
        normalizedEndpoint,
        clientHeaders
      )

      if (selectedApiKey) {
        logger.info(
          `ğŸ”‘ Forwarding request with Droid API Key ${selectedApiKey.id} (Account: ${account.id})`
        )
      }

      // å¤„ç†è¯·æ±‚ä½“ï¼ˆæ³¨å…¥ system prompt ç­‰ï¼‰
      const streamRequested = !disableStreaming && this._isStreamRequested(normalizedRequestBody)

      const processedBody = this._processRequestBody(normalizedRequestBody, normalizedEndpoint, {
        disableStreaming,
        streamRequested
      })

      // å‘é€è¯·æ±‚
      const isStreaming = streamRequested

      // æ ¹æ®æ˜¯å¦æµå¼é€‰æ‹©ä¸åŒçš„å¤„ç†æ–¹å¼
      if (isStreaming) {
        // æµå¼å“åº”ï¼šä½¿ç”¨åŸç”Ÿ https æ¨¡å—ä»¥æ›´å¥½åœ°æ§åˆ¶æµ
        return await this._handleStreamRequest(
          apiUrl,
          headers,
          processedBody,
          proxyAgent,
          clientRequest,
          clientResponse,
          account,
          keyInfo,
          normalizedRequestBody,
          normalizedEndpoint,
          skipUsageRecord,
          selectedApiKey,
          sessionHash,
          clientApiKeyId
        )
      } else {
        // éæµå¼å“åº”ï¼šä½¿ç”¨ axios
        const requestOptions = {
          method: 'POST',
          url: apiUrl,
          headers,
          data: processedBody,
          timeout: 600 * 1000, // 10åˆ†é’Ÿè¶…æ—¶
          responseType: 'json',
          ...(proxyAgent && {
            httpAgent: proxyAgent,
            httpsAgent: proxyAgent
          })
        }

        const response = await axios(requestOptions)

        logger.info(`âœ… Factory.ai response status: ${response.status}`)

        // å¤„ç†éæµå¼å“åº”
        return this._handleNonStreamResponse(
          response,
          account,
          keyInfo,
          normalizedRequestBody,
          clientRequest,
          normalizedEndpoint,
          skipUsageRecord
        )
      }
    } catch (error) {
      logger.error(`âŒ Droid relay error: ${error.message}`, error)

      const status = error?.response?.status
      if (status >= 400 && status < 500) {
        try {
          await this._handleUpstreamClientError(status, {
            account,
            selectedAccountApiKey: selectedApiKey,
            endpointType: normalizedEndpoint,
            sessionHash,
            clientApiKeyId
          })
        } catch (handlingError) {
          logger.error('âŒ å¤„ç† Droid 4xx å¼‚å¸¸å¤±è´¥:', handlingError)
        }
      }

      if (error.response) {
        // HTTP é”™è¯¯å“åº”
        return {
          statusCode: error.response.status,
          headers: { 'Content-Type': 'application/json' },
          body: JSON.stringify(
            error.response.data || {
              error: 'upstream_error',
              message: error.message
            }
          )
        }
      }

      // ç½‘ç»œé”™è¯¯æˆ–å…¶ä»–é”™è¯¯ï¼ˆç»Ÿä¸€è¿”å› 4xxï¼‰
      const mappedStatus = this._mapNetworkErrorStatus(error)
      return {
        statusCode: mappedStatus,
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify(this._buildNetworkErrorBody(error))
      }
    }
  }

  /**
   * å¤„ç†æµå¼è¯·æ±‚
   */
  async _handleStreamRequest(
    apiUrl,
    headers,
    processedBody,
    proxyAgent,
    clientRequest,
    clientResponse,
    account,
    apiKeyData,
    requestBody,
    endpointType,
    skipUsageRecord = false,
    selectedAccountApiKey = null,
    sessionHash = null,
    clientApiKeyId = null
  ) {
    return new Promise((resolve, reject) => {
      const url = new URL(apiUrl)
      const bodyString = JSON.stringify(processedBody)
      const contentLength = Buffer.byteLength(bodyString)
      const requestHeaders = {
        ...headers,
        'content-length': contentLength.toString()
      }

      let responseStarted = false
      let responseCompleted = false
      let settled = false
      let upstreamResponse = null
      let completionWindow = ''
      let hasForwardedData = false

      const resolveOnce = (value) => {
        if (settled) {
          return
        }
        settled = true
        resolve(value)
      }

      const rejectOnce = (error) => {
        if (settled) {
          return
        }
        settled = true
        reject(error)
      }

      const handleStreamError = (error) => {
        if (responseStarted) {
          const isConnectionReset =
            error && (error.code === 'ECONNRESET' || error.message === 'aborted')
          const upstreamComplete =
            responseCompleted || upstreamResponse?.complete || clientResponse.writableEnded

          if (isConnectionReset && (upstreamComplete || hasForwardedData)) {
            logger.debug('ğŸ” Droid streamè¿æ¥åœ¨å“åº”é˜¶æ®µè¢«é‡ç½®ï¼Œè§†ä¸ºæ­£å¸¸ç»“æŸ:', {
              message: error?.message,
              code: error?.code
            })
            if (!clientResponse.destroyed && !clientResponse.writableEnded) {
              clientResponse.end()
            }
            resolveOnce({ statusCode: 200, streaming: true })
            return
          }

          logger.error('âŒ Droid stream error:', error)
          const mappedStatus = this._mapNetworkErrorStatus(error)
          const errorBody = this._buildNetworkErrorBody(error)

          if (!clientResponse.destroyed) {
            if (!clientResponse.writableEnded) {
              const canUseJson =
                !hasForwardedData &&
                typeof clientResponse.status === 'function' &&
                typeof clientResponse.json === 'function'

              if (canUseJson) {
                clientResponse.status(mappedStatus).json(errorBody)
              } else {
                const errorPayload = JSON.stringify(errorBody)

                if (!hasForwardedData) {
                  if (typeof clientResponse.setHeader === 'function') {
                    clientResponse.setHeader('Content-Type', 'application/json')
                  }
                  clientResponse.write(errorPayload)
                  clientResponse.end()
                } else {
                  clientResponse.write(`event: error\ndata: ${errorPayload}\n\n`)
                  clientResponse.end()
                }
              }
            }
          }

          resolveOnce({ statusCode: mappedStatus, streaming: true, error })
        } else {
          rejectOnce(error)
        }
      }

      const options = {
        hostname: url.hostname,
        port: url.port || 443,
        path: url.pathname,
        method: 'POST',
        headers: requestHeaders,
        agent: proxyAgent,
        timeout: 600 * 1000
      }

      const req = https.request(options, (res) => {
        upstreamResponse = res
        logger.info(`âœ… Factory.ai stream response status: ${res.statusCode}`)

        // é”™è¯¯å“åº”
        if (res.statusCode !== 200) {
          const chunks = []

          res.on('data', (chunk) => {
            chunks.push(chunk)
            logger.info(`ğŸ“¦ got ${chunk.length} bytes of data`)
          })

          res.on('end', () => {
            logger.info('âœ… res.end() reached')
            const body = Buffer.concat(chunks).toString()
            logger.error(`âŒ Factory.ai error response body: ${body || '(empty)'}`)
            if (res.statusCode >= 400 && res.statusCode < 500) {
              this._handleUpstreamClientError(res.statusCode, {
                account,
                selectedAccountApiKey,
                endpointType,
                sessionHash,
                clientApiKeyId
              }).catch((handlingError) => {
                logger.error('âŒ å¤„ç† Droid æµå¼4xx å¼‚å¸¸å¤±è´¥:', handlingError)
              })
            }
            if (!clientResponse.headersSent) {
              clientResponse.status(res.statusCode).json({
                error: 'upstream_error',
                details: body
              })
            }
            resolveOnce({ statusCode: res.statusCode, streaming: true })
          })

          res.on('close', () => {
            logger.warn('âš ï¸ response closed before end event')
          })

          res.on('error', handleStreamError)

          return
        }

        responseStarted = true

        // è®¾ç½®æµå¼å“åº”å¤´
        clientResponse.setHeader('Content-Type', 'text/event-stream')
        clientResponse.setHeader('Cache-Control', 'no-cache')
        clientResponse.setHeader('Connection', 'keep-alive')

        // Usage æ•°æ®æ”¶é›†
        let buffer = ''
        const currentUsageData = {}
        const model = requestBody.model || 'unknown'

        // å¤„ç† SSE æµ
        res.on('data', (chunk) => {
          const chunkStr = chunk.toString()
          completionWindow = (completionWindow + chunkStr).slice(-1024)
          hasForwardedData = true

          // è½¬å‘æ•°æ®åˆ°å®¢æˆ·ç«¯
          clientResponse.write(chunk)
          hasForwardedData = true

          // è§£æ usage æ•°æ®ï¼ˆæ ¹æ®ç«¯ç‚¹ç±»å‹ï¼‰
          if (endpointType === 'anthropic') {
            // Anthropic Messages API æ ¼å¼
            this._parseAnthropicUsageFromSSE(chunkStr, buffer, currentUsageData)
          } else if (endpointType === 'openai') {
            // OpenAI Chat Completions æ ¼å¼
            this._parseOpenAIUsageFromSSE(chunkStr, buffer, currentUsageData)
          }

          if (!responseCompleted && this._detectStreamCompletion(completionWindow, endpointType)) {
            responseCompleted = true
          }

          buffer += chunkStr
        })

        res.on('end', async () => {
          responseCompleted = true
          clientResponse.end()

          // è®°å½• usage æ•°æ®
          if (!skipUsageRecord) {
            const normalizedUsage = await this._recordUsageFromStreamData(
              currentUsageData,
              apiKeyData,
              account,
              model
            )

            const usageSummary = {
              inputTokens: normalizedUsage.input_tokens || 0,
              outputTokens: normalizedUsage.output_tokens || 0,
              cacheCreateTokens: normalizedUsage.cache_creation_input_tokens || 0,
              cacheReadTokens: normalizedUsage.cache_read_input_tokens || 0
            }

            await this._applyRateLimitTracking(
              clientRequest?.rateLimitInfo,
              usageSummary,
              model,
              ' [stream]'
            )

            logger.success(`âœ… Droid stream completed - Account: ${account.name}`)
          } else {
            logger.success(
              `âœ… Droid stream completed - Account: ${account.name}, usage recording skipped`
            )
          }
          resolveOnce({ statusCode: 200, streaming: true })
        })

        res.on('error', handleStreamError)

        res.on('close', () => {
          if (settled) {
            return
          }

          if (responseCompleted) {
            if (!clientResponse.destroyed && !clientResponse.writableEnded) {
              clientResponse.end()
            }
            resolveOnce({ statusCode: 200, streaming: true })
          } else {
            handleStreamError(new Error('Upstream stream closed unexpectedly'))
          }
        })
      })

      // å®¢æˆ·ç«¯æ–­å¼€è¿æ¥æ—¶æ¸…ç†
      clientResponse.on('close', () => {
        if (req && !req.destroyed) {
          req.destroy()
        }
      })

      req.on('error', handleStreamError)

      req.on('timeout', () => {
        req.destroy()
        logger.error('âŒ Droid request timeout')
        handleStreamError(new Error('Request timeout'))
      })

      // å†™å…¥è¯·æ±‚ä½“
      req.end(bodyString)
    })
  }

  /**
   * ä» SSE æµä¸­è§£æ Anthropic usage æ•°æ®
   */
  _parseAnthropicUsageFromSSE(chunkStr, buffer, currentUsageData) {
    try {
      // åˆ†å‰²æˆè¡Œ
      const lines = (buffer + chunkStr).split('\n')

      for (const line of lines) {
        if (line.startsWith('data: ') && line.length > 6) {
          try {
            const jsonStr = line.slice(6)
            const data = JSON.parse(jsonStr)

            // message_start åŒ…å« input tokens å’Œ cache tokens
            if (data.type === 'message_start' && data.message && data.message.usage) {
              currentUsageData.input_tokens = data.message.usage.input_tokens || 0
              currentUsageData.cache_creation_input_tokens =
                data.message.usage.cache_creation_input_tokens || 0
              currentUsageData.cache_read_input_tokens =
                data.message.usage.cache_read_input_tokens || 0

              // è¯¦ç»†çš„ç¼“å­˜ç±»å‹
              if (data.message.usage.cache_creation) {
                currentUsageData.cache_creation = {
                  ephemeral_5m_input_tokens:
                    data.message.usage.cache_creation.ephemeral_5m_input_tokens || 0,
                  ephemeral_1h_input_tokens:
                    data.message.usage.cache_creation.ephemeral_1h_input_tokens || 0
                }
              }

              logger.debug('ğŸ“Š Droid Anthropic input usage:', currentUsageData)
            }

            // message_delta åŒ…å« output tokens
            if (data.type === 'message_delta' && data.usage) {
              currentUsageData.output_tokens = data.usage.output_tokens || 0
              logger.debug('ğŸ“Š Droid Anthropic output usage:', currentUsageData.output_tokens)
            }
          } catch (parseError) {
            // å¿½ç•¥è§£æé”™è¯¯
          }
        }
      }
    } catch (error) {
      logger.debug('Error parsing Anthropic usage:', error)
    }
  }

  /**
   * ä» SSE æµä¸­è§£æ OpenAI usage æ•°æ®
   */
  _parseOpenAIUsageFromSSE(chunkStr, buffer, currentUsageData) {
    try {
      // OpenAI Chat Completions æµå¼æ ¼å¼
      const lines = (buffer + chunkStr).split('\n')

      for (const line of lines) {
        if (line.startsWith('data: ') && line.length > 6) {
          try {
            const jsonStr = line.slice(6)
            if (jsonStr === '[DONE]') {
              continue
            }

            const data = JSON.parse(jsonStr)

            // å…¼å®¹ä¼ ç»Ÿ Chat Completions usage å­—æ®µ
            if (data.usage) {
              currentUsageData.input_tokens = data.usage.prompt_tokens || 0
              currentUsageData.output_tokens = data.usage.completion_tokens || 0
              currentUsageData.total_tokens = data.usage.total_tokens || 0

              logger.debug('ğŸ“Š Droid OpenAI usage:', currentUsageData)
            }

            // æ–° Response API åœ¨ response.usage ä¸­è¿”å›ç»Ÿè®¡
            if (data.response && data.response.usage) {
              const { usage } = data.response
              currentUsageData.input_tokens =
                usage.input_tokens || usage.prompt_tokens || usage.total_tokens || 0
              currentUsageData.output_tokens = usage.output_tokens || usage.completion_tokens || 0
              currentUsageData.total_tokens = usage.total_tokens || 0

              logger.debug('ğŸ“Š Droid OpenAI response usage:', currentUsageData)
            }
          } catch (parseError) {
            // å¿½ç•¥è§£æé”™è¯¯
          }
        }
      }
    } catch (error) {
      logger.debug('Error parsing OpenAI usage:', error)
    }
  }

  /**
   * æ£€æµ‹æµå¼å“åº”æ˜¯å¦å·²ç»åŒ…å«ç»ˆæ­¢æ ‡è®°
   */
  _detectStreamCompletion(windowStr, endpointType) {
    if (!windowStr) {
      return false
    }

    const lower = windowStr.toLowerCase()
    const compact = lower.replace(/\s+/g, '')

    if (endpointType === 'anthropic') {
      if (lower.includes('event: message_stop')) {
        return true
      }
      if (compact.includes('"type":"message_stop"')) {
        return true
      }
      return false
    }

    if (endpointType === 'openai') {
      if (lower.includes('data: [done]')) {
        return true
      }

      if (compact.includes('"finish_reason"')) {
        return true
      }

      if (lower.includes('event: response.done') || lower.includes('event: response.completed')) {
        return true
      }

      if (
        compact.includes('"type":"response.done"') ||
        compact.includes('"type":"response.completed"')
      ) {
        return true
      }
    }

    return false
  }

  /**
   * è®°å½•ä»æµä¸­è§£æçš„ usage æ•°æ®
   */
  async _recordUsageFromStreamData(usageData, apiKeyData, account, model) {
    const normalizedUsage = this._normalizeUsageSnapshot(usageData)
    await this._recordUsage(apiKeyData, account, model, normalizedUsage)
    return normalizedUsage
  }

  /**
   * æ ‡å‡†åŒ– usage æ•°æ®ï¼Œç¡®ä¿å­—æ®µå®Œæ•´ä¸”ä¸ºæ•°å­—
   */
  _normalizeUsageSnapshot(usageData = {}) {
    const toNumber = (value) => {
      if (value === undefined || value === null || value === '') {
        return 0
      }
      const num = Number(value)
      if (!Number.isFinite(num)) {
        return 0
      }
      return Math.max(0, num)
    }

    const inputTokens = toNumber(
      usageData.input_tokens ??
        usageData.prompt_tokens ??
        usageData.inputTokens ??
        usageData.total_input_tokens
    )
    const outputTokens = toNumber(
      usageData.output_tokens ?? usageData.completion_tokens ?? usageData.outputTokens
    )
    const cacheReadTokens = toNumber(
      usageData.cache_read_input_tokens ??
        usageData.cacheReadTokens ??
        usageData.input_tokens_details?.cached_tokens
    )

    const rawCacheCreateTokens =
      usageData.cache_creation_input_tokens ??
      usageData.cacheCreateTokens ??
      usageData.cache_tokens ??
      0
    let cacheCreateTokens = toNumber(rawCacheCreateTokens)

    const ephemeral5m = toNumber(
      usageData.cache_creation?.ephemeral_5m_input_tokens ?? usageData.ephemeral_5m_input_tokens
    )
    const ephemeral1h = toNumber(
      usageData.cache_creation?.ephemeral_1h_input_tokens ?? usageData.ephemeral_1h_input_tokens
    )

    if (cacheCreateTokens === 0 && (ephemeral5m > 0 || ephemeral1h > 0)) {
      cacheCreateTokens = ephemeral5m + ephemeral1h
    }

    const normalized = {
      input_tokens: inputTokens,
      output_tokens: outputTokens,
      cache_creation_input_tokens: cacheCreateTokens,
      cache_read_input_tokens: cacheReadTokens
    }

    if (ephemeral5m > 0 || ephemeral1h > 0) {
      normalized.cache_creation = {
        ephemeral_5m_input_tokens: ephemeral5m,
        ephemeral_1h_input_tokens: ephemeral1h
      }
    }

    return normalized
  }

  /**
   * è®¡ç®— usage å¯¹è±¡çš„æ€» token æ•°
   */
  _getTotalTokens(usageObject = {}) {
    const toNumber = (value) => {
      if (value === undefined || value === null || value === '') {
        return 0
      }
      const num = Number(value)
      if (!Number.isFinite(num)) {
        return 0
      }
      return Math.max(0, num)
    }

    return (
      toNumber(usageObject.input_tokens) +
      toNumber(usageObject.output_tokens) +
      toNumber(usageObject.cache_creation_input_tokens) +
      toNumber(usageObject.cache_read_input_tokens)
    )
  }

  /**
   * æå–è´¦æˆ· ID
   */
  _extractAccountId(account) {
    if (!account || typeof account !== 'object') {
      return null
    }
    return account.id || account.accountId || account.account_id || null
  }

  /**
   * æ„å»ºè¯·æ±‚å¤´
   */
  _buildHeaders(accessToken, requestBody, endpointType, clientHeaders = {}) {
    const headers = {
      'content-type': 'application/json',
      authorization: `Bearer ${accessToken}`,
      'user-agent': this.userAgent,
      'x-factory-client': 'cli',
      connection: 'keep-alive'
    }

    // Anthropic ç‰¹å®šå¤´
    if (endpointType === 'anthropic') {
      headers['accept'] = 'application/json'
      headers['anthropic-version'] = '2023-06-01'
      headers['x-api-key'] = 'placeholder'
      headers['x-api-provider'] = 'anthropic'

      // å¤„ç† anthropic-beta å¤´
      const reasoningLevel = this._getReasoningLevel(requestBody)
      if (reasoningLevel) {
        headers['anthropic-beta'] = 'interleaved-thinking-2025-05-14'
      }
    }

    // OpenAI ç‰¹å®šå¤´
    if (endpointType === 'openai') {
      headers['x-api-provider'] = 'azure_openai'
    }

    // ç”Ÿæˆä¼šè¯ IDï¼ˆå¦‚æœå®¢æˆ·ç«¯æ²¡æœ‰æä¾›ï¼‰
    headers['x-session-id'] = clientHeaders['x-session-id'] || this._generateUUID()

    return headers
  }

  /**
   * åˆ¤æ–­è¯·æ±‚æ˜¯å¦è¦æ±‚æµå¼å“åº”
   */
  _isStreamRequested(requestBody) {
    if (!requestBody || typeof requestBody !== 'object') {
      return false
    }

    const value = requestBody.stream

    if (value === true) {
      return true
    }

    if (typeof value === 'string') {
      return value.toLowerCase() === 'true'
    }

    return false
  }

  /**
   * å¤„ç†è¯·æ±‚ä½“ï¼ˆæ³¨å…¥ system prompt ç­‰ï¼‰
   */
  _processRequestBody(requestBody, endpointType, options = {}) {
    const { disableStreaming = false, streamRequested = false } = options
    const processedBody = { ...requestBody }

    const hasStreamField =
      requestBody && Object.prototype.hasOwnProperty.call(requestBody, 'stream')

    const shouldDisableThinking =
      endpointType === 'anthropic' && processedBody.__forceDisableThinking === true

    if ('__forceDisableThinking' in processedBody) {
      delete processedBody.__forceDisableThinking
    }

    if (requestBody && '__forceDisableThinking' in requestBody) {
      delete requestBody.__forceDisableThinking
    }

    if (processedBody && Object.prototype.hasOwnProperty.call(processedBody, 'metadata')) {
      delete processedBody.metadata
    }

    if (disableStreaming || !streamRequested) {
      if (hasStreamField) {
        processedBody.stream = false
      } else if ('stream' in processedBody) {
        delete processedBody.stream
      }
    } else {
      processedBody.stream = true
    }

    // Anthropic ç«¯ç‚¹ï¼šå¤„ç† thinking å­—æ®µ
    if (endpointType === 'anthropic') {
      if (this.systemPrompt) {
        const promptBlock = { type: 'text', text: this.systemPrompt }
        if (Array.isArray(processedBody.system)) {
          const hasPrompt = processedBody.system.some(
            (item) => item && item.type === 'text' && item.text === this.systemPrompt
          )
          if (!hasPrompt) {
            processedBody.system = [promptBlock, ...processedBody.system]
          }
        } else {
          processedBody.system = [promptBlock]
        }
      }

      const reasoningLevel = shouldDisableThinking ? null : this._getReasoningLevel(requestBody)
      if (reasoningLevel) {
        const budgetTokens = {
          low: 4096,
          medium: 12288,
          high: 24576
        }
        processedBody.thinking = {
          type: 'enabled',
          budget_tokens: budgetTokens[reasoningLevel]
        }
      } else {
        delete processedBody.thinking
      }

      if (shouldDisableThinking) {
        if ('thinking' in processedBody) {
          delete processedBody.thinking
        }
      }
    }

    // OpenAI ç«¯ç‚¹ï¼šå¤„ç† reasoning å­—æ®µ
    if (endpointType === 'openai') {
      if (this.systemPrompt) {
        if (processedBody.instructions) {
          if (!processedBody.instructions.startsWith(this.systemPrompt)) {
            processedBody.instructions = `${this.systemPrompt}${processedBody.instructions}`
          }
        } else {
          processedBody.instructions = this.systemPrompt
        }
      }

      const reasoningLevel = this._getReasoningLevel(requestBody)
      if (reasoningLevel) {
        processedBody.reasoning = {
          effort: reasoningLevel,
          summary: 'auto'
        }
      } else {
        delete processedBody.reasoning
      }
    }

    return processedBody
  }

  /**
   * è·å–æ¨ç†çº§åˆ«ï¼ˆå¦‚æœåœ¨ requestBody ä¸­é…ç½®ï¼‰
   */
  _getReasoningLevel(requestBody) {
    if (!requestBody || !requestBody.model) {
      return null
    }

    const configured = this.modelReasoningMap.get(requestBody.model)
    if (!configured) {
      return null
    }

    if (!VALID_REASONING_LEVELS.has(configured)) {
      return null
    }

    return configured
  }

  /**
   * å¤„ç†éæµå¼å“åº”
   */
  async _handleNonStreamResponse(
    response,
    account,
    apiKeyData,
    requestBody,
    clientRequest,
    endpointType,
    skipUsageRecord = false
  ) {
    const { data } = response

    // ä»å“åº”ä¸­æå– usage æ•°æ®
    const usage = data.usage || {}

    const model = requestBody.model || 'unknown'

    const normalizedUsage = this._normalizeUsageSnapshot(usage)

    if (!skipUsageRecord) {
      await this._recordUsage(apiKeyData, account, model, normalizedUsage)

      const totalTokens = this._getTotalTokens(normalizedUsage)

      const usageSummary = {
        inputTokens: normalizedUsage.input_tokens || 0,
        outputTokens: normalizedUsage.output_tokens || 0,
        cacheCreateTokens: normalizedUsage.cache_creation_input_tokens || 0,
        cacheReadTokens: normalizedUsage.cache_read_input_tokens || 0
      }

      await this._applyRateLimitTracking(
        clientRequest?.rateLimitInfo,
        usageSummary,
        model,
        endpointType === 'anthropic' ? ' [anthropic]' : ' [openai]'
      )

      logger.success(
        `âœ… Droid request completed - Account: ${account.name}, Tokens: ${totalTokens}`
      )
    } else {
      logger.success(
        `âœ… Droid request completed - Account: ${account.name}, usage recording skipped`
      )
    }

    return {
      statusCode: 200,
      headers: { 'Content-Type': 'application/json' },
      body: JSON.stringify(data)
    }
  }

  /**
   * è®°å½•ä½¿ç”¨ç»Ÿè®¡
   */
  async _recordUsage(apiKeyData, account, model, usageObject = {}) {
    const totalTokens = this._getTotalTokens(usageObject)

    if (totalTokens <= 0) {
      logger.debug('ğŸª™ Droid usage æ•°æ®ä¸ºç©ºï¼Œè·³è¿‡è®°å½•')
      return
    }

    try {
      const keyId = apiKeyData?.id
      const accountId = this._extractAccountId(account)

      if (keyId) {
        await apiKeyService.recordUsageWithDetails(keyId, usageObject, model, accountId, 'droid')
      } else if (accountId) {
        await redis.incrementAccountUsage(
          accountId,
          totalTokens,
          usageObject.input_tokens || 0,
          usageObject.output_tokens || 0,
          usageObject.cache_creation_input_tokens || 0,
          usageObject.cache_read_input_tokens || 0,
          model,
          false
        )
      } else {
        logger.warn('âš ï¸ æ— æ³•è®°å½• Droid usageï¼šç¼ºå°‘ API Key å’Œè´¦æˆ·æ ‡è¯†')
        return
      }

      logger.debug(
        `ğŸ“Š Droid usage recorded - Key: ${keyId || 'unknown'}, Account: ${accountId || 'unknown'}, Model: ${model}, Input: ${usageObject.input_tokens || 0}, Output: ${usageObject.output_tokens || 0}, Cache Create: ${usageObject.cache_creation_input_tokens || 0}, Cache Read: ${usageObject.cache_read_input_tokens || 0}, Total: ${totalTokens}`
      )
    } catch (error) {
      logger.error('âŒ Failed to record Droid usage:', error)
    }
  }

  /**
   * å¤„ç†ä¸Šæ¸¸ 4xx å“åº”ï¼Œç§»é™¤é—®é¢˜ API Key æˆ–åœæ­¢è´¦å·è°ƒåº¦
   */
  async _handleUpstreamClientError(statusCode, context = {}) {
    if (!statusCode || statusCode < 400 || statusCode >= 500) {
      return
    }

    const {
      account,
      selectedAccountApiKey = null,
      endpointType = null,
      sessionHash = null,
      clientApiKeyId = null
    } = context

    const accountId = this._extractAccountId(account)
    if (!accountId) {
      logger.warn('âš ï¸ ä¸Šæ¸¸ 4xx å¤„ç†è¢«è·³è¿‡ï¼šç¼ºå°‘æœ‰æ•ˆçš„è´¦æˆ·ä¿¡æ¯')
      return
    }

    const normalizedEndpoint = this._normalizeEndpointType(
      endpointType || account?.endpointType || 'anthropic'
    )
    const authMethod =
      typeof account?.authenticationMethod === 'string'
        ? account.authenticationMethod.toLowerCase().trim()
        : ''

    if (authMethod === 'api_key') {
      if (selectedAccountApiKey?.id) {
        let removalResult = null

        try {
          removalResult = await droidAccountService.removeApiKeyEntry(
            accountId,
            selectedAccountApiKey.id
          )
        } catch (error) {
          logger.error(
            `âŒ ç§»é™¤ Droid API Key ${selectedAccountApiKey.id}ï¼ˆAccount: ${accountId}ï¼‰å¤±è´¥ï¼š`,
            error
          )
        }

        await this._clearApiKeyStickyMapping(accountId, normalizedEndpoint, sessionHash)

        if (removalResult?.removed) {
          logger.warn(
            `ğŸš« ä¸Šæ¸¸è¿”å› ${statusCode}ï¼Œå·²ç§»é™¤ Droid API Key ${selectedAccountApiKey.id}ï¼ˆAccount: ${accountId}ï¼‰`
          )
        } else {
          logger.warn(
            `âš ï¸ ä¸Šæ¸¸è¿”å› ${statusCode}ï¼Œä½†æœªèƒ½ç§»é™¤ Droid API Key ${selectedAccountApiKey.id}ï¼ˆAccount: ${accountId}ï¼‰`
          )
        }

        if (!removalResult || removalResult.remainingCount === 0) {
          await this._stopDroidAccountScheduling(accountId, statusCode, 'API Key å·²å…¨éƒ¨å¤±æ•ˆ')
          await this._clearAccountStickyMapping(normalizedEndpoint, sessionHash, clientApiKeyId)
        } else {
          logger.info(
            `â„¹ï¸ Droid è´¦å· ${accountId} ä»æœ‰ ${removalResult.remainingCount} ä¸ª API Key å¯ç”¨`
          )
        }

        return
      }

      logger.warn(
        `âš ï¸ ä¸Šæ¸¸è¿”å› ${statusCode}ï¼Œä½†æœªè·å–åˆ°å¯¹åº”çš„ Droid API Keyï¼ˆAccount: ${accountId}ï¼‰`
      )
      await this._stopDroidAccountScheduling(accountId, statusCode, 'ç¼ºå°‘å¯ç”¨ API Key')
      await this._clearAccountStickyMapping(normalizedEndpoint, sessionHash, clientApiKeyId)
      return
    }

    await this._stopDroidAccountScheduling(accountId, statusCode, 'å‡­è¯ä¸å¯ç”¨')
    await this._clearAccountStickyMapping(normalizedEndpoint, sessionHash, clientApiKeyId)
  }

  /**
   * åœæ­¢æŒ‡å®š Droid è´¦å·çš„è°ƒåº¦
   */
  async _stopDroidAccountScheduling(accountId, statusCode, reason = '') {
    if (!accountId) {
      return
    }

    const message = reason ? `${reason}` : 'ä¸Šæ¸¸è¿”å› 4xx é”™è¯¯'

    try {
      await droidAccountService.updateAccount(accountId, {
        schedulable: 'false',
        status: 'error',
        errorMessage: `ä¸Šæ¸¸è¿”å› ${statusCode}ï¼š${message}`
      })
      logger.warn(`ğŸš« å·²åœæ­¢è°ƒåº¦ Droid è´¦å· ${accountId}ï¼ˆçŠ¶æ€ç  ${statusCode}ï¼ŒåŸå› ï¼š${message}ï¼‰`)
    } catch (error) {
      logger.error(`âŒ åœæ­¢è°ƒåº¦ Droid è´¦å·å¤±è´¥ï¼š${accountId}`, error)
    }
  }

  /**
   * æ¸…ç†è´¦å·å±‚é¢çš„ç²˜æ€§è°ƒåº¦æ˜ å°„
   */
  async _clearAccountStickyMapping(endpointType, sessionHash, clientApiKeyId) {
    if (!sessionHash) {
      return
    }

    const normalizedEndpoint = this._normalizeEndpointType(endpointType)
    const apiKeyPart = clientApiKeyId || 'default'
    const stickyKey = `droid:${normalizedEndpoint}:${apiKeyPart}:${sessionHash}`

    try {
      await redis.deleteSessionAccountMapping(stickyKey)
      logger.debug(`ğŸ§¹ å·²æ¸…ç† Droid ç²˜æ€§ä¼šè¯æ˜ å°„ï¼š${stickyKey}`)
    } catch (error) {
      logger.warn(`âš ï¸ æ¸…ç† Droid ç²˜æ€§ä¼šè¯æ˜ å°„å¤±è´¥ï¼š${stickyKey}`, error)
    }
  }

  /**
   * æ¸…ç† API Key çº§åˆ«çš„ç²˜æ€§æ˜ å°„
   */
  async _clearApiKeyStickyMapping(accountId, endpointType, sessionHash) {
    if (!accountId || !sessionHash) {
      return
    }

    try {
      const stickyKey = this._composeApiKeyStickyKey(accountId, endpointType, sessionHash)
      if (stickyKey) {
        await redis.deleteSessionAccountMapping(stickyKey)
        logger.debug(`ğŸ§¹ å·²æ¸…ç† Droid API Key ç²˜æ€§æ˜ å°„ï¼š${stickyKey}`)
      }
    } catch (error) {
      logger.warn(
        `âš ï¸ æ¸…ç† Droid API Key ç²˜æ€§æ˜ å°„å¤±è´¥ï¼š${accountId}ï¼ˆendpoint: ${endpointType}ï¼‰`,
        error
      )
    }
  }

  _mapNetworkErrorStatus(error) {
    const code = (error && error.code ? String(error.code) : '').toUpperCase()

    if (code === 'ECONNABORTED' || code === 'ETIMEDOUT') {
      return 408
    }

    if (code === 'ECONNRESET' || code === 'EPIPE') {
      return 424
    }

    if (code === 'ENOTFOUND' || code === 'EAI_AGAIN') {
      return 424
    }

    if (typeof error === 'object' && error !== null) {
      const message = (error.message || '').toLowerCase()
      if (message.includes('timeout')) {
        return 408
      }
    }

    return 424
  }

  _buildNetworkErrorBody(error) {
    const body = {
      error: 'relay_upstream_failure',
      message: error?.message || 'ä¸Šæ¸¸è¯·æ±‚å¤±è´¥'
    }

    if (error?.code) {
      body.code = error.code
    }

    if (error?.config?.url) {
      body.upstream = error.config.url
    }

    return body
  }

  /**
   * ç”Ÿæˆ UUID
   */
  _generateUUID() {
    return 'xxxxxxxx-xxxx-4xxx-yxxx-xxxxxxxxxxxx'.replace(/[xy]/g, (c) => {
      const r = (Math.random() * 16) | 0
      const v = c === 'x' ? r : (r & 0x3) | 0x8
      return v.toString(16)
    })
  }
}

// å¯¼å‡ºå•ä¾‹
module.exports = new DroidRelayService()
