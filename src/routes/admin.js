const express = require('express')
const apiKeyService = require('../services/apiKeyService')
const claudeAccountService = require('../services/claudeAccountService')
const claudeConsoleAccountService = require('../services/claudeConsoleAccountService')
const bedrockAccountService = require('../services/bedrockAccountService')
const geminiAccountService = require('../services/geminiAccountService')
const openaiAccountService = require('../services/openaiAccountService')
const azureOpenaiAccountService = require('../services/azureOpenaiAccountService')
const accountGroupService = require('../services/accountGroupService')
const redis = require('../models/redis')
const { authenticateAdmin } = require('../middleware/auth')
const logger = require('../utils/logger')
const oauthHelper = require('../utils/oauthHelper')
const CostCalculator = require('../utils/costCalculator')
const pricingService = require('../services/pricingService')
const claudeCodeHeadersService = require('../services/claudeCodeHeadersService')
const webhookNotifier = require('../utils/webhookNotifier')
const axios = require('axios')
const crypto = require('crypto')
const fs = require('fs')
const path = require('path')
const config = require('../../config/config')
const ProxyHelper = require('../utils/proxyHelper')

const router = express.Router()

// ğŸ”‘ API Keys ç®¡ç†

// è°ƒè¯•ï¼šè·å–API Keyè´¹ç”¨è¯¦æƒ…
router.get('/api-keys/:keyId/cost-debug', authenticateAdmin, async (req, res) => {
  try {
    const { keyId } = req.params
    const costStats = await redis.getCostStats(keyId)
    const dailyCost = await redis.getDailyCost(keyId)
    const today = redis.getDateStringInTimezone()
    const client = redis.getClientSafe()

    // è·å–æ‰€æœ‰ç›¸å…³çš„Redisé”®
    const costKeys = await client.keys(`usage:cost:*:${keyId}:*`)
    const keyValues = {}

    for (const key of costKeys) {
      keyValues[key] = await client.get(key)
    }

    return res.json({
      keyId,
      today,
      dailyCost,
      costStats,
      redisKeys: keyValues,
      timezone: config.system.timezoneOffset || 8
    })
  } catch (error) {
    logger.error('âŒ Failed to get cost debug info:', error)
    return res.status(500).json({ error: 'Failed to get cost debug info', message: error.message })
  }
})

// è·å–æ‰€æœ‰API Keys
router.get('/api-keys', authenticateAdmin, async (req, res) => {
  try {
    const { timeRange = 'all' } = req.query // all, 7days, monthly
    const apiKeys = await apiKeyService.getAllApiKeys()

    // æ ¹æ®æ—¶é—´èŒƒå›´è®¡ç®—æŸ¥è¯¢æ¨¡å¼
    const now = new Date()
    const searchPatterns = []

    if (timeRange === 'today') {
      // ä»Šæ—¥ - ä½¿ç”¨æ—¶åŒºæ—¥æœŸ
      const redisClient = require('../models/redis')
      const tzDate = redisClient.getDateInTimezone(now)
      const dateStr = `${tzDate.getUTCFullYear()}-${String(tzDate.getUTCMonth() + 1).padStart(2, '0')}-${String(tzDate.getUTCDate()).padStart(2, '0')}`
      searchPatterns.push(`usage:daily:*:${dateStr}`)
    } else if (timeRange === '7days') {
      // æœ€è¿‘7å¤©
      const redisClient = require('../models/redis')
      for (let i = 0; i < 7; i++) {
        const date = new Date(now)
        date.setDate(date.getDate() - i)
        const tzDate = redisClient.getDateInTimezone(date)
        const dateStr = `${tzDate.getUTCFullYear()}-${String(tzDate.getUTCMonth() + 1).padStart(2, '0')}-${String(tzDate.getUTCDate()).padStart(2, '0')}`
        searchPatterns.push(`usage:daily:*:${dateStr}`)
      }
    } else if (timeRange === 'monthly') {
      // æœ¬æœˆ
      const redisClient = require('../models/redis')
      const tzDate = redisClient.getDateInTimezone(now)
      const currentMonth = `${tzDate.getUTCFullYear()}-${String(tzDate.getUTCMonth() + 1).padStart(2, '0')}`
      searchPatterns.push(`usage:monthly:*:${currentMonth}`)
    }

    // ä¸ºæ¯ä¸ªAPI Keyè®¡ç®—å‡†ç¡®çš„è´¹ç”¨å’Œç»Ÿè®¡æ•°æ®
    for (const apiKey of apiKeys) {
      const client = redis.getClientSafe()

      if (timeRange === 'all') {
        // å…¨éƒ¨æ—¶é—´ï¼šä¿æŒåŸæœ‰é€»è¾‘
        if (apiKey.usage && apiKey.usage.total) {
          // ä½¿ç”¨ä¸å±•å¼€æ¨¡å‹ç»Ÿè®¡ç›¸åŒçš„æ•°æ®æº
          // è·å–æ‰€æœ‰æ—¶é—´çš„æ¨¡å‹ç»Ÿè®¡æ•°æ®
          const monthlyKeys = await client.keys(`usage:${apiKey.id}:model:monthly:*:*`)
          const modelStatsMap = new Map()

          // æ±‡æ€»æ‰€æœ‰æœˆä»½çš„æ•°æ®
          for (const key of monthlyKeys) {
            const match = key.match(/usage:.+:model:monthly:(.+):\d{4}-\d{2}$/)
            if (!match) {
              continue
            }

            const model = match[1]
            const data = await client.hgetall(key)

            if (data && Object.keys(data).length > 0) {
              if (!modelStatsMap.has(model)) {
                modelStatsMap.set(model, {
                  inputTokens: 0,
                  outputTokens: 0,
                  cacheCreateTokens: 0,
                  cacheReadTokens: 0
                })
              }

              const stats = modelStatsMap.get(model)
              stats.inputTokens +=
                parseInt(data.totalInputTokens) || parseInt(data.inputTokens) || 0
              stats.outputTokens +=
                parseInt(data.totalOutputTokens) || parseInt(data.outputTokens) || 0
              stats.cacheCreateTokens +=
                parseInt(data.totalCacheCreateTokens) || parseInt(data.cacheCreateTokens) || 0
              stats.cacheReadTokens +=
                parseInt(data.totalCacheReadTokens) || parseInt(data.cacheReadTokens) || 0
            }
          }

          let totalCost = 0

          // è®¡ç®—æ¯ä¸ªæ¨¡å‹çš„è´¹ç”¨
          for (const [model, stats] of modelStatsMap) {
            const usage = {
              input_tokens: stats.inputTokens,
              output_tokens: stats.outputTokens,
              cache_creation_input_tokens: stats.cacheCreateTokens,
              cache_read_input_tokens: stats.cacheReadTokens
            }

            const costResult = CostCalculator.calculateCost(usage, model)
            totalCost += costResult.costs.total
          }

          // å¦‚æœæ²¡æœ‰è¯¦ç»†çš„æ¨¡å‹æ•°æ®ï¼Œä½¿ç”¨æ€»é‡æ•°æ®å’Œé»˜è®¤æ¨¡å‹è®¡ç®—
          if (modelStatsMap.size === 0) {
            const usage = {
              input_tokens: apiKey.usage.total.inputTokens || 0,
              output_tokens: apiKey.usage.total.outputTokens || 0,
              cache_creation_input_tokens: apiKey.usage.total.cacheCreateTokens || 0,
              cache_read_input_tokens: apiKey.usage.total.cacheReadTokens || 0
            }

            const costResult = CostCalculator.calculateCost(usage, 'claude-3-5-haiku-20241022')
            totalCost = costResult.costs.total
          }

          // æ·»åŠ æ ¼å¼åŒ–çš„è´¹ç”¨åˆ°å“åº”æ•°æ®
          apiKey.usage.total.cost = totalCost
          apiKey.usage.total.formattedCost = CostCalculator.formatCost(totalCost)
        }
      } else {
        // 7å¤©æˆ–æœ¬æœˆï¼šé‡æ–°è®¡ç®—ç»Ÿè®¡æ•°æ®
        const tempUsage = {
          requests: 0,
          tokens: 0,
          allTokens: 0, // æ·»åŠ allTokenså­—æ®µ
          inputTokens: 0,
          outputTokens: 0,
          cacheCreateTokens: 0,
          cacheReadTokens: 0
        }

        // è·å–æŒ‡å®šæ—¶é—´èŒƒå›´çš„ç»Ÿè®¡æ•°æ®
        for (const pattern of searchPatterns) {
          const keys = await client.keys(pattern.replace('*', apiKey.id))

          for (const key of keys) {
            const data = await client.hgetall(key)
            if (data && Object.keys(data).length > 0) {
              // ä½¿ç”¨ä¸ redis.js incrementTokenUsage ä¸­ç›¸åŒçš„å­—æ®µå
              tempUsage.requests += parseInt(data.totalRequests) || parseInt(data.requests) || 0
              tempUsage.tokens += parseInt(data.totalTokens) || parseInt(data.tokens) || 0
              tempUsage.allTokens += parseInt(data.totalAllTokens) || parseInt(data.allTokens) || 0 // è¯»å–åŒ…å«æ‰€æœ‰Tokençš„å­—æ®µ
              tempUsage.inputTokens +=
                parseInt(data.totalInputTokens) || parseInt(data.inputTokens) || 0
              tempUsage.outputTokens +=
                parseInt(data.totalOutputTokens) || parseInt(data.outputTokens) || 0
              tempUsage.cacheCreateTokens +=
                parseInt(data.totalCacheCreateTokens) || parseInt(data.cacheCreateTokens) || 0
              tempUsage.cacheReadTokens +=
                parseInt(data.totalCacheReadTokens) || parseInt(data.cacheReadTokens) || 0
            }
          }
        }

        // è®¡ç®—æŒ‡å®šæ—¶é—´èŒƒå›´çš„è´¹ç”¨
        let totalCost = 0
        const redisClient = require('../models/redis')
        const tzToday = redisClient.getDateStringInTimezone(now)
        const tzDate = redisClient.getDateInTimezone(now)
        const tzMonth = `${tzDate.getUTCFullYear()}-${String(tzDate.getUTCMonth() + 1).padStart(2, '0')}`

        const modelKeys =
          timeRange === 'today'
            ? await client.keys(`usage:${apiKey.id}:model:daily:*:${tzToday}`)
            : timeRange === '7days'
              ? await client.keys(`usage:${apiKey.id}:model:daily:*:*`)
              : await client.keys(`usage:${apiKey.id}:model:monthly:*:${tzMonth}`)

        const modelStatsMap = new Map()

        // è¿‡æ»¤å’Œæ±‡æ€»ç›¸åº”æ—¶é—´èŒƒå›´çš„æ¨¡å‹æ•°æ®
        for (const key of modelKeys) {
          if (timeRange === '7days') {
            // æ£€æŸ¥æ˜¯å¦åœ¨æœ€è¿‘7å¤©å†…
            const dateMatch = key.match(/\d{4}-\d{2}-\d{2}$/)
            if (dateMatch) {
              const keyDate = new Date(dateMatch[0])
              const daysDiff = Math.floor((now - keyDate) / (1000 * 60 * 60 * 24))
              if (daysDiff > 6) {
                continue
              }
            }
          } else if (timeRange === 'today') {
            // todayé€‰é¡¹å·²ç»åœ¨æŸ¥è¯¢æ—¶è¿‡æ»¤äº†ï¼Œä¸éœ€è¦é¢å¤–å¤„ç†
          }

          const modelMatch = key.match(
            /usage:.+:model:(?:daily|monthly):(.+):\d{4}-\d{2}(?:-\d{2})?$/
          )
          if (!modelMatch) {
            continue
          }

          const model = modelMatch[1]
          const data = await client.hgetall(key)

          if (data && Object.keys(data).length > 0) {
            if (!modelStatsMap.has(model)) {
              modelStatsMap.set(model, {
                inputTokens: 0,
                outputTokens: 0,
                cacheCreateTokens: 0,
                cacheReadTokens: 0
              })
            }

            const stats = modelStatsMap.get(model)
            stats.inputTokens += parseInt(data.totalInputTokens) || parseInt(data.inputTokens) || 0
            stats.outputTokens +=
              parseInt(data.totalOutputTokens) || parseInt(data.outputTokens) || 0
            stats.cacheCreateTokens +=
              parseInt(data.totalCacheCreateTokens) || parseInt(data.cacheCreateTokens) || 0
            stats.cacheReadTokens +=
              parseInt(data.totalCacheReadTokens) || parseInt(data.cacheReadTokens) || 0
          }
        }

        // è®¡ç®—è´¹ç”¨
        for (const [model, stats] of modelStatsMap) {
          const usage = {
            input_tokens: stats.inputTokens,
            output_tokens: stats.outputTokens,
            cache_creation_input_tokens: stats.cacheCreateTokens,
            cache_read_input_tokens: stats.cacheReadTokens
          }

          const costResult = CostCalculator.calculateCost(usage, model)
          totalCost += costResult.costs.total
        }

        // å¦‚æœæ²¡æœ‰æ¨¡å‹æ•°æ®ï¼Œä½¿ç”¨ä¸´æ—¶ç»Ÿè®¡æ•°æ®è®¡ç®—
        if (modelStatsMap.size === 0 && tempUsage.tokens > 0) {
          const usage = {
            input_tokens: tempUsage.inputTokens,
            output_tokens: tempUsage.outputTokens,
            cache_creation_input_tokens: tempUsage.cacheCreateTokens,
            cache_read_input_tokens: tempUsage.cacheReadTokens
          }

          const costResult = CostCalculator.calculateCost(usage, 'claude-3-5-haiku-20241022')
          totalCost = costResult.costs.total
        }

        // ä½¿ç”¨ä»Redisè¯»å–çš„allTokensï¼Œå¦‚æœæ²¡æœ‰åˆ™è®¡ç®—
        const allTokens =
          tempUsage.allTokens ||
          tempUsage.inputTokens +
            tempUsage.outputTokens +
            tempUsage.cacheCreateTokens +
            tempUsage.cacheReadTokens

        // æ›´æ–°API Keyçš„usageæ•°æ®ä¸ºæŒ‡å®šæ—¶é—´èŒƒå›´çš„æ•°æ®
        apiKey.usage[timeRange] = {
          ...tempUsage,
          tokens: allTokens, // ä½¿ç”¨åŒ…å«æ‰€æœ‰Tokençš„æ€»æ•°
          allTokens,
          cost: totalCost,
          formattedCost: CostCalculator.formatCost(totalCost)
        }

        // ä¸ºäº†ä¿æŒå…¼å®¹æ€§ï¼Œä¹Ÿæ›´æ–°totalå­—æ®µ
        apiKey.usage.total = apiKey.usage[timeRange]
      }
    }

    return res.json({ success: true, data: apiKeys })
  } catch (error) {
    logger.error('âŒ Failed to get API keys:', error)
    return res.status(500).json({ error: 'Failed to get API keys', message: error.message })
  }
})

// è·å–æ”¯æŒçš„å®¢æˆ·ç«¯åˆ—è¡¨
router.get('/supported-clients', authenticateAdmin, async (req, res) => {
  try {
    // æ£€æŸ¥é…ç½®æ˜¯å¦å­˜åœ¨ï¼Œå¦‚æœä¸å­˜åœ¨åˆ™ä½¿ç”¨é»˜è®¤å€¼
    const predefinedClients = config.clientRestrictions?.predefinedClients || [
      {
        id: 'claude_code',
        name: 'ClaudeCode',
        description: 'Official Claude Code CLI'
      },
      {
        id: 'gemini_cli',
        name: 'Gemini-CLI',
        description: 'Gemini Command Line Interface'
      }
    ]

    const clients = predefinedClients.map((client) => ({
      id: client.id,
      name: client.name,
      description: client.description
    }))

    return res.json({ success: true, data: clients })
  } catch (error) {
    logger.error('âŒ Failed to get supported clients:', error)
    return res
      .status(500)
      .json({ error: 'Failed to get supported clients', message: error.message })
  }
})

// è·å–å·²å­˜åœ¨çš„æ ‡ç­¾åˆ—è¡¨
router.get('/api-keys/tags', authenticateAdmin, async (req, res) => {
  try {
    const apiKeys = await apiKeyService.getAllApiKeys()
    const tagSet = new Set()

    // æ”¶é›†æ‰€æœ‰API Keysçš„æ ‡ç­¾
    for (const apiKey of apiKeys) {
      if (apiKey.tags && Array.isArray(apiKey.tags)) {
        apiKey.tags.forEach((tag) => {
          if (tag && tag.trim()) {
            tagSet.add(tag.trim())
          }
        })
      }
    }

    // è½¬æ¢ä¸ºæ•°ç»„å¹¶æ’åº
    const tags = Array.from(tagSet).sort()

    logger.info(`ğŸ“‹ Retrieved ${tags.length} unique tags from API keys`)
    return res.json({ success: true, data: tags })
  } catch (error) {
    logger.error('âŒ Failed to get API key tags:', error)
    return res.status(500).json({ error: 'Failed to get API key tags', message: error.message })
  }
})

// åˆ›å»ºæ–°çš„API Key
router.post('/api-keys', authenticateAdmin, async (req, res) => {
  try {
    const {
      name,
      description,
      tokenLimit,
      expiresAt,
      claudeAccountId,
      claudeConsoleAccountId,
      geminiAccountId,
      openaiAccountId,
      bedrockAccountId,
      permissions,
      concurrencyLimit,
      rateLimitWindow,
      rateLimitRequests,
      enableModelRestriction,
      restrictedModels,
      enableClientRestriction,
      allowedClients,
      dailyCostLimit,
      tags
    } = req.body

    // è¾“å…¥éªŒè¯
    if (!name || typeof name !== 'string' || name.trim().length === 0) {
      return res.status(400).json({ error: 'Name is required and must be a non-empty string' })
    }

    if (name.length > 100) {
      return res.status(400).json({ error: 'Name must be less than 100 characters' })
    }

    if (description && (typeof description !== 'string' || description.length > 500)) {
      return res
        .status(400)
        .json({ error: 'Description must be a string with less than 500 characters' })
    }

    if (tokenLimit && (!Number.isInteger(Number(tokenLimit)) || Number(tokenLimit) < 0)) {
      return res.status(400).json({ error: 'Token limit must be a non-negative integer' })
    }

    if (
      concurrencyLimit !== undefined &&
      concurrencyLimit !== null &&
      concurrencyLimit !== '' &&
      (!Number.isInteger(Number(concurrencyLimit)) || Number(concurrencyLimit) < 0)
    ) {
      return res.status(400).json({ error: 'Concurrency limit must be a non-negative integer' })
    }

    if (
      rateLimitWindow !== undefined &&
      rateLimitWindow !== null &&
      rateLimitWindow !== '' &&
      (!Number.isInteger(Number(rateLimitWindow)) || Number(rateLimitWindow) < 1)
    ) {
      return res
        .status(400)
        .json({ error: 'Rate limit window must be a positive integer (minutes)' })
    }

    if (
      rateLimitRequests !== undefined &&
      rateLimitRequests !== null &&
      rateLimitRequests !== '' &&
      (!Number.isInteger(Number(rateLimitRequests)) || Number(rateLimitRequests) < 1)
    ) {
      return res.status(400).json({ error: 'Rate limit requests must be a positive integer' })
    }

    // éªŒè¯æ¨¡å‹é™åˆ¶å­—æ®µ
    if (enableModelRestriction !== undefined && typeof enableModelRestriction !== 'boolean') {
      return res.status(400).json({ error: 'Enable model restriction must be a boolean' })
    }

    if (restrictedModels !== undefined && !Array.isArray(restrictedModels)) {
      return res.status(400).json({ error: 'Restricted models must be an array' })
    }

    // éªŒè¯å®¢æˆ·ç«¯é™åˆ¶å­—æ®µ
    if (enableClientRestriction !== undefined && typeof enableClientRestriction !== 'boolean') {
      return res.status(400).json({ error: 'Enable client restriction must be a boolean' })
    }

    if (allowedClients !== undefined && !Array.isArray(allowedClients)) {
      return res.status(400).json({ error: 'Allowed clients must be an array' })
    }

    // éªŒè¯æ ‡ç­¾å­—æ®µ
    if (tags !== undefined && !Array.isArray(tags)) {
      return res.status(400).json({ error: 'Tags must be an array' })
    }

    if (tags && tags.some((tag) => typeof tag !== 'string' || tag.trim().length === 0)) {
      return res.status(400).json({ error: 'All tags must be non-empty strings' })
    }

    const newKey = await apiKeyService.generateApiKey({
      name,
      description,
      tokenLimit,
      expiresAt,
      claudeAccountId,
      claudeConsoleAccountId,
      geminiAccountId,
      openaiAccountId,
      bedrockAccountId,
      permissions,
      concurrencyLimit,
      rateLimitWindow,
      rateLimitRequests,
      enableModelRestriction,
      restrictedModels,
      enableClientRestriction,
      allowedClients,
      dailyCostLimit,
      tags
    })

    logger.success(`ğŸ”‘ Admin created new API key: ${name}`)
    return res.json({ success: true, data: newKey })
  } catch (error) {
    logger.error('âŒ Failed to create API key:', error)
    return res.status(500).json({ error: 'Failed to create API key', message: error.message })
  }
})

// æ‰¹é‡åˆ›å»ºAPI Keys
router.post('/api-keys/batch', authenticateAdmin, async (req, res) => {
  try {
    const {
      baseName,
      count,
      description,
      tokenLimit,
      expiresAt,
      claudeAccountId,
      claudeConsoleAccountId,
      geminiAccountId,
      openaiAccountId,
      permissions,
      concurrencyLimit,
      rateLimitWindow,
      rateLimitRequests,
      enableModelRestriction,
      restrictedModels,
      enableClientRestriction,
      allowedClients,
      dailyCostLimit,
      tags
    } = req.body

    // è¾“å…¥éªŒè¯
    if (!baseName || typeof baseName !== 'string' || baseName.trim().length === 0) {
      return res.status(400).json({ error: 'Base name is required and must be a non-empty string' })
    }

    if (!count || !Number.isInteger(count) || count < 2 || count > 500) {
      return res.status(400).json({ error: 'Count must be an integer between 2 and 500' })
    }

    if (baseName.length > 90) {
      return res
        .status(400)
        .json({ error: 'Base name must be less than 90 characters to allow for numbering' })
    }

    // ç”Ÿæˆæ‰¹é‡API Keys
    const createdKeys = []
    const errors = []

    for (let i = 1; i <= count; i++) {
      try {
        const name = `${baseName}_${i}`
        const newKey = await apiKeyService.generateApiKey({
          name,
          description,
          tokenLimit,
          expiresAt,
          claudeAccountId,
          claudeConsoleAccountId,
          geminiAccountId,
          openaiAccountId,
          permissions,
          concurrencyLimit,
          rateLimitWindow,
          rateLimitRequests,
          enableModelRestriction,
          restrictedModels,
          enableClientRestriction,
          allowedClients,
          dailyCostLimit,
          tags
        })

        // ä¿ç•™åŸå§‹ API Key ä¾›è¿”å›
        createdKeys.push({
          ...newKey,
          apiKey: newKey.apiKey
        })
      } catch (error) {
        errors.push({
          index: i,
          name: `${baseName}_${i}`,
          error: error.message
        })
      }
    }

    // å¦‚æœæœ‰éƒ¨åˆ†å¤±è´¥ï¼Œè¿”å›éƒ¨åˆ†æˆåŠŸçš„ç»“æœ
    if (errors.length > 0 && createdKeys.length === 0) {
      return res.status(400).json({
        success: false,
        error: 'Failed to create any API keys',
        errors
      })
    }

    // è¿”å›åˆ›å»ºçš„keysï¼ˆåŒ…å«å®Œæ•´çš„apiKeyï¼‰
    return res.json({
      success: true,
      data: createdKeys,
      errors: errors.length > 0 ? errors : undefined,
      summary: {
        requested: count,
        created: createdKeys.length,
        failed: errors.length
      }
    })
  } catch (error) {
    logger.error('Failed to batch create API keys:', error)
    return res.status(500).json({
      success: false,
      error: 'Failed to batch create API keys',
      message: error.message
    })
  }
})

// æ‰¹é‡ç¼–è¾‘API Keys
router.put('/api-keys/batch', authenticateAdmin, async (req, res) => {
  try {
    const { keyIds, updates } = req.body

    if (!keyIds || !Array.isArray(keyIds) || keyIds.length === 0) {
      return res.status(400).json({
        error: 'Invalid input',
        message: 'keyIds must be a non-empty array'
      })
    }

    if (!updates || typeof updates !== 'object') {
      return res.status(400).json({
        error: 'Invalid input',
        message: 'updates must be an object'
      })
    }

    logger.info(
      `ğŸ”„ Admin batch editing ${keyIds.length} API keys with updates: ${JSON.stringify(updates)}`
    )
    logger.info(`ğŸ” Debug: keyIds received: ${JSON.stringify(keyIds)}`)

    const results = {
      successCount: 0,
      failedCount: 0,
      errors: []
    }

    // å¤„ç†æ¯ä¸ªAPI Key
    for (const keyId of keyIds) {
      try {
        // è·å–å½“å‰API Keyä¿¡æ¯
        const currentKey = await redis.getApiKey(keyId)
        if (!currentKey || Object.keys(currentKey).length === 0) {
          results.failedCount++
          results.errors.push(`API key ${keyId} not found`)
          continue
        }

        // æ„å»ºæœ€ç»ˆæ›´æ–°æ•°æ®
        const finalUpdates = {}

        // å¤„ç†æ™®é€šå­—æ®µ
        if (updates.name) {
          finalUpdates.name = updates.name
        }
        if (updates.tokenLimit !== undefined) {
          finalUpdates.tokenLimit = updates.tokenLimit
        }
        if (updates.concurrencyLimit !== undefined) {
          finalUpdates.concurrencyLimit = updates.concurrencyLimit
        }
        if (updates.rateLimitWindow !== undefined) {
          finalUpdates.rateLimitWindow = updates.rateLimitWindow
        }
        if (updates.rateLimitRequests !== undefined) {
          finalUpdates.rateLimitRequests = updates.rateLimitRequests
        }
        if (updates.dailyCostLimit !== undefined) {
          finalUpdates.dailyCostLimit = updates.dailyCostLimit
        }
        if (updates.permissions !== undefined) {
          finalUpdates.permissions = updates.permissions
        }
        if (updates.isActive !== undefined) {
          finalUpdates.isActive = updates.isActive
        }
        if (updates.monthlyLimit !== undefined) {
          finalUpdates.monthlyLimit = updates.monthlyLimit
        }
        if (updates.priority !== undefined) {
          finalUpdates.priority = updates.priority
        }
        if (updates.enabled !== undefined) {
          finalUpdates.enabled = updates.enabled
        }

        // å¤„ç†è´¦æˆ·ç»‘å®š
        if (updates.claudeAccountId !== undefined) {
          finalUpdates.claudeAccountId = updates.claudeAccountId
        }
        if (updates.claudeConsoleAccountId !== undefined) {
          finalUpdates.claudeConsoleAccountId = updates.claudeConsoleAccountId
        }
        if (updates.geminiAccountId !== undefined) {
          finalUpdates.geminiAccountId = updates.geminiAccountId
        }
        if (updates.openaiAccountId !== undefined) {
          finalUpdates.openaiAccountId = updates.openaiAccountId
        }
        if (updates.bedrockAccountId !== undefined) {
          finalUpdates.bedrockAccountId = updates.bedrockAccountId
        }

        // å¤„ç†æ ‡ç­¾æ“ä½œ
        if (updates.tags !== undefined) {
          if (updates.tagOperation) {
            const currentTags = currentKey.tags ? JSON.parse(currentKey.tags) : []
            const operationTags = updates.tags

            switch (updates.tagOperation) {
              case 'replace': {
                finalUpdates.tags = operationTags
                break
              }
              case 'add': {
                const newTags = [...currentTags]
                operationTags.forEach((tag) => {
                  if (!newTags.includes(tag)) {
                    newTags.push(tag)
                  }
                })
                finalUpdates.tags = newTags
                break
              }
              case 'remove': {
                finalUpdates.tags = currentTags.filter((tag) => !operationTags.includes(tag))
                break
              }
            }
          } else {
            // å¦‚æœæ²¡æœ‰æŒ‡å®šæ“ä½œç±»å‹ï¼Œé»˜è®¤ä¸ºæ›¿æ¢
            finalUpdates.tags = updates.tags
          }
        }

        // æ‰§è¡Œæ›´æ–°
        await apiKeyService.updateApiKey(keyId, finalUpdates)
        results.successCount++
        logger.success(`âœ… Batch edit: API key ${keyId} updated successfully`)
      } catch (error) {
        results.failedCount++
        results.errors.push(`Failed to update key ${keyId}: ${error.message}`)
        logger.error(`âŒ Batch edit failed for key ${keyId}:`, error)
      }
    }

    // è®°å½•æ‰¹é‡ç¼–è¾‘ç»“æœ
    if (results.successCount > 0) {
      logger.success(
        `ğŸ‰ Batch edit completed: ${results.successCount} successful, ${results.failedCount} failed`
      )
    } else {
      logger.warn(
        `âš ï¸ Batch edit completed with no successful updates: ${results.failedCount} failed`
      )
    }

    return res.json({
      success: true,
      message: `æ‰¹é‡ç¼–è¾‘å®Œæˆ`,
      data: results
    })
  } catch (error) {
    logger.error('âŒ Failed to batch edit API keys:', error)
    return res.status(500).json({
      error: 'Batch edit failed',
      message: error.message
    })
  }
})

// æ›´æ–°API Key
router.put('/api-keys/:keyId', authenticateAdmin, async (req, res) => {
  try {
    const { keyId } = req.params
    const {
      tokenLimit,
      concurrencyLimit,
      rateLimitWindow,
      rateLimitRequests,
      isActive,
      claudeAccountId,
      claudeConsoleAccountId,
      geminiAccountId,
      openaiAccountId,
      bedrockAccountId,
      permissions,
      enableModelRestriction,
      restrictedModels,
      enableClientRestriction,
      allowedClients,
      expiresAt,
      dailyCostLimit,
      tags
    } = req.body

    // åªå…è®¸æ›´æ–°æŒ‡å®šå­—æ®µ
    const updates = {}

    if (tokenLimit !== undefined && tokenLimit !== null && tokenLimit !== '') {
      if (!Number.isInteger(Number(tokenLimit)) || Number(tokenLimit) < 0) {
        return res.status(400).json({ error: 'Token limit must be a non-negative integer' })
      }
      updates.tokenLimit = Number(tokenLimit)
    }

    if (concurrencyLimit !== undefined && concurrencyLimit !== null && concurrencyLimit !== '') {
      if (!Number.isInteger(Number(concurrencyLimit)) || Number(concurrencyLimit) < 0) {
        return res.status(400).json({ error: 'Concurrency limit must be a non-negative integer' })
      }
      updates.concurrencyLimit = Number(concurrencyLimit)
    }

    if (rateLimitWindow !== undefined && rateLimitWindow !== null && rateLimitWindow !== '') {
      if (!Number.isInteger(Number(rateLimitWindow)) || Number(rateLimitWindow) < 0) {
        return res
          .status(400)
          .json({ error: 'Rate limit window must be a non-negative integer (minutes)' })
      }
      updates.rateLimitWindow = Number(rateLimitWindow)
    }

    if (rateLimitRequests !== undefined && rateLimitRequests !== null && rateLimitRequests !== '') {
      if (!Number.isInteger(Number(rateLimitRequests)) || Number(rateLimitRequests) < 0) {
        return res.status(400).json({ error: 'Rate limit requests must be a non-negative integer' })
      }
      updates.rateLimitRequests = Number(rateLimitRequests)
    }

    if (claudeAccountId !== undefined) {
      // ç©ºå­—ç¬¦ä¸²è¡¨ç¤ºè§£ç»‘ï¼Œnullæˆ–ç©ºå­—ç¬¦ä¸²éƒ½è®¾ç½®ä¸ºç©ºå­—ç¬¦ä¸²
      updates.claudeAccountId = claudeAccountId || ''
    }

    if (claudeConsoleAccountId !== undefined) {
      // ç©ºå­—ç¬¦ä¸²è¡¨ç¤ºè§£ç»‘ï¼Œnullæˆ–ç©ºå­—ç¬¦ä¸²éƒ½è®¾ç½®ä¸ºç©ºå­—ç¬¦ä¸²
      updates.claudeConsoleAccountId = claudeConsoleAccountId || ''
    }

    if (geminiAccountId !== undefined) {
      // ç©ºå­—ç¬¦ä¸²è¡¨ç¤ºè§£ç»‘ï¼Œnullæˆ–ç©ºå­—ç¬¦ä¸²éƒ½è®¾ç½®ä¸ºç©ºå­—ç¬¦ä¸²
      updates.geminiAccountId = geminiAccountId || ''
    }

    if (openaiAccountId !== undefined) {
      // ç©ºå­—ç¬¦ä¸²è¡¨ç¤ºè§£ç»‘ï¼Œnullæˆ–ç©ºå­—ç¬¦ä¸²éƒ½è®¾ç½®ä¸ºç©ºå­—ç¬¦ä¸²
      updates.openaiAccountId = openaiAccountId || ''
    }

    if (bedrockAccountId !== undefined) {
      // ç©ºå­—ç¬¦ä¸²è¡¨ç¤ºè§£ç»‘ï¼Œnullæˆ–ç©ºå­—ç¬¦ä¸²éƒ½è®¾ç½®ä¸ºç©ºå­—ç¬¦ä¸²
      updates.bedrockAccountId = bedrockAccountId || ''
    }

    if (permissions !== undefined) {
      // éªŒè¯æƒé™å€¼
      if (!['claude', 'gemini', 'openai', 'all'].includes(permissions)) {
        return res
          .status(400)
          .json({ error: 'Invalid permissions value. Must be claude, gemini, openai, or all' })
      }
      updates.permissions = permissions
    }

    // å¤„ç†æ¨¡å‹é™åˆ¶å­—æ®µ
    if (enableModelRestriction !== undefined) {
      if (typeof enableModelRestriction !== 'boolean') {
        return res.status(400).json({ error: 'Enable model restriction must be a boolean' })
      }
      updates.enableModelRestriction = enableModelRestriction
    }

    if (restrictedModels !== undefined) {
      if (!Array.isArray(restrictedModels)) {
        return res.status(400).json({ error: 'Restricted models must be an array' })
      }
      updates.restrictedModels = restrictedModels
    }

    // å¤„ç†å®¢æˆ·ç«¯é™åˆ¶å­—æ®µ
    if (enableClientRestriction !== undefined) {
      if (typeof enableClientRestriction !== 'boolean') {
        return res.status(400).json({ error: 'Enable client restriction must be a boolean' })
      }
      updates.enableClientRestriction = enableClientRestriction
    }

    if (allowedClients !== undefined) {
      if (!Array.isArray(allowedClients)) {
        return res.status(400).json({ error: 'Allowed clients must be an array' })
      }
      updates.allowedClients = allowedClients
    }

    // å¤„ç†è¿‡æœŸæ—¶é—´å­—æ®µ
    if (expiresAt !== undefined) {
      if (expiresAt === null) {
        // null è¡¨ç¤ºæ°¸ä¸è¿‡æœŸ
        updates.expiresAt = null
        updates.isActive = true
      } else {
        // éªŒè¯æ—¥æœŸæ ¼å¼
        const expireDate = new Date(expiresAt)
        if (isNaN(expireDate.getTime())) {
          return res.status(400).json({ error: 'Invalid expiration date format' })
        }
        updates.expiresAt = expiresAt
        updates.isActive = expireDate > new Date() // å¦‚æœè¿‡æœŸæ—¶é—´åœ¨å½“å‰æ—¶é—´ä¹‹åï¼Œåˆ™è®¾ç½®ä¸ºæ¿€æ´»çŠ¶æ€
      }
    }

    // å¤„ç†æ¯æ—¥è´¹ç”¨é™åˆ¶
    if (dailyCostLimit !== undefined && dailyCostLimit !== null && dailyCostLimit !== '') {
      const costLimit = Number(dailyCostLimit)
      if (isNaN(costLimit) || costLimit < 0) {
        return res.status(400).json({ error: 'Daily cost limit must be a non-negative number' })
      }
      updates.dailyCostLimit = costLimit
    }

    // å¤„ç†æ ‡ç­¾
    if (tags !== undefined) {
      if (!Array.isArray(tags)) {
        return res.status(400).json({ error: 'Tags must be an array' })
      }
      if (tags.some((tag) => typeof tag !== 'string' || tag.trim().length === 0)) {
        return res.status(400).json({ error: 'All tags must be non-empty strings' })
      }
      updates.tags = tags
    }

    // å¤„ç†æ´»è·ƒ/ç¦ç”¨çŠ¶æ€çŠ¶æ€, æ”¾åœ¨è¿‡æœŸå¤„ç†åï¼Œä»¥ç¡®ä¿åç»­å¢åŠ ç¦ç”¨keyåŠŸèƒ½
    if (isActive !== undefined) {
      if (typeof isActive !== 'boolean') {
        return res.status(400).json({ error: 'isActive must be a boolean' })
      }
      updates.isActive = isActive
    }

    await apiKeyService.updateApiKey(keyId, updates)

    logger.success(`ğŸ“ Admin updated API key: ${keyId}`)
    return res.json({ success: true, message: 'API key updated successfully' })
  } catch (error) {
    logger.error('âŒ Failed to update API key:', error)
    return res.status(500).json({ error: 'Failed to update API key', message: error.message })
  }
})

// æ‰¹é‡åˆ é™¤API Keysï¼ˆå¿…é¡»åœ¨ :keyId è·¯ç”±ä¹‹å‰å®šä¹‰ï¼‰
router.delete('/api-keys/batch', authenticateAdmin, async (req, res) => {
  try {
    const { keyIds } = req.body

    // è°ƒè¯•ä¿¡æ¯
    logger.info(`ğŸ› Batch delete request body: ${JSON.stringify(req.body)}`)
    logger.info(`ğŸ› keyIds type: ${typeof keyIds}, value: ${JSON.stringify(keyIds)}`)

    // å‚æ•°éªŒè¯
    if (!keyIds || !Array.isArray(keyIds) || keyIds.length === 0) {
      logger.warn(
        `ğŸš¨ Invalid keyIds: ${JSON.stringify({ keyIds, type: typeof keyIds, isArray: Array.isArray(keyIds) })}`
      )
      return res.status(400).json({
        error: 'Invalid request',
        message: 'keyIds å¿…é¡»æ˜¯ä¸€ä¸ªéç©ºæ•°ç»„'
      })
    }

    if (keyIds.length > 100) {
      return res.status(400).json({
        error: 'Too many keys',
        message: 'æ¯æ¬¡æœ€å¤šåªèƒ½åˆ é™¤100ä¸ªAPI Keys'
      })
    }

    // éªŒè¯keyIdsæ ¼å¼
    const invalidKeys = keyIds.filter((id) => !id || typeof id !== 'string')
    if (invalidKeys.length > 0) {
      return res.status(400).json({
        error: 'Invalid key IDs',
        message: 'åŒ…å«æ— æ•ˆçš„API Key ID'
      })
    }

    logger.info(
      `ğŸ—‘ï¸ Admin attempting batch delete of ${keyIds.length} API keys: ${JSON.stringify(keyIds)}`
    )

    const results = {
      successCount: 0,
      failedCount: 0,
      errors: []
    }

    // é€ä¸ªåˆ é™¤ï¼Œè®°å½•æˆåŠŸå’Œå¤±è´¥æƒ…å†µ
    for (const keyId of keyIds) {
      try {
        // æ£€æŸ¥API Keyæ˜¯å¦å­˜åœ¨
        const apiKey = await redis.getApiKey(keyId)
        if (!apiKey || Object.keys(apiKey).length === 0) {
          results.failedCount++
          results.errors.push({ keyId, error: 'API Key ä¸å­˜åœ¨' })
          continue
        }

        // æ‰§è¡Œåˆ é™¤
        await apiKeyService.deleteApiKey(keyId)
        results.successCount++

        logger.success(`âœ… Batch delete: API key ${keyId} deleted successfully`)
      } catch (error) {
        results.failedCount++
        results.errors.push({
          keyId,
          error: error.message || 'åˆ é™¤å¤±è´¥'
        })

        logger.error(`âŒ Batch delete failed for key ${keyId}:`, error)
      }
    }

    // è®°å½•æ‰¹é‡åˆ é™¤ç»“æœ
    if (results.successCount > 0) {
      logger.success(
        `ğŸ‰ Batch delete completed: ${results.successCount} successful, ${results.failedCount} failed`
      )
    } else {
      logger.warn(
        `âš ï¸ Batch delete completed with no successful deletions: ${results.failedCount} failed`
      )
    }

    return res.json({
      success: true,
      message: `æ‰¹é‡åˆ é™¤å®Œæˆ`,
      data: results
    })
  } catch (error) {
    logger.error('âŒ Failed to batch delete API keys:', error)
    return res.status(500).json({
      error: 'Batch delete failed',
      message: error.message
    })
  }
})

// åˆ é™¤å•ä¸ªAPI Keyï¼ˆå¿…é¡»åœ¨æ‰¹é‡åˆ é™¤è·¯ç”±ä¹‹åå®šä¹‰ï¼‰
router.delete('/api-keys/:keyId', authenticateAdmin, async (req, res) => {
  try {
    const { keyId } = req.params

    await apiKeyService.deleteApiKey(keyId)

    logger.success(`ğŸ—‘ï¸ Admin deleted API key: ${keyId}`)
    return res.json({ success: true, message: 'API key deleted successfully' })
  } catch (error) {
    logger.error('âŒ Failed to delete API key:', error)
    return res.status(500).json({ error: 'Failed to delete API key', message: error.message })
  }
})

// ğŸ‘¥ è´¦æˆ·åˆ†ç»„ç®¡ç†

// åˆ›å»ºè´¦æˆ·åˆ†ç»„
router.post('/account-groups', authenticateAdmin, async (req, res) => {
  try {
    const { name, platform, description } = req.body

    const group = await accountGroupService.createGroup({
      name,
      platform,
      description
    })

    return res.json({ success: true, data: group })
  } catch (error) {
    logger.error('âŒ Failed to create account group:', error)
    return res.status(400).json({ error: error.message })
  }
})

// è·å–æ‰€æœ‰åˆ†ç»„
router.get('/account-groups', authenticateAdmin, async (req, res) => {
  try {
    const { platform } = req.query
    const groups = await accountGroupService.getAllGroups(platform)
    return res.json({ success: true, data: groups })
  } catch (error) {
    logger.error('âŒ Failed to get account groups:', error)
    return res.status(500).json({ error: error.message })
  }
})

// è·å–åˆ†ç»„è¯¦æƒ…
router.get('/account-groups/:groupId', authenticateAdmin, async (req, res) => {
  try {
    const { groupId } = req.params
    const group = await accountGroupService.getGroup(groupId)

    if (!group) {
      return res.status(404).json({ error: 'åˆ†ç»„ä¸å­˜åœ¨' })
    }

    return res.json({ success: true, data: group })
  } catch (error) {
    logger.error('âŒ Failed to get account group:', error)
    return res.status(500).json({ error: error.message })
  }
})

// æ›´æ–°åˆ†ç»„
router.put('/account-groups/:groupId', authenticateAdmin, async (req, res) => {
  try {
    const { groupId } = req.params
    const updates = req.body

    const updatedGroup = await accountGroupService.updateGroup(groupId, updates)
    return res.json({ success: true, data: updatedGroup })
  } catch (error) {
    logger.error('âŒ Failed to update account group:', error)
    return res.status(400).json({ error: error.message })
  }
})

// åˆ é™¤åˆ†ç»„
router.delete('/account-groups/:groupId', authenticateAdmin, async (req, res) => {
  try {
    const { groupId } = req.params
    await accountGroupService.deleteGroup(groupId)
    return res.json({ success: true, message: 'åˆ†ç»„åˆ é™¤æˆåŠŸ' })
  } catch (error) {
    logger.error('âŒ Failed to delete account group:', error)
    return res.status(400).json({ error: error.message })
  }
})

// è·å–åˆ†ç»„æˆå‘˜
router.get('/account-groups/:groupId/members', authenticateAdmin, async (req, res) => {
  try {
    const { groupId } = req.params
    const memberIds = await accountGroupService.getGroupMembers(groupId)

    // è·å–æˆå‘˜è¯¦ç»†ä¿¡æ¯
    const members = []
    for (const memberId of memberIds) {
      // å°è¯•ä»ä¸åŒçš„æœåŠ¡è·å–è´¦æˆ·ä¿¡æ¯
      let account = null

      // å…ˆå°è¯•Claude OAuthè´¦æˆ·
      account = await claudeAccountService.getAccount(memberId)

      // å¦‚æœæ‰¾ä¸åˆ°ï¼Œå°è¯•Claude Consoleè´¦æˆ·
      if (!account) {
        account = await claudeConsoleAccountService.getAccount(memberId)
      }

      // å¦‚æœè¿˜æ‰¾ä¸åˆ°ï¼Œå°è¯•Geminiè´¦æˆ·
      if (!account) {
        account = await geminiAccountService.getAccount(memberId)
      }

      // å¦‚æœè¿˜æ‰¾ä¸åˆ°ï¼Œå°è¯•OpenAIè´¦æˆ·
      if (!account) {
        account = await openaiAccountService.getAccount(memberId)
      }

      if (account) {
        members.push(account)
      }
    }

    return res.json({ success: true, data: members })
  } catch (error) {
    logger.error('âŒ Failed to get group members:', error)
    return res.status(500).json({ error: error.message })
  }
})

// ğŸ¢ Claude è´¦æˆ·ç®¡ç†

// ç”ŸæˆOAuthæˆæƒURL
router.post('/claude-accounts/generate-auth-url', authenticateAdmin, async (req, res) => {
  try {
    const { proxy } = req.body // æ¥æ”¶ä»£ç†é…ç½®
    const oauthParams = await oauthHelper.generateOAuthParams()

    // å°†codeVerifierå’Œstateä¸´æ—¶å­˜å‚¨åˆ°Redisï¼Œç”¨äºåç»­éªŒè¯
    const sessionId = require('crypto').randomUUID()
    await redis.setOAuthSession(sessionId, {
      codeVerifier: oauthParams.codeVerifier,
      state: oauthParams.state,
      codeChallenge: oauthParams.codeChallenge,
      proxy: proxy || null, // å­˜å‚¨ä»£ç†é…ç½®
      createdAt: new Date().toISOString(),
      expiresAt: new Date(Date.now() + 10 * 60 * 1000).toISOString() // 10åˆ†é’Ÿè¿‡æœŸ
    })

    logger.success('ğŸ”— Generated OAuth authorization URL with proxy support')
    return res.json({
      success: true,
      data: {
        authUrl: oauthParams.authUrl,
        sessionId,
        instructions: [
          '1. å¤åˆ¶ä¸Šé¢çš„é“¾æ¥åˆ°æµè§ˆå™¨ä¸­æ‰“å¼€',
          '2. ç™»å½•æ‚¨çš„ Anthropic è´¦æˆ·',
          '3. åŒæ„åº”ç”¨æƒé™',
          '4. å¤åˆ¶æµè§ˆå™¨åœ°å€æ ä¸­çš„å®Œæ•´ URL',
          '5. åœ¨æ·»åŠ è´¦æˆ·è¡¨å•ä¸­ç²˜è´´å®Œæ•´çš„å›è°ƒ URL å’Œæˆæƒç '
        ]
      }
    })
  } catch (error) {
    logger.error('âŒ Failed to generate OAuth URL:', error)
    return res.status(500).json({ error: 'Failed to generate OAuth URL', message: error.message })
  }
})

// éªŒè¯æˆæƒç å¹¶è·å–token
router.post('/claude-accounts/exchange-code', authenticateAdmin, async (req, res) => {
  try {
    const { sessionId, authorizationCode, callbackUrl } = req.body

    if (!sessionId || (!authorizationCode && !callbackUrl)) {
      return res
        .status(400)
        .json({ error: 'Session ID and authorization code (or callback URL) are required' })
    }

    // ä»Redisè·å–OAuthä¼šè¯ä¿¡æ¯
    const oauthSession = await redis.getOAuthSession(sessionId)
    if (!oauthSession) {
      return res.status(400).json({ error: 'Invalid or expired OAuth session' })
    }

    // æ£€æŸ¥ä¼šè¯æ˜¯å¦è¿‡æœŸ
    if (new Date() > new Date(oauthSession.expiresAt)) {
      await redis.deleteOAuthSession(sessionId)
      return res
        .status(400)
        .json({ error: 'OAuth session has expired, please generate a new authorization URL' })
    }

    // ç»Ÿä¸€å¤„ç†æˆæƒç è¾“å…¥ï¼ˆå¯èƒ½æ˜¯ç›´æ¥çš„codeæˆ–å®Œæ•´çš„å›è°ƒURLï¼‰
    let finalAuthCode
    const inputValue = callbackUrl || authorizationCode

    try {
      finalAuthCode = oauthHelper.parseCallbackUrl(inputValue)
    } catch (parseError) {
      return res
        .status(400)
        .json({ error: 'Failed to parse authorization input', message: parseError.message })
    }

    // äº¤æ¢è®¿é—®ä»¤ç‰Œ
    const tokenData = await oauthHelper.exchangeCodeForTokens(
      finalAuthCode,
      oauthSession.codeVerifier,
      oauthSession.state,
      oauthSession.proxy // ä¼ é€’ä»£ç†é…ç½®
    )

    // æ¸…ç†OAuthä¼šè¯
    await redis.deleteOAuthSession(sessionId)

    logger.success('ğŸ‰ Successfully exchanged authorization code for tokens')
    return res.json({
      success: true,
      data: {
        claudeAiOauth: tokenData
      }
    })
  } catch (error) {
    logger.error('âŒ Failed to exchange authorization code:', {
      error: error.message,
      sessionId: req.body.sessionId,
      // ä¸è®°å½•å®Œæ•´çš„æˆæƒç ï¼Œåªè®°å½•é•¿åº¦å’Œå‰å‡ ä¸ªå­—ç¬¦
      codeLength: req.body.callbackUrl
        ? req.body.callbackUrl.length
        : req.body.authorizationCode
          ? req.body.authorizationCode.length
          : 0,
      codePrefix: req.body.callbackUrl
        ? `${req.body.callbackUrl.substring(0, 10)}...`
        : req.body.authorizationCode
          ? `${req.body.authorizationCode.substring(0, 10)}...`
          : 'N/A'
    })
    return res
      .status(500)
      .json({ error: 'Failed to exchange authorization code', message: error.message })
  }
})

// ç”ŸæˆClaude setup-tokenæˆæƒURL
router.post('/claude-accounts/generate-setup-token-url', authenticateAdmin, async (req, res) => {
  try {
    const { proxy } = req.body // æ¥æ”¶ä»£ç†é…ç½®
    const setupTokenParams = await oauthHelper.generateSetupTokenParams()

    // å°†codeVerifierå’Œstateä¸´æ—¶å­˜å‚¨åˆ°Redisï¼Œç”¨äºåç»­éªŒè¯
    const sessionId = require('crypto').randomUUID()
    await redis.setOAuthSession(sessionId, {
      type: 'setup-token', // æ ‡è®°ä¸ºsetup-tokenç±»å‹
      codeVerifier: setupTokenParams.codeVerifier,
      state: setupTokenParams.state,
      codeChallenge: setupTokenParams.codeChallenge,
      proxy: proxy || null, // å­˜å‚¨ä»£ç†é…ç½®
      createdAt: new Date().toISOString(),
      expiresAt: new Date(Date.now() + 10 * 60 * 1000).toISOString() // 10åˆ†é’Ÿè¿‡æœŸ
    })

    logger.success('ğŸ”— Generated Setup Token authorization URL with proxy support')
    return res.json({
      success: true,
      data: {
        authUrl: setupTokenParams.authUrl,
        sessionId,
        instructions: [
          '1. å¤åˆ¶ä¸Šé¢çš„é“¾æ¥åˆ°æµè§ˆå™¨ä¸­æ‰“å¼€',
          '2. ç™»å½•æ‚¨çš„ Claude è´¦æˆ·å¹¶æˆæƒ Claude Code',
          '3. å®Œæˆæˆæƒåï¼Œä»è¿”å›é¡µé¢å¤åˆ¶ Authorization Code',
          '4. åœ¨æ·»åŠ è´¦æˆ·è¡¨å•ä¸­ç²˜è´´ Authorization Code'
        ]
      }
    })
  } catch (error) {
    logger.error('âŒ Failed to generate Setup Token URL:', error)
    return res
      .status(500)
      .json({ error: 'Failed to generate Setup Token URL', message: error.message })
  }
})

// éªŒè¯setup-tokenæˆæƒç å¹¶è·å–token
router.post('/claude-accounts/exchange-setup-token-code', authenticateAdmin, async (req, res) => {
  try {
    const { sessionId, authorizationCode, callbackUrl } = req.body

    if (!sessionId || (!authorizationCode && !callbackUrl)) {
      return res
        .status(400)
        .json({ error: 'Session ID and authorization code (or callback URL) are required' })
    }

    // ä»Redisè·å–OAuthä¼šè¯ä¿¡æ¯
    const oauthSession = await redis.getOAuthSession(sessionId)
    if (!oauthSession) {
      return res.status(400).json({ error: 'Invalid or expired OAuth session' })
    }

    // æ£€æŸ¥æ˜¯å¦æ˜¯setup-tokenç±»å‹
    if (oauthSession.type !== 'setup-token') {
      return res.status(400).json({ error: 'Invalid session type for setup token exchange' })
    }

    // æ£€æŸ¥ä¼šè¯æ˜¯å¦è¿‡æœŸ
    if (new Date() > new Date(oauthSession.expiresAt)) {
      await redis.deleteOAuthSession(sessionId)
      return res
        .status(400)
        .json({ error: 'OAuth session has expired, please generate a new authorization URL' })
    }

    // ç»Ÿä¸€å¤„ç†æˆæƒç è¾“å…¥ï¼ˆå¯èƒ½æ˜¯ç›´æ¥çš„codeæˆ–å®Œæ•´çš„å›è°ƒURLï¼‰
    let finalAuthCode
    const inputValue = callbackUrl || authorizationCode

    try {
      finalAuthCode = oauthHelper.parseCallbackUrl(inputValue)
    } catch (parseError) {
      return res
        .status(400)
        .json({ error: 'Failed to parse authorization input', message: parseError.message })
    }

    // äº¤æ¢Setup Token
    const tokenData = await oauthHelper.exchangeSetupTokenCode(
      finalAuthCode,
      oauthSession.codeVerifier,
      oauthSession.state,
      oauthSession.proxy // ä¼ é€’ä»£ç†é…ç½®
    )

    // æ¸…ç†OAuthä¼šè¯
    await redis.deleteOAuthSession(sessionId)

    logger.success('ğŸ‰ Successfully exchanged setup token authorization code for tokens')
    return res.json({
      success: true,
      data: {
        claudeAiOauth: tokenData
      }
    })
  } catch (error) {
    logger.error('âŒ Failed to exchange setup token authorization code:', {
      error: error.message,
      sessionId: req.body.sessionId,
      // ä¸è®°å½•å®Œæ•´çš„æˆæƒç ï¼Œåªè®°å½•é•¿åº¦å’Œå‰å‡ ä¸ªå­—ç¬¦
      codeLength: req.body.callbackUrl
        ? req.body.callbackUrl.length
        : req.body.authorizationCode
          ? req.body.authorizationCode.length
          : 0,
      codePrefix: req.body.callbackUrl
        ? `${req.body.callbackUrl.substring(0, 10)}...`
        : req.body.authorizationCode
          ? `${req.body.authorizationCode.substring(0, 10)}...`
          : 'N/A'
    })
    return res
      .status(500)
      .json({ error: 'Failed to exchange setup token authorization code', message: error.message })
  }
})

// è·å–æ‰€æœ‰Claudeè´¦æˆ·
router.get('/claude-accounts', authenticateAdmin, async (req, res) => {
  try {
    const { platform, groupId } = req.query
    let accounts = await claudeAccountService.getAllAccounts()

    // æ ¹æ®æŸ¥è¯¢å‚æ•°è¿›è¡Œç­›é€‰
    if (platform && platform !== 'all' && platform !== 'claude') {
      // å¦‚æœæŒ‡å®šäº†å…¶ä»–å¹³å°ï¼Œè¿”å›ç©ºæ•°ç»„
      accounts = []
    }

    // å¦‚æœæŒ‡å®šäº†åˆ†ç»„ç­›é€‰
    if (groupId && groupId !== 'all') {
      if (groupId === 'ungrouped') {
        // ç­›é€‰æœªåˆ†ç»„è´¦æˆ·
        accounts = accounts.filter((account) => !account.groupInfo)
      } else {
        // ç­›é€‰ç‰¹å®šåˆ†ç»„çš„è´¦æˆ·
        accounts = accounts.filter(
          (account) => account.groupInfo && account.groupInfo.id === groupId
        )
      }
    }

    // ä¸ºæ¯ä¸ªè´¦æˆ·æ·»åŠ ä½¿ç”¨ç»Ÿè®¡ä¿¡æ¯
    const accountsWithStats = await Promise.all(
      accounts.map(async (account) => {
        try {
          const usageStats = await redis.getAccountUsageStats(account.id)
          return {
            ...account,
            usage: {
              daily: usageStats.daily,
              total: usageStats.total,
              averages: usageStats.averages
            }
          }
        } catch (statsError) {
          logger.warn(`âš ï¸ Failed to get usage stats for account ${account.id}:`, statsError.message)
          // å¦‚æœè·å–ç»Ÿè®¡å¤±è´¥ï¼Œè¿”å›ç©ºç»Ÿè®¡
          return {
            ...account,
            usage: {
              daily: { tokens: 0, requests: 0, allTokens: 0 },
              total: { tokens: 0, requests: 0, allTokens: 0 },
              averages: { rpm: 0, tpm: 0 }
            }
          }
        }
      })
    )

    return res.json({ success: true, data: accountsWithStats })
  } catch (error) {
    logger.error('âŒ Failed to get Claude accounts:', error)
    return res.status(500).json({ error: 'Failed to get Claude accounts', message: error.message })
  }
})

// åˆ›å»ºæ–°çš„Claudeè´¦æˆ·
router.post('/claude-accounts', authenticateAdmin, async (req, res) => {
  try {
    const {
      name,
      description,
      email,
      password,
      refreshToken,
      claudeAiOauth,
      proxy,
      accountType,
      platform = 'claude',
      priority,
      groupId
    } = req.body

    if (!name) {
      return res.status(400).json({ error: 'Name is required' })
    }

    // éªŒè¯accountTypeçš„æœ‰æ•ˆæ€§
    if (accountType && !['shared', 'dedicated', 'group'].includes(accountType)) {
      return res
        .status(400)
        .json({ error: 'Invalid account type. Must be "shared", "dedicated" or "group"' })
    }

    // å¦‚æœæ˜¯åˆ†ç»„ç±»å‹ï¼ŒéªŒè¯groupId
    if (accountType === 'group' && !groupId) {
      return res.status(400).json({ error: 'Group ID is required for group type accounts' })
    }

    // éªŒè¯priorityçš„æœ‰æ•ˆæ€§
    if (
      priority !== undefined &&
      (typeof priority !== 'number' || priority < 1 || priority > 100)
    ) {
      return res.status(400).json({ error: 'Priority must be a number between 1 and 100' })
    }

    const newAccount = await claudeAccountService.createAccount({
      name,
      description,
      email,
      password,
      refreshToken,
      claudeAiOauth,
      proxy,
      accountType: accountType || 'shared', // é»˜è®¤ä¸ºå…±äº«ç±»å‹
      platform,
      priority: priority || 50 // é»˜è®¤ä¼˜å…ˆçº§ä¸º50
    })

    // å¦‚æœæ˜¯åˆ†ç»„ç±»å‹ï¼Œå°†è´¦æˆ·æ·»åŠ åˆ°åˆ†ç»„
    if (accountType === 'group' && groupId) {
      await accountGroupService.addAccountToGroup(newAccount.id, groupId, newAccount.platform)
    }

    logger.success(`ğŸ¢ Admin created new Claude account: ${name} (${accountType || 'shared'})`)
    return res.json({ success: true, data: newAccount })
  } catch (error) {
    logger.error('âŒ Failed to create Claude account:', error)
    return res
      .status(500)
      .json({ error: 'Failed to create Claude account', message: error.message })
  }
})

// æ›´æ–°Claudeè´¦æˆ·
router.put('/claude-accounts/:accountId', authenticateAdmin, async (req, res) => {
  try {
    const { accountId } = req.params
    const updates = req.body

    // éªŒè¯priorityçš„æœ‰æ•ˆæ€§
    if (
      updates.priority !== undefined &&
      (typeof updates.priority !== 'number' || updates.priority < 1 || updates.priority > 100)
    ) {
      return res.status(400).json({ error: 'Priority must be a number between 1 and 100' })
    }

    // éªŒè¯accountTypeçš„æœ‰æ•ˆæ€§
    if (updates.accountType && !['shared', 'dedicated', 'group'].includes(updates.accountType)) {
      return res
        .status(400)
        .json({ error: 'Invalid account type. Must be "shared", "dedicated" or "group"' })
    }

    // å¦‚æœæ›´æ–°ä¸ºåˆ†ç»„ç±»å‹ï¼ŒéªŒè¯groupId
    if (updates.accountType === 'group' && !updates.groupId) {
      return res.status(400).json({ error: 'Group ID is required for group type accounts' })
    }

    // è·å–è´¦æˆ·å½“å‰ä¿¡æ¯ä»¥å¤„ç†åˆ†ç»„å˜æ›´
    const currentAccount = await claudeAccountService.getAccount(accountId)
    if (!currentAccount) {
      return res.status(404).json({ error: 'Account not found' })
    }

    // å¤„ç†åˆ†ç»„çš„å˜æ›´
    if (updates.accountType !== undefined) {
      // å¦‚æœä¹‹å‰æ˜¯åˆ†ç»„ç±»å‹ï¼Œéœ€è¦ä»åŸåˆ†ç»„ä¸­ç§»é™¤
      if (currentAccount.accountType === 'group') {
        const oldGroup = await accountGroupService.getAccountGroup(accountId)
        if (oldGroup) {
          await accountGroupService.removeAccountFromGroup(accountId, oldGroup.id)
        }
      }

      // å¦‚æœæ–°ç±»å‹æ˜¯åˆ†ç»„ï¼Œæ·»åŠ åˆ°æ–°åˆ†ç»„
      if (updates.accountType === 'group' && updates.groupId) {
        // ä»è·¯ç”±çŸ¥é“è¿™æ˜¯ Claude OAuth è´¦æˆ·ï¼Œå¹³å°ä¸º 'claude'
        await accountGroupService.addAccountToGroup(accountId, updates.groupId, 'claude')
      }
    }

    await claudeAccountService.updateAccount(accountId, updates)

    logger.success(`ğŸ“ Admin updated Claude account: ${accountId}`)
    return res.json({ success: true, message: 'Claude account updated successfully' })
  } catch (error) {
    logger.error('âŒ Failed to update Claude account:', error)
    return res
      .status(500)
      .json({ error: 'Failed to update Claude account', message: error.message })
  }
})

// åˆ é™¤Claudeè´¦æˆ·
router.delete('/claude-accounts/:accountId', authenticateAdmin, async (req, res) => {
  try {
    const { accountId } = req.params

    // è·å–è´¦æˆ·ä¿¡æ¯ä»¥æ£€æŸ¥æ˜¯å¦åœ¨åˆ†ç»„ä¸­
    const account = await claudeAccountService.getAccount(accountId)
    if (account && account.accountType === 'group') {
      const group = await accountGroupService.getAccountGroup(accountId)
      if (group) {
        await accountGroupService.removeAccountFromGroup(accountId, group.id)
      }
    }

    await claudeAccountService.deleteAccount(accountId)

    logger.success(`ğŸ—‘ï¸ Admin deleted Claude account: ${accountId}`)
    return res.json({ success: true, message: 'Claude account deleted successfully' })
  } catch (error) {
    logger.error('âŒ Failed to delete Claude account:', error)
    return res
      .status(500)
      .json({ error: 'Failed to delete Claude account', message: error.message })
  }
})

// æ›´æ–°å•ä¸ªClaudeè´¦æˆ·çš„Profileä¿¡æ¯
router.post('/claude-accounts/:accountId/update-profile', authenticateAdmin, async (req, res) => {
  try {
    const { accountId } = req.params

    const profileInfo = await claudeAccountService.fetchAndUpdateAccountProfile(accountId)

    logger.success(`âœ… Updated profile for Claude account: ${accountId}`)
    return res.json({
      success: true,
      message: 'Account profile updated successfully',
      data: profileInfo
    })
  } catch (error) {
    logger.error('âŒ Failed to update account profile:', error)
    return res
      .status(500)
      .json({ error: 'Failed to update account profile', message: error.message })
  }
})

// æ‰¹é‡æ›´æ–°æ‰€æœ‰Claudeè´¦æˆ·çš„Profileä¿¡æ¯
router.post('/claude-accounts/update-all-profiles', authenticateAdmin, async (req, res) => {
  try {
    const result = await claudeAccountService.updateAllAccountProfiles()

    logger.success('âœ… Batch profile update completed')
    return res.json({
      success: true,
      message: 'Batch profile update completed',
      data: result
    })
  } catch (error) {
    logger.error('âŒ Failed to update all account profiles:', error)
    return res
      .status(500)
      .json({ error: 'Failed to update all account profiles', message: error.message })
  }
})

// åˆ·æ–°Claudeè´¦æˆ·token
router.post('/claude-accounts/:accountId/refresh', authenticateAdmin, async (req, res) => {
  try {
    const { accountId } = req.params

    const result = await claudeAccountService.refreshAccountToken(accountId)

    logger.success(`ğŸ”„ Admin refreshed token for Claude account: ${accountId}`)
    return res.json({ success: true, data: result })
  } catch (error) {
    logger.error('âŒ Failed to refresh Claude account token:', error)
    return res.status(500).json({ error: 'Failed to refresh token', message: error.message })
  }
})

// é‡ç½®Claudeè´¦æˆ·çŠ¶æ€ï¼ˆæ¸…é™¤æ‰€æœ‰å¼‚å¸¸çŠ¶æ€ï¼‰
router.post('/claude-accounts/:accountId/reset-status', authenticateAdmin, async (req, res) => {
  try {
    const { accountId } = req.params

    const result = await claudeAccountService.resetAccountStatus(accountId)

    logger.success(`âœ… Admin reset status for Claude account: ${accountId}`)
    return res.json({ success: true, data: result })
  } catch (error) {
    logger.error('âŒ Failed to reset Claude account status:', error)
    return res.status(500).json({ error: 'Failed to reset status', message: error.message })
  }
})

// åˆ‡æ¢Claudeè´¦æˆ·è°ƒåº¦çŠ¶æ€
router.put(
  '/claude-accounts/:accountId/toggle-schedulable',
  authenticateAdmin,
  async (req, res) => {
    try {
      const { accountId } = req.params

      const accounts = await claudeAccountService.getAllAccounts()
      const account = accounts.find((acc) => acc.id === accountId)

      if (!account) {
        return res.status(404).json({ error: 'Account not found' })
      }

      const newSchedulable = !account.schedulable
      await claudeAccountService.updateAccount(accountId, { schedulable: newSchedulable })

      // å¦‚æœè´¦å·è¢«ç¦ç”¨ï¼Œå‘é€webhooké€šçŸ¥
      if (!newSchedulable) {
        await webhookNotifier.sendAccountAnomalyNotification({
          accountId: account.id,
          accountName: account.name || account.claudeAiOauth?.email || 'Claude Account',
          platform: 'claude-oauth',
          status: 'disabled',
          errorCode: 'CLAUDE_OAUTH_MANUALLY_DISABLED',
          reason: 'è´¦å·å·²è¢«ç®¡ç†å‘˜æ‰‹åŠ¨ç¦ç”¨è°ƒåº¦',
          timestamp: new Date().toISOString()
        })
      }

      logger.success(
        `ğŸ”„ Admin toggled Claude account schedulable status: ${accountId} -> ${newSchedulable ? 'schedulable' : 'not schedulable'}`
      )
      return res.json({ success: true, schedulable: newSchedulable })
    } catch (error) {
      logger.error('âŒ Failed to toggle Claude account schedulable status:', error)
      return res
        .status(500)
        .json({ error: 'Failed to toggle schedulable status', message: error.message })
    }
  }
)

// ğŸ® Claude Console è´¦æˆ·ç®¡ç†

// è·å–æ‰€æœ‰Claude Consoleè´¦æˆ·
router.get('/claude-console-accounts', authenticateAdmin, async (req, res) => {
  try {
    const { platform, groupId } = req.query
    let accounts = await claudeConsoleAccountService.getAllAccounts()

    // æ ¹æ®æŸ¥è¯¢å‚æ•°è¿›è¡Œç­›é€‰
    if (platform && platform !== 'all' && platform !== 'claude-console') {
      // å¦‚æœæŒ‡å®šäº†å…¶ä»–å¹³å°ï¼Œè¿”å›ç©ºæ•°ç»„
      accounts = []
    }

    // å¦‚æœæŒ‡å®šäº†åˆ†ç»„ç­›é€‰
    if (groupId && groupId !== 'all') {
      if (groupId === 'ungrouped') {
        // ç­›é€‰æœªåˆ†ç»„è´¦æˆ·
        accounts = accounts.filter((account) => !account.groupInfo)
      } else {
        // ç­›é€‰ç‰¹å®šåˆ†ç»„çš„è´¦æˆ·
        accounts = accounts.filter(
          (account) => account.groupInfo && account.groupInfo.id === groupId
        )
      }
    }

    // ä¸ºæ¯ä¸ªè´¦æˆ·æ·»åŠ ä½¿ç”¨ç»Ÿè®¡ä¿¡æ¯
    const accountsWithStats = await Promise.all(
      accounts.map(async (account) => {
        try {
          const usageStats = await redis.getAccountUsageStats(account.id)
          return {
            ...account,
            usage: {
              daily: usageStats.daily,
              total: usageStats.total,
              averages: usageStats.averages
            }
          }
        } catch (statsError) {
          logger.warn(
            `âš ï¸ Failed to get usage stats for Claude Console account ${account.id}:`,
            statsError.message
          )
          return {
            ...account,
            usage: {
              daily: { tokens: 0, requests: 0, allTokens: 0 },
              total: { tokens: 0, requests: 0, allTokens: 0 },
              averages: { rpm: 0, tpm: 0 }
            }
          }
        }
      })
    )

    return res.json({ success: true, data: accountsWithStats })
  } catch (error) {
    logger.error('âŒ Failed to get Claude Console accounts:', error)
    return res
      .status(500)
      .json({ error: 'Failed to get Claude Console accounts', message: error.message })
  }
})

// åˆ›å»ºæ–°çš„Claude Consoleè´¦æˆ·
router.post('/claude-console-accounts', authenticateAdmin, async (req, res) => {
  try {
    const {
      name,
      description,
      apiUrl,
      apiKey,
      priority,
      supportedModels,
      userAgent,
      rateLimitDuration,
      proxy,
      accountType,
      groupId
    } = req.body

    if (!name || !apiUrl || !apiKey) {
      return res.status(400).json({ error: 'Name, API URL and API Key are required' })
    }

    // éªŒè¯priorityçš„æœ‰æ•ˆæ€§ï¼ˆ1-100ï¼‰
    if (priority !== undefined && (priority < 1 || priority > 100)) {
      return res.status(400).json({ error: 'Priority must be between 1 and 100' })
    }

    // éªŒè¯accountTypeçš„æœ‰æ•ˆæ€§
    if (accountType && !['shared', 'dedicated', 'group'].includes(accountType)) {
      return res
        .status(400)
        .json({ error: 'Invalid account type. Must be "shared", "dedicated" or "group"' })
    }

    // å¦‚æœæ˜¯åˆ†ç»„ç±»å‹ï¼ŒéªŒè¯groupId
    if (accountType === 'group' && !groupId) {
      return res.status(400).json({ error: 'Group ID is required for group type accounts' })
    }

    const newAccount = await claudeConsoleAccountService.createAccount({
      name,
      description,
      apiUrl,
      apiKey,
      priority: priority || 50,
      supportedModels: supportedModels || [],
      userAgent,
      rateLimitDuration:
        rateLimitDuration !== undefined && rateLimitDuration !== null ? rateLimitDuration : 60,
      proxy,
      accountType: accountType || 'shared'
    })

    // å¦‚æœæ˜¯åˆ†ç»„ç±»å‹ï¼Œå°†è´¦æˆ·æ·»åŠ åˆ°åˆ†ç»„
    if (accountType === 'group' && groupId) {
      await accountGroupService.addAccountToGroup(newAccount.id, groupId, 'claude')
    }

    logger.success(`ğŸ® Admin created Claude Console account: ${name}`)
    return res.json({ success: true, data: newAccount })
  } catch (error) {
    logger.error('âŒ Failed to create Claude Console account:', error)
    return res
      .status(500)
      .json({ error: 'Failed to create Claude Console account', message: error.message })
  }
})

// æ›´æ–°Claude Consoleè´¦æˆ·
router.put('/claude-console-accounts/:accountId', authenticateAdmin, async (req, res) => {
  try {
    const { accountId } = req.params
    const updates = req.body

    // éªŒè¯priorityçš„æœ‰æ•ˆæ€§ï¼ˆ1-100ï¼‰
    if (updates.priority !== undefined && (updates.priority < 1 || updates.priority > 100)) {
      return res.status(400).json({ error: 'Priority must be between 1 and 100' })
    }

    // éªŒè¯accountTypeçš„æœ‰æ•ˆæ€§
    if (updates.accountType && !['shared', 'dedicated', 'group'].includes(updates.accountType)) {
      return res
        .status(400)
        .json({ error: 'Invalid account type. Must be "shared", "dedicated" or "group"' })
    }

    // å¦‚æœæ›´æ–°ä¸ºåˆ†ç»„ç±»å‹ï¼ŒéªŒè¯groupId
    if (updates.accountType === 'group' && !updates.groupId) {
      return res.status(400).json({ error: 'Group ID is required for group type accounts' })
    }

    // è·å–è´¦æˆ·å½“å‰ä¿¡æ¯ä»¥å¤„ç†åˆ†ç»„å˜æ›´
    const currentAccount = await claudeConsoleAccountService.getAccount(accountId)
    if (!currentAccount) {
      return res.status(404).json({ error: 'Account not found' })
    }

    // å¤„ç†åˆ†ç»„çš„å˜æ›´
    if (updates.accountType !== undefined) {
      // å¦‚æœä¹‹å‰æ˜¯åˆ†ç»„ç±»å‹ï¼Œéœ€è¦ä»åŸåˆ†ç»„ä¸­ç§»é™¤
      if (currentAccount.accountType === 'group') {
        const oldGroup = await accountGroupService.getAccountGroup(accountId)
        if (oldGroup) {
          await accountGroupService.removeAccountFromGroup(accountId, oldGroup.id)
        }
      }
      // å¦‚æœæ–°ç±»å‹æ˜¯åˆ†ç»„ï¼Œæ·»åŠ åˆ°æ–°åˆ†ç»„
      if (updates.accountType === 'group' && updates.groupId) {
        // Claude Console è´¦æˆ·åœ¨åˆ†ç»„ä¸­è¢«è§†ä¸º 'claude' å¹³å°
        await accountGroupService.addAccountToGroup(accountId, updates.groupId, 'claude')
      }
    }

    await claudeConsoleAccountService.updateAccount(accountId, updates)

    logger.success(`ğŸ“ Admin updated Claude Console account: ${accountId}`)
    return res.json({ success: true, message: 'Claude Console account updated successfully' })
  } catch (error) {
    logger.error('âŒ Failed to update Claude Console account:', error)
    return res
      .status(500)
      .json({ error: 'Failed to update Claude Console account', message: error.message })
  }
})

// åˆ é™¤Claude Consoleè´¦æˆ·
router.delete('/claude-console-accounts/:accountId', authenticateAdmin, async (req, res) => {
  try {
    const { accountId } = req.params

    // è·å–è´¦æˆ·ä¿¡æ¯ä»¥æ£€æŸ¥æ˜¯å¦åœ¨åˆ†ç»„ä¸­
    const account = await claudeConsoleAccountService.getAccount(accountId)
    if (account && account.accountType === 'group') {
      const group = await accountGroupService.getAccountGroup(accountId)
      if (group) {
        await accountGroupService.removeAccountFromGroup(accountId, group.id)
      }
    }

    await claudeConsoleAccountService.deleteAccount(accountId)

    logger.success(`ğŸ—‘ï¸ Admin deleted Claude Console account: ${accountId}`)
    return res.json({ success: true, message: 'Claude Console account deleted successfully' })
  } catch (error) {
    logger.error('âŒ Failed to delete Claude Console account:', error)
    return res
      .status(500)
      .json({ error: 'Failed to delete Claude Console account', message: error.message })
  }
})

// åˆ‡æ¢Claude Consoleè´¦æˆ·çŠ¶æ€
router.put('/claude-console-accounts/:accountId/toggle', authenticateAdmin, async (req, res) => {
  try {
    const { accountId } = req.params

    const account = await claudeConsoleAccountService.getAccount(accountId)
    if (!account) {
      return res.status(404).json({ error: 'Account not found' })
    }

    const newStatus = !account.isActive
    await claudeConsoleAccountService.updateAccount(accountId, { isActive: newStatus })

    logger.success(
      `ğŸ”„ Admin toggled Claude Console account status: ${accountId} -> ${newStatus ? 'active' : 'inactive'}`
    )
    return res.json({ success: true, isActive: newStatus })
  } catch (error) {
    logger.error('âŒ Failed to toggle Claude Console account status:', error)
    return res
      .status(500)
      .json({ error: 'Failed to toggle account status', message: error.message })
  }
})

// åˆ‡æ¢Claude Consoleè´¦æˆ·è°ƒåº¦çŠ¶æ€
router.put(
  '/claude-console-accounts/:accountId/toggle-schedulable',
  authenticateAdmin,
  async (req, res) => {
    try {
      const { accountId } = req.params

      const account = await claudeConsoleAccountService.getAccount(accountId)
      if (!account) {
        return res.status(404).json({ error: 'Account not found' })
      }

      const newSchedulable = !account.schedulable
      await claudeConsoleAccountService.updateAccount(accountId, { schedulable: newSchedulable })

      // å¦‚æœè´¦å·è¢«ç¦ç”¨ï¼Œå‘é€webhooké€šçŸ¥
      if (!newSchedulable) {
        await webhookNotifier.sendAccountAnomalyNotification({
          accountId: account.id,
          accountName: account.name || 'Claude Console Account',
          platform: 'claude-console',
          status: 'disabled',
          errorCode: 'CLAUDE_CONSOLE_MANUALLY_DISABLED',
          reason: 'è´¦å·å·²è¢«ç®¡ç†å‘˜æ‰‹åŠ¨ç¦ç”¨è°ƒåº¦',
          timestamp: new Date().toISOString()
        })
      }

      logger.success(
        `ğŸ”„ Admin toggled Claude Console account schedulable status: ${accountId} -> ${newSchedulable ? 'schedulable' : 'not schedulable'}`
      )
      return res.json({ success: true, schedulable: newSchedulable })
    } catch (error) {
      logger.error('âŒ Failed to toggle Claude Console account schedulable status:', error)
      return res
        .status(500)
        .json({ error: 'Failed to toggle schedulable status', message: error.message })
    }
  }
)

// â˜ï¸ Bedrock è´¦æˆ·ç®¡ç†

// è·å–æ‰€æœ‰Bedrockè´¦æˆ·
router.get('/bedrock-accounts', authenticateAdmin, async (req, res) => {
  try {
    const { platform, groupId } = req.query
    const result = await bedrockAccountService.getAllAccounts()
    if (!result.success) {
      return res
        .status(500)
        .json({ error: 'Failed to get Bedrock accounts', message: result.error })
    }

    let accounts = result.data

    // æ ¹æ®æŸ¥è¯¢å‚æ•°è¿›è¡Œç­›é€‰
    if (platform && platform !== 'all' && platform !== 'bedrock') {
      // å¦‚æœæŒ‡å®šäº†å…¶ä»–å¹³å°ï¼Œè¿”å›ç©ºæ•°ç»„
      accounts = []
    }

    // å¦‚æœæŒ‡å®šäº†åˆ†ç»„ç­›é€‰
    if (groupId && groupId !== 'all') {
      if (groupId === 'ungrouped') {
        // ç­›é€‰æœªåˆ†ç»„è´¦æˆ·
        accounts = accounts.filter((account) => !account.groupInfo)
      } else {
        // ç­›é€‰ç‰¹å®šåˆ†ç»„çš„è´¦æˆ·
        accounts = accounts.filter(
          (account) => account.groupInfo && account.groupInfo.id === groupId
        )
      }
    }

    // ä¸ºæ¯ä¸ªè´¦æˆ·æ·»åŠ ä½¿ç”¨ç»Ÿè®¡ä¿¡æ¯
    const accountsWithStats = await Promise.all(
      accounts.map(async (account) => {
        try {
          const usageStats = await redis.getAccountUsageStats(account.id)
          return {
            ...account,
            usage: {
              daily: usageStats.daily,
              total: usageStats.total,
              averages: usageStats.averages
            }
          }
        } catch (statsError) {
          logger.warn(
            `âš ï¸ Failed to get usage stats for Bedrock account ${account.id}:`,
            statsError.message
          )
          return {
            ...account,
            usage: {
              daily: { tokens: 0, requests: 0, allTokens: 0 },
              total: { tokens: 0, requests: 0, allTokens: 0 },
              averages: { rpm: 0, tpm: 0 }
            }
          }
        }
      })
    )

    return res.json({ success: true, data: accountsWithStats })
  } catch (error) {
    logger.error('âŒ Failed to get Bedrock accounts:', error)
    return res.status(500).json({ error: 'Failed to get Bedrock accounts', message: error.message })
  }
})

// åˆ›å»ºæ–°çš„Bedrockè´¦æˆ·
router.post('/bedrock-accounts', authenticateAdmin, async (req, res) => {
  try {
    const {
      name,
      description,
      region,
      awsCredentials,
      defaultModel,
      priority,
      accountType,
      credentialType
    } = req.body

    if (!name) {
      return res.status(400).json({ error: 'Name is required' })
    }

    // éªŒè¯priorityçš„æœ‰æ•ˆæ€§ï¼ˆ1-100ï¼‰
    if (priority !== undefined && (priority < 1 || priority > 100)) {
      return res.status(400).json({ error: 'Priority must be between 1 and 100' })
    }

    // éªŒè¯accountTypeçš„æœ‰æ•ˆæ€§
    if (accountType && !['shared', 'dedicated'].includes(accountType)) {
      return res
        .status(400)
        .json({ error: 'Invalid account type. Must be "shared" or "dedicated"' })
    }

    // éªŒè¯credentialTypeçš„æœ‰æ•ˆæ€§
    if (credentialType && !['default', 'access_key', 'bearer_token'].includes(credentialType)) {
      return res.status(400).json({
        error: 'Invalid credential type. Must be "default", "access_key", or "bearer_token"'
      })
    }

    const result = await bedrockAccountService.createAccount({
      name,
      description: description || '',
      region: region || 'us-east-1',
      awsCredentials,
      defaultModel,
      priority: priority || 50,
      accountType: accountType || 'shared',
      credentialType: credentialType || 'default'
    })

    if (!result.success) {
      return res
        .status(500)
        .json({ error: 'Failed to create Bedrock account', message: result.error })
    }

    logger.success(`â˜ï¸ Admin created Bedrock account: ${name}`)
    return res.json({ success: true, data: result.data })
  } catch (error) {
    logger.error('âŒ Failed to create Bedrock account:', error)
    return res
      .status(500)
      .json({ error: 'Failed to create Bedrock account', message: error.message })
  }
})

// æ›´æ–°Bedrockè´¦æˆ·
router.put('/bedrock-accounts/:accountId', authenticateAdmin, async (req, res) => {
  try {
    const { accountId } = req.params
    const updates = req.body

    // éªŒè¯priorityçš„æœ‰æ•ˆæ€§ï¼ˆ1-100ï¼‰
    if (updates.priority !== undefined && (updates.priority < 1 || updates.priority > 100)) {
      return res.status(400).json({ error: 'Priority must be between 1 and 100' })
    }

    // éªŒè¯accountTypeçš„æœ‰æ•ˆæ€§
    if (updates.accountType && !['shared', 'dedicated'].includes(updates.accountType)) {
      return res
        .status(400)
        .json({ error: 'Invalid account type. Must be "shared" or "dedicated"' })
    }

    // éªŒè¯credentialTypeçš„æœ‰æ•ˆæ€§
    if (
      updates.credentialType &&
      !['default', 'access_key', 'bearer_token'].includes(updates.credentialType)
    ) {
      return res.status(400).json({
        error: 'Invalid credential type. Must be "default", "access_key", or "bearer_token"'
      })
    }

    const result = await bedrockAccountService.updateAccount(accountId, updates)

    if (!result.success) {
      return res
        .status(500)
        .json({ error: 'Failed to update Bedrock account', message: result.error })
    }

    logger.success(`ğŸ“ Admin updated Bedrock account: ${accountId}`)
    return res.json({ success: true, message: 'Bedrock account updated successfully' })
  } catch (error) {
    logger.error('âŒ Failed to update Bedrock account:', error)
    return res
      .status(500)
      .json({ error: 'Failed to update Bedrock account', message: error.message })
  }
})

// åˆ é™¤Bedrockè´¦æˆ·
router.delete('/bedrock-accounts/:accountId', authenticateAdmin, async (req, res) => {
  try {
    const { accountId } = req.params

    const result = await bedrockAccountService.deleteAccount(accountId)

    if (!result.success) {
      return res
        .status(500)
        .json({ error: 'Failed to delete Bedrock account', message: result.error })
    }

    logger.success(`ğŸ—‘ï¸ Admin deleted Bedrock account: ${accountId}`)
    return res.json({ success: true, message: 'Bedrock account deleted successfully' })
  } catch (error) {
    logger.error('âŒ Failed to delete Bedrock account:', error)
    return res
      .status(500)
      .json({ error: 'Failed to delete Bedrock account', message: error.message })
  }
})

// åˆ‡æ¢Bedrockè´¦æˆ·çŠ¶æ€
router.put('/bedrock-accounts/:accountId/toggle', authenticateAdmin, async (req, res) => {
  try {
    const { accountId } = req.params

    const accountResult = await bedrockAccountService.getAccount(accountId)
    if (!accountResult.success) {
      return res.status(404).json({ error: 'Account not found' })
    }

    const newStatus = !accountResult.data.isActive
    const updateResult = await bedrockAccountService.updateAccount(accountId, {
      isActive: newStatus
    })

    if (!updateResult.success) {
      return res
        .status(500)
        .json({ error: 'Failed to toggle account status', message: updateResult.error })
    }

    logger.success(
      `ğŸ”„ Admin toggled Bedrock account status: ${accountId} -> ${newStatus ? 'active' : 'inactive'}`
    )
    return res.json({ success: true, isActive: newStatus })
  } catch (error) {
    logger.error('âŒ Failed to toggle Bedrock account status:', error)
    return res
      .status(500)
      .json({ error: 'Failed to toggle account status', message: error.message })
  }
})

// åˆ‡æ¢Bedrockè´¦æˆ·è°ƒåº¦çŠ¶æ€
router.put(
  '/bedrock-accounts/:accountId/toggle-schedulable',
  authenticateAdmin,
  async (req, res) => {
    try {
      const { accountId } = req.params

      const accountResult = await bedrockAccountService.getAccount(accountId)
      if (!accountResult.success) {
        return res.status(404).json({ error: 'Account not found' })
      }

      const newSchedulable = !accountResult.data.schedulable
      const updateResult = await bedrockAccountService.updateAccount(accountId, {
        schedulable: newSchedulable
      })

      if (!updateResult.success) {
        return res
          .status(500)
          .json({ error: 'Failed to toggle schedulable status', message: updateResult.error })
      }

      // å¦‚æœè´¦å·è¢«ç¦ç”¨ï¼Œå‘é€webhooké€šçŸ¥
      if (!newSchedulable) {
        await webhookNotifier.sendAccountAnomalyNotification({
          accountId: accountResult.data.id,
          accountName: accountResult.data.name || 'Bedrock Account',
          platform: 'bedrock',
          status: 'disabled',
          errorCode: 'BEDROCK_MANUALLY_DISABLED',
          reason: 'è´¦å·å·²è¢«ç®¡ç†å‘˜æ‰‹åŠ¨ç¦ç”¨è°ƒåº¦',
          timestamp: new Date().toISOString()
        })
      }

      logger.success(
        `ğŸ”„ Admin toggled Bedrock account schedulable status: ${accountId} -> ${newSchedulable ? 'schedulable' : 'not schedulable'}`
      )
      return res.json({ success: true, schedulable: newSchedulable })
    } catch (error) {
      logger.error('âŒ Failed to toggle Bedrock account schedulable status:', error)
      return res
        .status(500)
        .json({ error: 'Failed to toggle schedulable status', message: error.message })
    }
  }
)

// æµ‹è¯•Bedrockè´¦æˆ·è¿æ¥
router.post('/bedrock-accounts/:accountId/test', authenticateAdmin, async (req, res) => {
  try {
    const { accountId } = req.params

    const result = await bedrockAccountService.testAccount(accountId)

    if (!result.success) {
      return res.status(500).json({ error: 'Account test failed', message: result.error })
    }

    logger.success(`ğŸ§ª Admin tested Bedrock account: ${accountId} - ${result.data.status}`)
    return res.json({ success: true, data: result.data })
  } catch (error) {
    logger.error('âŒ Failed to test Bedrock account:', error)
    return res.status(500).json({ error: 'Failed to test Bedrock account', message: error.message })
  }
})

// ğŸ¤– Gemini è´¦æˆ·ç®¡ç†

// ç”Ÿæˆ Gemini OAuth æˆæƒ URL
router.post('/gemini-accounts/generate-auth-url', authenticateAdmin, async (req, res) => {
  try {
    const { state, proxy } = req.body // æ¥æ”¶ä»£ç†é…ç½®

    // ä½¿ç”¨æ–°çš„ codeassist.google.com å›è°ƒåœ°å€
    const redirectUri = 'https://codeassist.google.com/authcode'

    logger.info(`Generating Gemini OAuth URL with redirect_uri: ${redirectUri}`)

    const {
      authUrl,
      state: authState,
      codeVerifier,
      redirectUri: finalRedirectUri
    } = await geminiAccountService.generateAuthUrl(state, redirectUri)

    // åˆ›å»º OAuth ä¼šè¯ï¼ŒåŒ…å« codeVerifier å’Œä»£ç†é…ç½®
    const sessionId = authState
    await redis.setOAuthSession(sessionId, {
      state: authState,
      type: 'gemini',
      redirectUri: finalRedirectUri,
      codeVerifier, // ä¿å­˜ PKCE code verifier
      proxy: proxy || null, // ä¿å­˜ä»£ç†é…ç½®
      createdAt: new Date().toISOString()
    })

    logger.info(`Generated Gemini OAuth URL with session: ${sessionId}`)
    return res.json({
      success: true,
      data: {
        authUrl,
        sessionId
      }
    })
  } catch (error) {
    logger.error('âŒ Failed to generate Gemini auth URL:', error)
    return res.status(500).json({ error: 'Failed to generate auth URL', message: error.message })
  }
})

// è½®è¯¢ Gemini OAuth æˆæƒçŠ¶æ€
router.post('/gemini-accounts/poll-auth-status', authenticateAdmin, async (req, res) => {
  try {
    const { sessionId } = req.body

    if (!sessionId) {
      return res.status(400).json({ error: 'Session ID is required' })
    }

    const result = await geminiAccountService.pollAuthorizationStatus(sessionId)

    if (result.success) {
      logger.success(`âœ… Gemini OAuth authorization successful for session: ${sessionId}`)
      return res.json({ success: true, data: { tokens: result.tokens } })
    } else {
      return res.json({ success: false, error: result.error })
    }
  } catch (error) {
    logger.error('âŒ Failed to poll Gemini auth status:', error)
    return res.status(500).json({ error: 'Failed to poll auth status', message: error.message })
  }
})

// äº¤æ¢ Gemini æˆæƒç 
router.post('/gemini-accounts/exchange-code', authenticateAdmin, async (req, res) => {
  try {
    const { code, sessionId, proxy: requestProxy } = req.body

    if (!code) {
      return res.status(400).json({ error: 'Authorization code is required' })
    }

    let redirectUri = 'https://codeassist.google.com/authcode'
    let codeVerifier = null
    let proxyConfig = null

    // å¦‚æœæä¾›äº† sessionIdï¼Œä» OAuth ä¼šè¯ä¸­è·å–ä¿¡æ¯
    if (sessionId) {
      const sessionData = await redis.getOAuthSession(sessionId)
      if (sessionData) {
        const {
          redirectUri: sessionRedirectUri,
          codeVerifier: sessionCodeVerifier,
          proxy
        } = sessionData
        redirectUri = sessionRedirectUri || redirectUri
        codeVerifier = sessionCodeVerifier
        proxyConfig = proxy // è·å–ä»£ç†é…ç½®
        logger.info(
          `Using session redirect_uri: ${redirectUri}, has codeVerifier: ${!!codeVerifier}, has proxy from session: ${!!proxyConfig}`
        )
      }
    }

    // å¦‚æœè¯·æ±‚ä½“ä¸­ç›´æ¥æä¾›äº†ä»£ç†é…ç½®ï¼Œä¼˜å…ˆä½¿ç”¨å®ƒ
    if (requestProxy) {
      proxyConfig = requestProxy
      logger.info(
        `Using proxy from request body: ${proxyConfig ? JSON.stringify(proxyConfig) : 'none'}`
      )
    }

    const tokens = await geminiAccountService.exchangeCodeForTokens(
      code,
      redirectUri,
      codeVerifier,
      proxyConfig // ä¼ é€’ä»£ç†é…ç½®
    )

    // æ¸…ç† OAuth ä¼šè¯
    if (sessionId) {
      await redis.deleteOAuthSession(sessionId)
    }

    logger.success('âœ… Successfully exchanged Gemini authorization code')
    return res.json({ success: true, data: { tokens } })
  } catch (error) {
    logger.error('âŒ Failed to exchange Gemini authorization code:', error)
    return res.status(500).json({ error: 'Failed to exchange code', message: error.message })
  }
})

// è·å–æ‰€æœ‰ Gemini è´¦æˆ·
router.get('/gemini-accounts', authenticateAdmin, async (req, res) => {
  try {
    const { platform, groupId } = req.query
    let accounts = await geminiAccountService.getAllAccounts()

    // æ ¹æ®æŸ¥è¯¢å‚æ•°è¿›è¡Œç­›é€‰
    if (platform && platform !== 'all' && platform !== 'gemini') {
      // å¦‚æœæŒ‡å®šäº†å…¶ä»–å¹³å°ï¼Œè¿”å›ç©ºæ•°ç»„
      accounts = []
    }

    // å¦‚æœæŒ‡å®šäº†åˆ†ç»„ç­›é€‰
    if (groupId && groupId !== 'all') {
      if (groupId === 'ungrouped') {
        // ç­›é€‰æœªåˆ†ç»„è´¦æˆ·
        accounts = accounts.filter((account) => !account.groupInfo)
      } else {
        // ç­›é€‰ç‰¹å®šåˆ†ç»„çš„è´¦æˆ·
        accounts = accounts.filter(
          (account) => account.groupInfo && account.groupInfo.id === groupId
        )
      }
    }

    // ä¸ºæ¯ä¸ªè´¦æˆ·æ·»åŠ ä½¿ç”¨ç»Ÿè®¡ä¿¡æ¯ï¼ˆä¸Claudeè´¦æˆ·ç›¸åŒçš„é€»è¾‘ï¼‰
    const accountsWithStats = await Promise.all(
      accounts.map(async (account) => {
        try {
          const usageStats = await redis.getAccountUsageStats(account.id)
          return {
            ...account,
            usage: {
              daily: usageStats.daily,
              total: usageStats.total,
              averages: usageStats.averages
            }
          }
        } catch (statsError) {
          logger.warn(
            `âš ï¸ Failed to get usage stats for Gemini account ${account.id}:`,
            statsError.message
          )
          // å¦‚æœè·å–ç»Ÿè®¡å¤±è´¥ï¼Œè¿”å›ç©ºç»Ÿè®¡
          return {
            ...account,
            usage: {
              daily: { tokens: 0, requests: 0, allTokens: 0 },
              total: { tokens: 0, requests: 0, allTokens: 0 },
              averages: { rpm: 0, tpm: 0 }
            }
          }
        }
      })
    )

    return res.json({ success: true, data: accountsWithStats })
  } catch (error) {
    logger.error('âŒ Failed to get Gemini accounts:', error)
    return res.status(500).json({ error: 'Failed to get accounts', message: error.message })
  }
})

// åˆ›å»ºæ–°çš„ Gemini è´¦æˆ·
router.post('/gemini-accounts', authenticateAdmin, async (req, res) => {
  try {
    const accountData = req.body

    // è¾“å…¥éªŒè¯
    if (!accountData.name) {
      return res.status(400).json({ error: 'Account name is required' })
    }

    // éªŒè¯accountTypeçš„æœ‰æ•ˆæ€§
    if (
      accountData.accountType &&
      !['shared', 'dedicated', 'group'].includes(accountData.accountType)
    ) {
      return res
        .status(400)
        .json({ error: 'Invalid account type. Must be "shared", "dedicated" or "group"' })
    }

    // å¦‚æœæ˜¯åˆ†ç»„ç±»å‹ï¼ŒéªŒè¯groupId
    if (accountData.accountType === 'group' && !accountData.groupId) {
      return res.status(400).json({ error: 'Group ID is required for group type accounts' })
    }

    const newAccount = await geminiAccountService.createAccount(accountData)

    // å¦‚æœæ˜¯åˆ†ç»„ç±»å‹ï¼Œå°†è´¦æˆ·æ·»åŠ åˆ°åˆ†ç»„
    if (accountData.accountType === 'group' && accountData.groupId) {
      await accountGroupService.addAccountToGroup(newAccount.id, accountData.groupId, 'gemini')
    }

    logger.success(`ğŸ¢ Admin created new Gemini account: ${accountData.name}`)
    return res.json({ success: true, data: newAccount })
  } catch (error) {
    logger.error('âŒ Failed to create Gemini account:', error)
    return res.status(500).json({ error: 'Failed to create account', message: error.message })
  }
})

// æ›´æ–° Gemini è´¦æˆ·
router.put('/gemini-accounts/:accountId', authenticateAdmin, async (req, res) => {
  try {
    const { accountId } = req.params
    const updates = req.body

    // éªŒè¯accountTypeçš„æœ‰æ•ˆæ€§
    if (updates.accountType && !['shared', 'dedicated', 'group'].includes(updates.accountType)) {
      return res
        .status(400)
        .json({ error: 'Invalid account type. Must be "shared", "dedicated" or "group"' })
    }

    // å¦‚æœæ›´æ–°ä¸ºåˆ†ç»„ç±»å‹ï¼ŒéªŒè¯groupId
    if (updates.accountType === 'group' && !updates.groupId) {
      return res.status(400).json({ error: 'Group ID is required for group type accounts' })
    }

    // è·å–è´¦æˆ·å½“å‰ä¿¡æ¯ä»¥å¤„ç†åˆ†ç»„å˜æ›´
    const currentAccount = await geminiAccountService.getAccount(accountId)
    if (!currentAccount) {
      return res.status(404).json({ error: 'Account not found' })
    }

    // å¤„ç†åˆ†ç»„çš„å˜æ›´
    if (updates.accountType !== undefined) {
      // å¦‚æœä¹‹å‰æ˜¯åˆ†ç»„ç±»å‹ï¼Œéœ€è¦ä»åŸåˆ†ç»„ä¸­ç§»é™¤
      if (currentAccount.accountType === 'group') {
        const oldGroup = await accountGroupService.getAccountGroup(accountId)
        if (oldGroup) {
          await accountGroupService.removeAccountFromGroup(accountId, oldGroup.id)
        }
      }
      // å¦‚æœæ–°ç±»å‹æ˜¯åˆ†ç»„ï¼Œæ·»åŠ åˆ°æ–°åˆ†ç»„
      if (updates.accountType === 'group' && updates.groupId) {
        await accountGroupService.addAccountToGroup(accountId, updates.groupId, 'gemini')
      }
    }

    const updatedAccount = await geminiAccountService.updateAccount(accountId, updates)

    logger.success(`ğŸ“ Admin updated Gemini account: ${accountId}`)
    return res.json({ success: true, data: updatedAccount })
  } catch (error) {
    logger.error('âŒ Failed to update Gemini account:', error)
    return res.status(500).json({ error: 'Failed to update account', message: error.message })
  }
})

// åˆ é™¤ Gemini è´¦æˆ·
router.delete('/gemini-accounts/:accountId', authenticateAdmin, async (req, res) => {
  try {
    const { accountId } = req.params

    // è·å–è´¦æˆ·ä¿¡æ¯ä»¥æ£€æŸ¥æ˜¯å¦åœ¨åˆ†ç»„ä¸­
    const account = await geminiAccountService.getAccount(accountId)
    if (account && account.accountType === 'group') {
      const group = await accountGroupService.getAccountGroup(accountId)
      if (group) {
        await accountGroupService.removeAccountFromGroup(accountId, group.id)
      }
    }

    await geminiAccountService.deleteAccount(accountId)

    logger.success(`ğŸ—‘ï¸ Admin deleted Gemini account: ${accountId}`)
    return res.json({ success: true, message: 'Gemini account deleted successfully' })
  } catch (error) {
    logger.error('âŒ Failed to delete Gemini account:', error)
    return res.status(500).json({ error: 'Failed to delete account', message: error.message })
  }
})

// åˆ·æ–° Gemini è´¦æˆ· token
router.post('/gemini-accounts/:accountId/refresh', authenticateAdmin, async (req, res) => {
  try {
    const { accountId } = req.params

    const result = await geminiAccountService.refreshAccountToken(accountId)

    logger.success(`ğŸ”„ Admin refreshed token for Gemini account: ${accountId}`)
    return res.json({ success: true, data: result })
  } catch (error) {
    logger.error('âŒ Failed to refresh Gemini account token:', error)
    return res.status(500).json({ error: 'Failed to refresh token', message: error.message })
  }
})

// åˆ‡æ¢ Gemini è´¦æˆ·è°ƒåº¦çŠ¶æ€
router.put(
  '/gemini-accounts/:accountId/toggle-schedulable',
  authenticateAdmin,
  async (req, res) => {
    try {
      const { accountId } = req.params

      const account = await geminiAccountService.getAccount(accountId)
      if (!account) {
        return res.status(404).json({ error: 'Account not found' })
      }

      // ç°åœ¨ account.schedulable å·²ç»æ˜¯å¸ƒå°”å€¼äº†ï¼Œç›´æ¥å–åå³å¯
      const newSchedulable = !account.schedulable

      await geminiAccountService.updateAccount(accountId, { schedulable: String(newSchedulable) })

      // éªŒè¯æ›´æ–°æ˜¯å¦æˆåŠŸï¼Œé‡æ–°è·å–è´¦æˆ·ä¿¡æ¯
      const updatedAccount = await geminiAccountService.getAccount(accountId)
      const actualSchedulable = updatedAccount ? updatedAccount.schedulable : newSchedulable

      // å¦‚æœè´¦å·è¢«ç¦ç”¨ï¼Œå‘é€webhooké€šçŸ¥
      if (!actualSchedulable) {
        await webhookNotifier.sendAccountAnomalyNotification({
          accountId: account.id,
          accountName: account.accountName || 'Gemini Account',
          platform: 'gemini',
          status: 'disabled',
          errorCode: 'GEMINI_MANUALLY_DISABLED',
          reason: 'è´¦å·å·²è¢«ç®¡ç†å‘˜æ‰‹åŠ¨ç¦ç”¨è°ƒåº¦',
          timestamp: new Date().toISOString()
        })
      }

      logger.success(
        `ğŸ”„ Admin toggled Gemini account schedulable status: ${accountId} -> ${actualSchedulable ? 'schedulable' : 'not schedulable'}`
      )

      // è¿”å›å®é™…çš„æ•°æ®åº“å€¼ï¼Œç¡®ä¿å‰ç«¯çŠ¶æ€ä¸åç«¯ä¸€è‡´
      return res.json({ success: true, schedulable: actualSchedulable })
    } catch (error) {
      logger.error('âŒ Failed to toggle Gemini account schedulable status:', error)
      return res
        .status(500)
        .json({ error: 'Failed to toggle schedulable status', message: error.message })
    }
  }
)

// ğŸ“Š è´¦æˆ·ä½¿ç”¨ç»Ÿè®¡

// è·å–æ‰€æœ‰è´¦æˆ·çš„ä½¿ç”¨ç»Ÿè®¡
router.get('/accounts/usage-stats', authenticateAdmin, async (req, res) => {
  try {
    const accountsStats = await redis.getAllAccountsUsageStats()

    return res.json({
      success: true,
      data: accountsStats,
      summary: {
        totalAccounts: accountsStats.length,
        activeToday: accountsStats.filter((account) => account.daily.requests > 0).length,
        totalDailyTokens: accountsStats.reduce(
          (sum, account) => sum + (account.daily.allTokens || 0),
          0
        ),
        totalDailyRequests: accountsStats.reduce(
          (sum, account) => sum + (account.daily.requests || 0),
          0
        )
      },
      timestamp: new Date().toISOString()
    })
  } catch (error) {
    logger.error('âŒ Failed to get accounts usage stats:', error)
    return res.status(500).json({
      success: false,
      error: 'Failed to get accounts usage stats',
      message: error.message
    })
  }
})

// è·å–å•ä¸ªè´¦æˆ·çš„ä½¿ç”¨ç»Ÿè®¡
router.get('/accounts/:accountId/usage-stats', authenticateAdmin, async (req, res) => {
  try {
    const { accountId } = req.params
    const accountStats = await redis.getAccountUsageStats(accountId)

    // è·å–è´¦æˆ·åŸºæœ¬ä¿¡æ¯
    const accountData = await claudeAccountService.getAccount(accountId)
    if (!accountData) {
      return res.status(404).json({
        success: false,
        error: 'Account not found'
      })
    }

    return res.json({
      success: true,
      data: {
        ...accountStats,
        accountInfo: {
          name: accountData.name,
          email: accountData.email,
          status: accountData.status,
          isActive: accountData.isActive,
          createdAt: accountData.createdAt
        }
      },
      timestamp: new Date().toISOString()
    })
  } catch (error) {
    logger.error('âŒ Failed to get account usage stats:', error)
    return res.status(500).json({
      success: false,
      error: 'Failed to get account usage stats',
      message: error.message
    })
  }
})

// ğŸ“Š ç³»ç»Ÿç»Ÿè®¡

// è·å–ç³»ç»Ÿæ¦‚è§ˆ
router.get('/dashboard', authenticateAdmin, async (req, res) => {
  try {
    const [
      ,
      apiKeys,
      claudeAccounts,
      claudeConsoleAccounts,
      geminiAccounts,
      bedrockAccountsResult,
      openaiAccounts,
      todayStats,
      systemAverages,
      realtimeMetrics
    ] = await Promise.all([
      redis.getSystemStats(),
      apiKeyService.getAllApiKeys(),
      claudeAccountService.getAllAccounts(),
      claudeConsoleAccountService.getAllAccounts(),
      geminiAccountService.getAllAccounts(),
      bedrockAccountService.getAllAccounts(),
      redis.getAllOpenAIAccounts(),
      redis.getTodayStats(),
      redis.getSystemAverages(),
      redis.getRealtimeSystemMetrics()
    ])

    // å¤„ç†Bedrockè´¦æˆ·æ•°æ®
    const bedrockAccounts = bedrockAccountsResult.success ? bedrockAccountsResult.data : []

    // è®¡ç®—ä½¿ç”¨ç»Ÿè®¡ï¼ˆç»Ÿä¸€ä½¿ç”¨allTokensï¼‰
    const totalTokensUsed = apiKeys.reduce(
      (sum, key) => sum + (key.usage?.total?.allTokens || 0),
      0
    )
    const totalRequestsUsed = apiKeys.reduce(
      (sum, key) => sum + (key.usage?.total?.requests || 0),
      0
    )
    const totalInputTokensUsed = apiKeys.reduce(
      (sum, key) => sum + (key.usage?.total?.inputTokens || 0),
      0
    )
    const totalOutputTokensUsed = apiKeys.reduce(
      (sum, key) => sum + (key.usage?.total?.outputTokens || 0),
      0
    )
    const totalCacheCreateTokensUsed = apiKeys.reduce(
      (sum, key) => sum + (key.usage?.total?.cacheCreateTokens || 0),
      0
    )
    const totalCacheReadTokensUsed = apiKeys.reduce(
      (sum, key) => sum + (key.usage?.total?.cacheReadTokens || 0),
      0
    )
    const totalAllTokensUsed = apiKeys.reduce(
      (sum, key) => sum + (key.usage?.total?.allTokens || 0),
      0
    )

    const activeApiKeys = apiKeys.filter((key) => key.isActive).length

    // Claudeè´¦æˆ·ç»Ÿè®¡ - æ ¹æ®è´¦æˆ·ç®¡ç†é¡µé¢çš„åˆ¤æ–­é€»è¾‘
    const normalClaudeAccounts = claudeAccounts.filter(
      (acc) =>
        acc.isActive &&
        acc.status !== 'blocked' &&
        acc.status !== 'unauthorized' &&
        acc.schedulable !== false &&
        !(acc.rateLimitStatus && acc.rateLimitStatus.isRateLimited)
    ).length
    const abnormalClaudeAccounts = claudeAccounts.filter(
      (acc) => !acc.isActive || acc.status === 'blocked' || acc.status === 'unauthorized'
    ).length
    const pausedClaudeAccounts = claudeAccounts.filter(
      (acc) =>
        acc.schedulable === false &&
        acc.isActive &&
        acc.status !== 'blocked' &&
        acc.status !== 'unauthorized'
    ).length
    const rateLimitedClaudeAccounts = claudeAccounts.filter(
      (acc) => acc.rateLimitStatus && acc.rateLimitStatus.isRateLimited
    ).length

    // Claude Consoleè´¦æˆ·ç»Ÿè®¡
    const normalClaudeConsoleAccounts = claudeConsoleAccounts.filter(
      (acc) =>
        acc.isActive &&
        acc.status !== 'blocked' &&
        acc.status !== 'unauthorized' &&
        acc.schedulable !== false &&
        !(acc.rateLimitStatus && acc.rateLimitStatus.isRateLimited)
    ).length
    const abnormalClaudeConsoleAccounts = claudeConsoleAccounts.filter(
      (acc) => !acc.isActive || acc.status === 'blocked' || acc.status === 'unauthorized'
    ).length
    const pausedClaudeConsoleAccounts = claudeConsoleAccounts.filter(
      (acc) =>
        acc.schedulable === false &&
        acc.isActive &&
        acc.status !== 'blocked' &&
        acc.status !== 'unauthorized'
    ).length
    const rateLimitedClaudeConsoleAccounts = claudeConsoleAccounts.filter(
      (acc) => acc.rateLimitStatus && acc.rateLimitStatus.isRateLimited
    ).length

    // Geminiè´¦æˆ·ç»Ÿè®¡
    const normalGeminiAccounts = geminiAccounts.filter(
      (acc) =>
        acc.isActive &&
        acc.status !== 'blocked' &&
        acc.status !== 'unauthorized' &&
        acc.schedulable !== false &&
        !(
          acc.rateLimitStatus === 'limited' ||
          (acc.rateLimitStatus && acc.rateLimitStatus.isRateLimited)
        )
    ).length
    const abnormalGeminiAccounts = geminiAccounts.filter(
      (acc) => !acc.isActive || acc.status === 'blocked' || acc.status === 'unauthorized'
    ).length
    const pausedGeminiAccounts = geminiAccounts.filter(
      (acc) =>
        acc.schedulable === false &&
        acc.isActive &&
        acc.status !== 'blocked' &&
        acc.status !== 'unauthorized'
    ).length
    const rateLimitedGeminiAccounts = geminiAccounts.filter(
      (acc) =>
        acc.rateLimitStatus === 'limited' ||
        (acc.rateLimitStatus && acc.rateLimitStatus.isRateLimited)
    ).length

    // Bedrockè´¦æˆ·ç»Ÿè®¡
    const normalBedrockAccounts = bedrockAccounts.filter(
      (acc) =>
        acc.isActive &&
        acc.status !== 'blocked' &&
        acc.status !== 'unauthorized' &&
        acc.schedulable !== false &&
        !(acc.rateLimitStatus && acc.rateLimitStatus.isRateLimited)
    ).length
    const abnormalBedrockAccounts = bedrockAccounts.filter(
      (acc) => !acc.isActive || acc.status === 'blocked' || acc.status === 'unauthorized'
    ).length
    const pausedBedrockAccounts = bedrockAccounts.filter(
      (acc) =>
        acc.schedulable === false &&
        acc.isActive &&
        acc.status !== 'blocked' &&
        acc.status !== 'unauthorized'
    ).length
    const rateLimitedBedrockAccounts = bedrockAccounts.filter(
      (acc) => acc.rateLimitStatus && acc.rateLimitStatus.isRateLimited
    ).length

    // OpenAIè´¦æˆ·ç»Ÿè®¡
    // æ³¨æ„ï¼šOpenAIè´¦æˆ·çš„isActiveå’Œschedulableæ˜¯å­—ç¬¦ä¸²ç±»å‹ï¼Œé»˜è®¤å€¼ä¸º'true'
    const normalOpenAIAccounts = openaiAccounts.filter(
      (acc) =>
        (acc.isActive === 'true' ||
          acc.isActive === true ||
          (!acc.isActive && acc.isActive !== 'false' && acc.isActive !== false)) &&
        acc.status !== 'blocked' &&
        acc.status !== 'unauthorized' &&
        acc.schedulable !== 'false' &&
        acc.schedulable !== false && // åŒ…æ‹¬'true'ã€trueå’Œundefined
        !(acc.rateLimitStatus && acc.rateLimitStatus.isRateLimited)
    ).length
    const abnormalOpenAIAccounts = openaiAccounts.filter(
      (acc) =>
        acc.isActive === 'false' ||
        acc.isActive === false ||
        acc.status === 'blocked' ||
        acc.status === 'unauthorized'
    ).length
    const pausedOpenAIAccounts = openaiAccounts.filter(
      (acc) =>
        (acc.schedulable === 'false' || acc.schedulable === false) &&
        (acc.isActive === 'true' ||
          acc.isActive === true ||
          (!acc.isActive && acc.isActive !== 'false' && acc.isActive !== false)) &&
        acc.status !== 'blocked' &&
        acc.status !== 'unauthorized'
    ).length
    const rateLimitedOpenAIAccounts = openaiAccounts.filter(
      (acc) => acc.rateLimitStatus && acc.rateLimitStatus.isRateLimited
    ).length

    const dashboard = {
      overview: {
        totalApiKeys: apiKeys.length,
        activeApiKeys,
        // æ€»è´¦æˆ·ç»Ÿè®¡ï¼ˆæ‰€æœ‰å¹³å°ï¼‰
        totalAccounts:
          claudeAccounts.length +
          claudeConsoleAccounts.length +
          geminiAccounts.length +
          bedrockAccounts.length +
          openaiAccounts.length,
        normalAccounts:
          normalClaudeAccounts +
          normalClaudeConsoleAccounts +
          normalGeminiAccounts +
          normalBedrockAccounts +
          normalOpenAIAccounts,
        abnormalAccounts:
          abnormalClaudeAccounts +
          abnormalClaudeConsoleAccounts +
          abnormalGeminiAccounts +
          abnormalBedrockAccounts +
          abnormalOpenAIAccounts,
        pausedAccounts:
          pausedClaudeAccounts +
          pausedClaudeConsoleAccounts +
          pausedGeminiAccounts +
          pausedBedrockAccounts +
          pausedOpenAIAccounts,
        rateLimitedAccounts:
          rateLimitedClaudeAccounts +
          rateLimitedClaudeConsoleAccounts +
          rateLimitedGeminiAccounts +
          rateLimitedBedrockAccounts +
          rateLimitedOpenAIAccounts,
        // å„å¹³å°è¯¦ç»†ç»Ÿè®¡
        accountsByPlatform: {
          claude: {
            total: claudeAccounts.length,
            normal: normalClaudeAccounts,
            abnormal: abnormalClaudeAccounts,
            paused: pausedClaudeAccounts,
            rateLimited: rateLimitedClaudeAccounts
          },
          'claude-console': {
            total: claudeConsoleAccounts.length,
            normal: normalClaudeConsoleAccounts,
            abnormal: abnormalClaudeConsoleAccounts,
            paused: pausedClaudeConsoleAccounts,
            rateLimited: rateLimitedClaudeConsoleAccounts
          },
          gemini: {
            total: geminiAccounts.length,
            normal: normalGeminiAccounts,
            abnormal: abnormalGeminiAccounts,
            paused: pausedGeminiAccounts,
            rateLimited: rateLimitedGeminiAccounts
          },
          bedrock: {
            total: bedrockAccounts.length,
            normal: normalBedrockAccounts,
            abnormal: abnormalBedrockAccounts,
            paused: pausedBedrockAccounts,
            rateLimited: rateLimitedBedrockAccounts
          },
          openai: {
            total: openaiAccounts.length,
            normal: normalOpenAIAccounts,
            abnormal: abnormalOpenAIAccounts,
            paused: pausedOpenAIAccounts,
            rateLimited: rateLimitedOpenAIAccounts
          }
        },
        // ä¿ç•™æ—§å­—æ®µä»¥å…¼å®¹
        activeAccounts:
          normalClaudeAccounts +
          normalClaudeConsoleAccounts +
          normalGeminiAccounts +
          normalBedrockAccounts +
          normalOpenAIAccounts,
        totalClaudeAccounts: claudeAccounts.length + claudeConsoleAccounts.length,
        activeClaudeAccounts: normalClaudeAccounts + normalClaudeConsoleAccounts,
        rateLimitedClaudeAccounts: rateLimitedClaudeAccounts + rateLimitedClaudeConsoleAccounts,
        totalGeminiAccounts: geminiAccounts.length,
        activeGeminiAccounts: normalGeminiAccounts,
        rateLimitedGeminiAccounts,
        totalTokensUsed,
        totalRequestsUsed,
        totalInputTokensUsed,
        totalOutputTokensUsed,
        totalCacheCreateTokensUsed,
        totalCacheReadTokensUsed,
        totalAllTokensUsed
      },
      recentActivity: {
        apiKeysCreatedToday: todayStats.apiKeysCreatedToday,
        requestsToday: todayStats.requestsToday,
        tokensToday: todayStats.tokensToday,
        inputTokensToday: todayStats.inputTokensToday,
        outputTokensToday: todayStats.outputTokensToday,
        cacheCreateTokensToday: todayStats.cacheCreateTokensToday || 0,
        cacheReadTokensToday: todayStats.cacheReadTokensToday || 0
      },
      systemAverages: {
        rpm: systemAverages.systemRPM,
        tpm: systemAverages.systemTPM
      },
      realtimeMetrics: {
        rpm: realtimeMetrics.realtimeRPM,
        tpm: realtimeMetrics.realtimeTPM,
        windowMinutes: realtimeMetrics.windowMinutes,
        isHistorical: realtimeMetrics.windowMinutes === 0 // æ ‡è¯†æ˜¯å¦ä½¿ç”¨äº†å†å²æ•°æ®
      },
      systemHealth: {
        redisConnected: redis.isConnected,
        claudeAccountsHealthy: normalClaudeAccounts + normalClaudeConsoleAccounts > 0,
        geminiAccountsHealthy: normalGeminiAccounts > 0,
        uptime: process.uptime()
      },
      systemTimezone: config.system.timezoneOffset || 8
    }

    return res.json({ success: true, data: dashboard })
  } catch (error) {
    logger.error('âŒ Failed to get dashboard data:', error)
    return res.status(500).json({ error: 'Failed to get dashboard data', message: error.message })
  }
})

// è·å–ä½¿ç”¨ç»Ÿè®¡
router.get('/usage-stats', authenticateAdmin, async (req, res) => {
  try {
    const { period = 'daily' } = req.query // daily, monthly

    // è·å–åŸºç¡€API Keyç»Ÿè®¡
    const apiKeys = await apiKeyService.getAllApiKeys()

    const stats = apiKeys.map((key) => ({
      keyId: key.id,
      keyName: key.name,
      usage: key.usage
    }))

    return res.json({ success: true, data: { period, stats } })
  } catch (error) {
    logger.error('âŒ Failed to get usage stats:', error)
    return res.status(500).json({ error: 'Failed to get usage stats', message: error.message })
  }
})

// è·å–æŒ‰æ¨¡å‹çš„ä½¿ç”¨ç»Ÿè®¡å’Œè´¹ç”¨
router.get('/model-stats', authenticateAdmin, async (req, res) => {
  try {
    const { period = 'daily', startDate, endDate } = req.query // daily, monthly, æ”¯æŒè‡ªå®šä¹‰æ—¶é—´èŒƒå›´
    const today = redis.getDateStringInTimezone()
    const tzDate = redis.getDateInTimezone()
    const currentMonth = `${tzDate.getUTCFullYear()}-${String(tzDate.getUTCMonth() + 1).padStart(2, '0')}`

    logger.info(
      `ğŸ“Š Getting global model stats, period: ${period}, startDate: ${startDate}, endDate: ${endDate}, today: ${today}, currentMonth: ${currentMonth}`
    )

    const client = redis.getClientSafe()

    // è·å–æ‰€æœ‰æ¨¡å‹çš„ç»Ÿè®¡æ•°æ®
    let searchPatterns = []

    if (startDate && endDate) {
      // è‡ªå®šä¹‰æ—¥æœŸèŒƒå›´ï¼Œç”Ÿæˆå¤šä¸ªæ—¥æœŸçš„æœç´¢æ¨¡å¼
      const start = new Date(startDate)
      const end = new Date(endDate)

      // ç¡®ä¿æ—¥æœŸèŒƒå›´æœ‰æ•ˆ
      if (start > end) {
        return res.status(400).json({ error: 'Start date must be before or equal to end date' })
      }

      // é™åˆ¶æœ€å¤§èŒƒå›´ä¸º31å¤©
      const daysDiff = Math.ceil((end - start) / (1000 * 60 * 60 * 24)) + 1
      if (daysDiff > 31) {
        return res.status(400).json({ error: 'Date range cannot exceed 31 days' })
      }

      // ç”Ÿæˆæ—¥æœŸèŒƒå›´å†…æ‰€æœ‰æ—¥æœŸçš„æœç´¢æ¨¡å¼
      const currentDate = new Date(start)
      while (currentDate <= end) {
        const dateStr = redis.getDateStringInTimezone(currentDate)
        searchPatterns.push(`usage:model:daily:*:${dateStr}`)
        currentDate.setDate(currentDate.getDate() + 1)
      }

      logger.info(`ğŸ“Š Generated ${searchPatterns.length} search patterns for date range`)
    } else {
      // ä½¿ç”¨é»˜è®¤çš„period
      const pattern =
        period === 'daily'
          ? `usage:model:daily:*:${today}`
          : `usage:model:monthly:*:${currentMonth}`
      searchPatterns = [pattern]
    }

    logger.info('ğŸ“Š Searching patterns:', searchPatterns)

    // è·å–æ‰€æœ‰åŒ¹é…çš„keys
    const allKeys = []
    for (const pattern of searchPatterns) {
      const keys = await client.keys(pattern)
      allKeys.push(...keys)
    }

    logger.info(`ğŸ“Š Found ${allKeys.length} matching keys in total`)

    // æ¨¡å‹åæ ‡å‡†åŒ–å‡½æ•°ï¼ˆä¸redis.jsä¿æŒä¸€è‡´ï¼‰
    const normalizeModelName = (model) => {
      if (!model || model === 'unknown') {
        return model
      }

      // å¯¹äºBedrockæ¨¡å‹ï¼Œå»æ‰åŒºåŸŸå‰ç¼€è¿›è¡Œç»Ÿä¸€
      if (model.includes('.anthropic.') || model.includes('.claude')) {
        // åŒ¹é…æ‰€æœ‰AWSåŒºåŸŸæ ¼å¼ï¼šregion.anthropic.model-name-v1:0 -> claude-model-name
        // æ”¯æŒæ‰€æœ‰AWSåŒºåŸŸæ ¼å¼ï¼Œå¦‚ï¼šus-east-1, eu-west-1, ap-southeast-1, ca-central-1ç­‰
        let normalized = model.replace(/^[a-z0-9-]+\./, '') // å»æ‰ä»»ä½•åŒºåŸŸå‰ç¼€ï¼ˆæ›´é€šç”¨ï¼‰
        normalized = normalized.replace('anthropic.', '') // å»æ‰anthropicå‰ç¼€
        normalized = normalized.replace(/-v\d+:\d+$/, '') // å»æ‰ç‰ˆæœ¬åç¼€ï¼ˆå¦‚-v1:0, -v2:1ç­‰ï¼‰
        return normalized
      }

      // å¯¹äºå…¶ä»–æ¨¡å‹ï¼Œå»æ‰å¸¸è§çš„ç‰ˆæœ¬åç¼€
      return model.replace(/-v\d+:\d+$|:latest$/, '')
    }

    // èšåˆç›¸åŒæ¨¡å‹çš„æ•°æ®
    const modelStatsMap = new Map()

    for (const key of allKeys) {
      const match = key.match(/usage:model:daily:(.+):\d{4}-\d{2}-\d{2}$/)

      if (!match) {
        logger.warn(`ğŸ“Š Pattern mismatch for key: ${key}`)
        continue
      }

      const rawModel = match[1]
      const normalizedModel = normalizeModelName(rawModel)
      const data = await client.hgetall(key)

      if (data && Object.keys(data).length > 0) {
        const stats = modelStatsMap.get(normalizedModel) || {
          requests: 0,
          inputTokens: 0,
          outputTokens: 0,
          cacheCreateTokens: 0,
          cacheReadTokens: 0,
          allTokens: 0
        }

        stats.requests += parseInt(data.requests) || 0
        stats.inputTokens += parseInt(data.inputTokens) || 0
        stats.outputTokens += parseInt(data.outputTokens) || 0
        stats.cacheCreateTokens += parseInt(data.cacheCreateTokens) || 0
        stats.cacheReadTokens += parseInt(data.cacheReadTokens) || 0
        stats.allTokens += parseInt(data.allTokens) || 0

        modelStatsMap.set(normalizedModel, stats)
      }
    }

    // è½¬æ¢ä¸ºæ•°ç»„å¹¶è®¡ç®—è´¹ç”¨
    const modelStats = []

    for (const [model, stats] of modelStatsMap) {
      const usage = {
        input_tokens: stats.inputTokens,
        output_tokens: stats.outputTokens,
        cache_creation_input_tokens: stats.cacheCreateTokens,
        cache_read_input_tokens: stats.cacheReadTokens
      }

      // è®¡ç®—è´¹ç”¨
      const costData = CostCalculator.calculateCost(usage, model)

      modelStats.push({
        model,
        period: startDate && endDate ? 'custom' : period,
        requests: stats.requests,
        inputTokens: usage.input_tokens,
        outputTokens: usage.output_tokens,
        cacheCreateTokens: usage.cache_creation_input_tokens,
        cacheReadTokens: usage.cache_read_input_tokens,
        allTokens: stats.allTokens,
        usage: {
          requests: stats.requests,
          inputTokens: usage.input_tokens,
          outputTokens: usage.output_tokens,
          cacheCreateTokens: usage.cache_creation_input_tokens,
          cacheReadTokens: usage.cache_read_input_tokens,
          totalTokens:
            usage.input_tokens +
            usage.output_tokens +
            usage.cache_creation_input_tokens +
            usage.cache_read_input_tokens
        },
        costs: costData.costs,
        formatted: costData.formatted,
        pricing: costData.pricing
      })
    }

    // æŒ‰æ€»è´¹ç”¨æ’åº
    modelStats.sort((a, b) => b.costs.total - a.costs.total)

    logger.info(
      `ğŸ“Š Returning ${modelStats.length} global model stats for period ${period}:`,
      modelStats
    )

    return res.json({ success: true, data: modelStats })
  } catch (error) {
    logger.error('âŒ Failed to get model stats:', error)
    return res.status(500).json({ error: 'Failed to get model stats', message: error.message })
  }
})

// ğŸ”§ ç³»ç»Ÿç®¡ç†

// æ¸…ç†è¿‡æœŸæ•°æ®
router.post('/cleanup', authenticateAdmin, async (req, res) => {
  try {
    const [expiredKeys, errorAccounts] = await Promise.all([
      apiKeyService.cleanupExpiredKeys(),
      claudeAccountService.cleanupErrorAccounts()
    ])

    await redis.cleanup()

    logger.success(
      `ğŸ§¹ Admin triggered cleanup: ${expiredKeys} expired keys, ${errorAccounts} error accounts`
    )

    return res.json({
      success: true,
      message: 'Cleanup completed',
      data: {
        expiredKeysRemoved: expiredKeys,
        errorAccountsReset: errorAccounts
      }
    })
  } catch (error) {
    logger.error('âŒ Cleanup failed:', error)
    return res.status(500).json({ error: 'Cleanup failed', message: error.message })
  }
})

// è·å–ä½¿ç”¨è¶‹åŠ¿æ•°æ®
router.get('/usage-trend', authenticateAdmin, async (req, res) => {
  try {
    const { days = 7, granularity = 'day', startDate, endDate } = req.query
    const client = redis.getClientSafe()

    const trendData = []

    if (granularity === 'hour') {
      // å°æ—¶ç²’åº¦ç»Ÿè®¡
      let startTime, endTime

      if (startDate && endDate) {
        // ä½¿ç”¨è‡ªå®šä¹‰æ—¶é—´èŒƒå›´
        startTime = new Date(startDate)
        endTime = new Date(endDate)

        // è°ƒè¯•æ—¥å¿—
        logger.info('ğŸ“Š Usage trend hour granularity - received times:')
        logger.info(`  startDate (raw): ${startDate}`)
        logger.info(`  endDate (raw): ${endDate}`)
        logger.info(`  startTime (parsed): ${startTime.toISOString()}`)
        logger.info(`  endTime (parsed): ${endTime.toISOString()}`)
        logger.info(`  System timezone offset: ${config.system.timezoneOffset || 8}`)
      } else {
        // é»˜è®¤æœ€è¿‘24å°æ—¶
        endTime = new Date()
        startTime = new Date(endTime.getTime() - 24 * 60 * 60 * 1000)
      }

      // ç¡®ä¿æ—¶é—´èŒƒå›´ä¸è¶…è¿‡24å°æ—¶
      const timeDiff = endTime - startTime
      if (timeDiff > 24 * 60 * 60 * 1000) {
        return res.status(400).json({
          error: 'å°æ—¶ç²’åº¦æŸ¥è¯¢æ—¶é—´èŒƒå›´ä¸èƒ½è¶…è¿‡24å°æ—¶'
        })
      }

      // æŒ‰å°æ—¶éå†
      const currentHour = new Date(startTime)
      currentHour.setMinutes(0, 0, 0)

      while (currentHour <= endTime) {
        // æ³¨æ„ï¼šå‰ç«¯å‘é€çš„æ—¶é—´å·²ç»æ˜¯UTCæ—¶é—´ï¼Œä¸éœ€è¦å†æ¬¡è½¬æ¢
        // ç›´æ¥ä»currentHourç”Ÿæˆå¯¹åº”ç³»ç»Ÿæ—¶åŒºçš„æ—¥æœŸå’Œå°æ—¶
        const tzCurrentHour = redis.getDateInTimezone(currentHour)
        const dateStr = redis.getDateStringInTimezone(currentHour)
        const hour = String(tzCurrentHour.getUTCHours()).padStart(2, '0')
        const hourKey = `${dateStr}:${hour}`

        // è·å–å½“å‰å°æ—¶çš„æ¨¡å‹ç»Ÿè®¡æ•°æ®
        const modelPattern = `usage:model:hourly:*:${hourKey}`
        const modelKeys = await client.keys(modelPattern)

        let hourInputTokens = 0
        let hourOutputTokens = 0
        let hourRequests = 0
        let hourCacheCreateTokens = 0
        let hourCacheReadTokens = 0
        let hourCost = 0

        for (const modelKey of modelKeys) {
          const modelMatch = modelKey.match(/usage:model:hourly:(.+):\d{4}-\d{2}-\d{2}:\d{2}$/)
          if (!modelMatch) {
            continue
          }

          const model = modelMatch[1]
          const data = await client.hgetall(modelKey)

          if (data && Object.keys(data).length > 0) {
            const modelInputTokens = parseInt(data.inputTokens) || 0
            const modelOutputTokens = parseInt(data.outputTokens) || 0
            const modelCacheCreateTokens = parseInt(data.cacheCreateTokens) || 0
            const modelCacheReadTokens = parseInt(data.cacheReadTokens) || 0
            const modelRequests = parseInt(data.requests) || 0

            hourInputTokens += modelInputTokens
            hourOutputTokens += modelOutputTokens
            hourCacheCreateTokens += modelCacheCreateTokens
            hourCacheReadTokens += modelCacheReadTokens
            hourRequests += modelRequests

            const modelUsage = {
              input_tokens: modelInputTokens,
              output_tokens: modelOutputTokens,
              cache_creation_input_tokens: modelCacheCreateTokens,
              cache_read_input_tokens: modelCacheReadTokens
            }
            const modelCostResult = CostCalculator.calculateCost(modelUsage, model)
            hourCost += modelCostResult.costs.total
          }
        }

        // å¦‚æœæ²¡æœ‰æ¨¡å‹çº§åˆ«çš„æ•°æ®ï¼Œå°è¯•API Keyçº§åˆ«çš„æ•°æ®
        if (modelKeys.length === 0) {
          const pattern = `usage:hourly:*:${hourKey}`
          const keys = await client.keys(pattern)

          for (const key of keys) {
            const data = await client.hgetall(key)
            if (data) {
              hourInputTokens += parseInt(data.inputTokens) || 0
              hourOutputTokens += parseInt(data.outputTokens) || 0
              hourRequests += parseInt(data.requests) || 0
              hourCacheCreateTokens += parseInt(data.cacheCreateTokens) || 0
              hourCacheReadTokens += parseInt(data.cacheReadTokens) || 0
            }
          }

          const usage = {
            input_tokens: hourInputTokens,
            output_tokens: hourOutputTokens,
            cache_creation_input_tokens: hourCacheCreateTokens,
            cache_read_input_tokens: hourCacheReadTokens
          }
          const costResult = CostCalculator.calculateCost(usage, 'unknown')
          hourCost = costResult.costs.total
        }

        // æ ¼å¼åŒ–æ—¶é—´æ ‡ç­¾ - ä½¿ç”¨ç³»ç»Ÿæ—¶åŒºçš„æ˜¾ç¤º
        const tzDateForLabel = redis.getDateInTimezone(currentHour)
        const month = String(tzDateForLabel.getUTCMonth() + 1).padStart(2, '0')
        const day = String(tzDateForLabel.getUTCDate()).padStart(2, '0')
        const hourStr = String(tzDateForLabel.getUTCHours()).padStart(2, '0')

        trendData.push({
          // å¯¹äºå°æ—¶ç²’åº¦ï¼Œåªè¿”å›hourå­—æ®µï¼Œä¸è¿”å›dateå­—æ®µ
          hour: currentHour.toISOString(), // ä¿ç•™åŸå§‹ISOæ—¶é—´ç”¨äºæ’åº
          label: `${month}/${day} ${hourStr}:00`, // æ·»åŠ æ ¼å¼åŒ–çš„æ ‡ç­¾
          inputTokens: hourInputTokens,
          outputTokens: hourOutputTokens,
          requests: hourRequests,
          cacheCreateTokens: hourCacheCreateTokens,
          cacheReadTokens: hourCacheReadTokens,
          totalTokens:
            hourInputTokens + hourOutputTokens + hourCacheCreateTokens + hourCacheReadTokens,
          cost: hourCost
        })

        // ç§»åˆ°ä¸‹ä¸€ä¸ªå°æ—¶
        currentHour.setHours(currentHour.getHours() + 1)
      }
    } else {
      // å¤©ç²’åº¦ç»Ÿè®¡ï¼ˆä¿æŒåŸæœ‰é€»è¾‘ï¼‰
      const daysCount = parseInt(days) || 7
      const today = new Date()

      // è·å–è¿‡å»Nå¤©çš„æ•°æ®
      for (let i = 0; i < daysCount; i++) {
        const date = new Date(today)
        date.setDate(date.getDate() - i)
        const dateStr = redis.getDateStringInTimezone(date)

        // æ±‡æ€»å½“å¤©æ‰€æœ‰API Keyçš„ä½¿ç”¨æ•°æ®
        const pattern = `usage:daily:*:${dateStr}`
        const keys = await client.keys(pattern)

        let dayInputTokens = 0
        let dayOutputTokens = 0
        let dayRequests = 0
        let dayCacheCreateTokens = 0
        let dayCacheReadTokens = 0
        let dayCost = 0

        // æŒ‰æ¨¡å‹ç»Ÿè®¡ä½¿ç”¨é‡
        // const modelUsageMap = new Map();

        // è·å–å½“å¤©æ‰€æœ‰æ¨¡å‹çš„ä½¿ç”¨æ•°æ®
        const modelPattern = `usage:model:daily:*:${dateStr}`
        const modelKeys = await client.keys(modelPattern)

        for (const modelKey of modelKeys) {
          // è§£ææ¨¡å‹åç§°
          const modelMatch = modelKey.match(/usage:model:daily:(.+):\d{4}-\d{2}-\d{2}$/)
          if (!modelMatch) {
            continue
          }

          const model = modelMatch[1]
          const data = await client.hgetall(modelKey)

          if (data && Object.keys(data).length > 0) {
            const modelInputTokens = parseInt(data.inputTokens) || 0
            const modelOutputTokens = parseInt(data.outputTokens) || 0
            const modelCacheCreateTokens = parseInt(data.cacheCreateTokens) || 0
            const modelCacheReadTokens = parseInt(data.cacheReadTokens) || 0
            const modelRequests = parseInt(data.requests) || 0

            // ç´¯åŠ æ€»æ•°
            dayInputTokens += modelInputTokens
            dayOutputTokens += modelOutputTokens
            dayCacheCreateTokens += modelCacheCreateTokens
            dayCacheReadTokens += modelCacheReadTokens
            dayRequests += modelRequests

            // æŒ‰æ¨¡å‹è®¡ç®—è´¹ç”¨
            const modelUsage = {
              input_tokens: modelInputTokens,
              output_tokens: modelOutputTokens,
              cache_creation_input_tokens: modelCacheCreateTokens,
              cache_read_input_tokens: modelCacheReadTokens
            }
            const modelCostResult = CostCalculator.calculateCost(modelUsage, model)
            dayCost += modelCostResult.costs.total
          }
        }

        // å¦‚æœæ²¡æœ‰æ¨¡å‹çº§åˆ«çš„æ•°æ®ï¼Œå›é€€åˆ°åŸå§‹æ–¹æ³•
        if (modelKeys.length === 0 && keys.length > 0) {
          for (const key of keys) {
            const data = await client.hgetall(key)
            if (data) {
              dayInputTokens += parseInt(data.inputTokens) || 0
              dayOutputTokens += parseInt(data.outputTokens) || 0
              dayRequests += parseInt(data.requests) || 0
              dayCacheCreateTokens += parseInt(data.cacheCreateTokens) || 0
              dayCacheReadTokens += parseInt(data.cacheReadTokens) || 0
            }
          }

          // ä½¿ç”¨é»˜è®¤æ¨¡å‹ä»·æ ¼è®¡ç®—
          const usage = {
            input_tokens: dayInputTokens,
            output_tokens: dayOutputTokens,
            cache_creation_input_tokens: dayCacheCreateTokens,
            cache_read_input_tokens: dayCacheReadTokens
          }
          const costResult = CostCalculator.calculateCost(usage, 'unknown')
          dayCost = costResult.costs.total
        }

        trendData.push({
          date: dateStr,
          inputTokens: dayInputTokens,
          outputTokens: dayOutputTokens,
          requests: dayRequests,
          cacheCreateTokens: dayCacheCreateTokens,
          cacheReadTokens: dayCacheReadTokens,
          totalTokens: dayInputTokens + dayOutputTokens + dayCacheCreateTokens + dayCacheReadTokens,
          cost: dayCost,
          formattedCost: CostCalculator.formatCost(dayCost)
        })
      }
    }

    // æŒ‰æ—¥æœŸæ­£åºæ’åˆ—
    if (granularity === 'hour') {
      trendData.sort((a, b) => new Date(a.hour) - new Date(b.hour))
    } else {
      trendData.sort((a, b) => new Date(a.date) - new Date(b.date))
    }

    return res.json({ success: true, data: trendData, granularity })
  } catch (error) {
    logger.error('âŒ Failed to get usage trend:', error)
    return res.status(500).json({ error: 'Failed to get usage trend', message: error.message })
  }
})

// è·å–å•ä¸ªAPI Keyçš„æ¨¡å‹ç»Ÿè®¡
router.get('/api-keys/:keyId/model-stats', authenticateAdmin, async (req, res) => {
  try {
    const { keyId } = req.params
    const { period = 'monthly', startDate, endDate } = req.query

    logger.info(
      `ğŸ“Š Getting model stats for API key: ${keyId}, period: ${period}, startDate: ${startDate}, endDate: ${endDate}`
    )

    const client = redis.getClientSafe()
    const today = redis.getDateStringInTimezone()
    const tzDate = redis.getDateInTimezone()
    const currentMonth = `${tzDate.getUTCFullYear()}-${String(tzDate.getUTCMonth() + 1).padStart(2, '0')}`

    let searchPatterns = []

    if (period === 'custom' && startDate && endDate) {
      // è‡ªå®šä¹‰æ—¥æœŸèŒƒå›´ï¼Œç”Ÿæˆå¤šä¸ªæ—¥æœŸçš„æœç´¢æ¨¡å¼
      const start = new Date(startDate)
      const end = new Date(endDate)

      // ç¡®ä¿æ—¥æœŸèŒƒå›´æœ‰æ•ˆ
      if (start > end) {
        return res.status(400).json({ error: 'Start date must be before or equal to end date' })
      }

      // é™åˆ¶æœ€å¤§èŒƒå›´ä¸º31å¤©
      const daysDiff = Math.ceil((end - start) / (1000 * 60 * 60 * 24)) + 1
      if (daysDiff > 31) {
        return res.status(400).json({ error: 'Date range cannot exceed 31 days' })
      }

      // ç”Ÿæˆæ—¥æœŸèŒƒå›´å†…æ‰€æœ‰æ—¥æœŸçš„æœç´¢æ¨¡å¼
      for (let d = new Date(start); d <= end; d.setDate(d.getDate() + 1)) {
        const dateStr = redis.getDateStringInTimezone(d)
        searchPatterns.push(`usage:${keyId}:model:daily:*:${dateStr}`)
      }

      logger.info(
        `ğŸ“Š Custom date range patterns: ${searchPatterns.length} days from ${startDate} to ${endDate}`
      )
    } else {
      // åŸæœ‰çš„é¢„è®¾æœŸé—´é€»è¾‘
      const pattern =
        period === 'daily'
          ? `usage:${keyId}:model:daily:*:${today}`
          : `usage:${keyId}:model:monthly:*:${currentMonth}`
      searchPatterns = [pattern]
      logger.info(`ğŸ“Š Preset period pattern: ${pattern}`)
    }

    // æ±‡æ€»æ‰€æœ‰åŒ¹é…çš„æ•°æ®
    const modelStatsMap = new Map()
    const modelStats = [] // å®šä¹‰ç»“æœæ•°ç»„

    for (const pattern of searchPatterns) {
      const keys = await client.keys(pattern)
      logger.info(`ğŸ“Š Pattern ${pattern} found ${keys.length} keys`)

      for (const key of keys) {
        const match =
          key.match(/usage:.+:model:daily:(.+):\d{4}-\d{2}-\d{2}$/) ||
          key.match(/usage:.+:model:monthly:(.+):\d{4}-\d{2}$/)

        if (!match) {
          logger.warn(`ğŸ“Š Pattern mismatch for key: ${key}`)
          continue
        }

        const model = match[1]
        const data = await client.hgetall(key)

        if (data && Object.keys(data).length > 0) {
          // ç´¯åŠ åŒä¸€æ¨¡å‹çš„æ•°æ®
          if (!modelStatsMap.has(model)) {
            modelStatsMap.set(model, {
              requests: 0,
              inputTokens: 0,
              outputTokens: 0,
              cacheCreateTokens: 0,
              cacheReadTokens: 0,
              allTokens: 0
            })
          }

          const stats = modelStatsMap.get(model)
          stats.requests += parseInt(data.requests) || 0
          stats.inputTokens += parseInt(data.inputTokens) || 0
          stats.outputTokens += parseInt(data.outputTokens) || 0
          stats.cacheCreateTokens += parseInt(data.cacheCreateTokens) || 0
          stats.cacheReadTokens += parseInt(data.cacheReadTokens) || 0
          stats.allTokens += parseInt(data.allTokens) || 0
        }
      }
    }

    // å°†æ±‡æ€»çš„æ•°æ®è½¬æ¢ä¸ºæœ€ç»ˆç»“æœ
    for (const [model, stats] of modelStatsMap) {
      logger.info(`ğŸ“Š Model ${model} aggregated data:`, stats)

      const usage = {
        input_tokens: stats.inputTokens,
        output_tokens: stats.outputTokens,
        cache_creation_input_tokens: stats.cacheCreateTokens,
        cache_read_input_tokens: stats.cacheReadTokens
      }

      // ä½¿ç”¨CostCalculatorè®¡ç®—è´¹ç”¨
      const costData = CostCalculator.calculateCost(usage, model)

      modelStats.push({
        model,
        requests: stats.requests,
        inputTokens: stats.inputTokens,
        outputTokens: stats.outputTokens,
        cacheCreateTokens: stats.cacheCreateTokens,
        cacheReadTokens: stats.cacheReadTokens,
        allTokens: stats.allTokens,
        // æ·»åŠ è´¹ç”¨ä¿¡æ¯
        costs: costData.costs,
        formatted: costData.formatted,
        pricing: costData.pricing,
        usingDynamicPricing: costData.usingDynamicPricing
      })
    }

    // å¦‚æœæ²¡æœ‰æ‰¾åˆ°æ¨¡å‹çº§åˆ«çš„è¯¦ç»†æ•°æ®ï¼Œå°è¯•ä»æ±‡æ€»æ•°æ®ä¸­ç”Ÿæˆå±•ç¤º
    if (modelStats.length === 0) {
      logger.info(
        `ğŸ“Š No detailed model stats found, trying to get aggregate data for API key ${keyId}`
      )

      // å°è¯•ä»API Keysåˆ—è¡¨ä¸­è·å–usageæ•°æ®ä½œä¸ºå¤‡é€‰æ–¹æ¡ˆ
      try {
        const apiKeys = await apiKeyService.getAllApiKeys()
        const targetApiKey = apiKeys.find((key) => key.id === keyId)

        if (targetApiKey && targetApiKey.usage) {
          logger.info(
            `ğŸ“Š Found API key usage data from getAllApiKeys for ${keyId}:`,
            targetApiKey.usage
          )

          // ä»æ±‡æ€»æ•°æ®åˆ›å»ºå±•ç¤ºæ¡ç›®
          let usageData
          if (period === 'custom' || period === 'daily') {
            // å¯¹äºè‡ªå®šä¹‰æˆ–æ—¥ç»Ÿè®¡ï¼Œä½¿ç”¨dailyæ•°æ®æˆ–totalæ•°æ®
            usageData = targetApiKey.usage.daily || targetApiKey.usage.total
          } else {
            // å¯¹äºæœˆç»Ÿè®¡ï¼Œä½¿ç”¨monthlyæ•°æ®æˆ–totalæ•°æ®
            usageData = targetApiKey.usage.monthly || targetApiKey.usage.total
          }

          if (usageData && usageData.allTokens > 0) {
            const usage = {
              input_tokens: usageData.inputTokens || 0,
              output_tokens: usageData.outputTokens || 0,
              cache_creation_input_tokens: usageData.cacheCreateTokens || 0,
              cache_read_input_tokens: usageData.cacheReadTokens || 0
            }

            // å¯¹äºæ±‡æ€»æ•°æ®ï¼Œä½¿ç”¨é»˜è®¤æ¨¡å‹è®¡ç®—è´¹ç”¨
            const costData = CostCalculator.calculateCost(usage, 'claude-3-5-sonnet-20241022')

            modelStats.push({
              model: 'æ€»ä½“ä½¿ç”¨ (å†å²æ•°æ®)',
              requests: usageData.requests || 0,
              inputTokens: usageData.inputTokens || 0,
              outputTokens: usageData.outputTokens || 0,
              cacheCreateTokens: usageData.cacheCreateTokens || 0,
              cacheReadTokens: usageData.cacheReadTokens || 0,
              allTokens: usageData.allTokens || 0,
              // æ·»åŠ è´¹ç”¨ä¿¡æ¯
              costs: costData.costs,
              formatted: costData.formatted,
              pricing: costData.pricing,
              usingDynamicPricing: costData.usingDynamicPricing
            })

            logger.info('ğŸ“Š Generated display data from API key usage stats')
          } else {
            logger.info(`ğŸ“Š No usage data found for period ${period} in API key data`)
          }
        } else {
          logger.info(`ğŸ“Š API key ${keyId} not found or has no usage data`)
        }
      } catch (error) {
        logger.error('âŒ Error fetching API key usage data:', error)
      }
    }

    // æŒ‰æ€»tokenæ•°é™åºæ’åˆ—
    modelStats.sort((a, b) => b.allTokens - a.allTokens)

    logger.info(`ğŸ“Š Returning ${modelStats.length} model stats for API key ${keyId}:`, modelStats)

    return res.json({ success: true, data: modelStats })
  } catch (error) {
    logger.error('âŒ Failed to get API key model stats:', error)
    return res
      .status(500)
      .json({ error: 'Failed to get API key model stats', message: error.message })
  }
})

// è·å–æŒ‰API Keyåˆ†ç»„çš„ä½¿ç”¨è¶‹åŠ¿
router.get('/api-keys-usage-trend', authenticateAdmin, async (req, res) => {
  try {
    const { granularity = 'day', days = 7, startDate, endDate } = req.query

    logger.info(`ğŸ“Š Getting API keys usage trend, granularity: ${granularity}, days: ${days}`)

    const client = redis.getClientSafe()
    const trendData = []

    // è·å–æ‰€æœ‰API Keys
    const apiKeys = await apiKeyService.getAllApiKeys()
    const apiKeyMap = new Map(apiKeys.map((key) => [key.id, key]))

    if (granularity === 'hour') {
      // å°æ—¶ç²’åº¦ç»Ÿè®¡
      let endTime, startTime

      if (startDate && endDate) {
        // è‡ªå®šä¹‰æ—¶é—´èŒƒå›´
        startTime = new Date(startDate)
        endTime = new Date(endDate)
      } else {
        // é»˜è®¤è¿‘24å°æ—¶
        endTime = new Date()
        startTime = new Date(endTime.getTime() - 24 * 60 * 60 * 1000)
      }

      // æŒ‰å°æ—¶éå†
      const currentHour = new Date(startTime)
      currentHour.setMinutes(0, 0, 0)

      while (currentHour <= endTime) {
        // ä½¿ç”¨æ—¶åŒºè½¬æ¢åçš„æ—¶é—´æ¥ç”Ÿæˆé”®
        const tzCurrentHour = redis.getDateInTimezone(currentHour)
        const dateStr = redis.getDateStringInTimezone(currentHour)
        const hour = String(tzCurrentHour.getUTCHours()).padStart(2, '0')
        const hourKey = `${dateStr}:${hour}`

        // è·å–è¿™ä¸ªå°æ—¶æ‰€æœ‰API Keyçš„æ•°æ®
        const pattern = `usage:hourly:*:${hourKey}`
        const keys = await client.keys(pattern)

        // æ ¼å¼åŒ–æ—¶é—´æ ‡ç­¾
        const tzDateForLabel = redis.getDateInTimezone(currentHour)
        const monthLabel = String(tzDateForLabel.getUTCMonth() + 1).padStart(2, '0')
        const dayLabel = String(tzDateForLabel.getUTCDate()).padStart(2, '0')
        const hourLabel = String(tzDateForLabel.getUTCHours()).padStart(2, '0')

        const hourData = {
          hour: currentHour.toISOString(), // ä½¿ç”¨åŸå§‹æ—¶é—´ï¼Œä¸è¿›è¡Œæ—¶åŒºè½¬æ¢
          label: `${monthLabel}/${dayLabel} ${hourLabel}:00`, // æ·»åŠ æ ¼å¼åŒ–çš„æ ‡ç­¾
          apiKeys: {}
        }

        // å…ˆæ”¶é›†åŸºç¡€æ•°æ®
        const apiKeyDataMap = new Map()
        for (const key of keys) {
          const match = key.match(/usage:hourly:(.+?):\d{4}-\d{2}-\d{2}:\d{2}/)
          if (!match) {
            continue
          }

          const apiKeyId = match[1]
          const data = await client.hgetall(key)

          if (data && apiKeyMap.has(apiKeyId)) {
            const inputTokens = parseInt(data.inputTokens) || 0
            const outputTokens = parseInt(data.outputTokens) || 0
            const cacheCreateTokens = parseInt(data.cacheCreateTokens) || 0
            const cacheReadTokens = parseInt(data.cacheReadTokens) || 0
            const totalTokens = inputTokens + outputTokens + cacheCreateTokens + cacheReadTokens

            apiKeyDataMap.set(apiKeyId, {
              name: apiKeyMap.get(apiKeyId).name,
              tokens: totalTokens,
              requests: parseInt(data.requests) || 0,
              inputTokens,
              outputTokens,
              cacheCreateTokens,
              cacheReadTokens
            })
          }
        }

        // è·å–è¯¥å°æ—¶çš„æ¨¡å‹çº§åˆ«æ•°æ®æ¥è®¡ç®—å‡†ç¡®è´¹ç”¨
        const modelPattern = `usage:*:model:hourly:*:${hourKey}`
        const modelKeys = await client.keys(modelPattern)
        const apiKeyCostMap = new Map()

        for (const modelKey of modelKeys) {
          const match = modelKey.match(/usage:(.+?):model:hourly:(.+?):\d{4}-\d{2}-\d{2}:\d{2}/)
          if (!match) {
            continue
          }

          const apiKeyId = match[1]
          const model = match[2]
          const modelData = await client.hgetall(modelKey)

          if (modelData && apiKeyDataMap.has(apiKeyId)) {
            const usage = {
              input_tokens: parseInt(modelData.inputTokens) || 0,
              output_tokens: parseInt(modelData.outputTokens) || 0,
              cache_creation_input_tokens: parseInt(modelData.cacheCreateTokens) || 0,
              cache_read_input_tokens: parseInt(modelData.cacheReadTokens) || 0
            }

            const costResult = CostCalculator.calculateCost(usage, model)
            const currentCost = apiKeyCostMap.get(apiKeyId) || 0
            apiKeyCostMap.set(apiKeyId, currentCost + costResult.costs.total)
          }
        }

        // ç»„åˆæ•°æ®
        for (const [apiKeyId, data] of apiKeyDataMap) {
          const cost = apiKeyCostMap.get(apiKeyId) || 0

          // å¦‚æœæ²¡æœ‰æ¨¡å‹çº§åˆ«æ•°æ®ï¼Œä½¿ç”¨é»˜è®¤æ¨¡å‹è®¡ç®—ï¼ˆé™çº§æ–¹æ¡ˆï¼‰
          let finalCost = cost
          let formattedCost = CostCalculator.formatCost(cost)

          if (cost === 0 && data.tokens > 0) {
            const usage = {
              input_tokens: data.inputTokens,
              output_tokens: data.outputTokens,
              cache_creation_input_tokens: data.cacheCreateTokens,
              cache_read_input_tokens: data.cacheReadTokens
            }
            const fallbackResult = CostCalculator.calculateCost(usage, 'claude-3-5-sonnet-20241022')
            finalCost = fallbackResult.costs.total
            formattedCost = fallbackResult.formatted.total
          }

          hourData.apiKeys[apiKeyId] = {
            name: data.name,
            tokens: data.tokens,
            requests: data.requests,
            cost: finalCost,
            formattedCost
          }
        }

        trendData.push(hourData)
        currentHour.setHours(currentHour.getHours() + 1)
      }
    } else {
      // å¤©ç²’åº¦ç»Ÿè®¡
      const daysCount = parseInt(days) || 7
      const today = new Date()

      // è·å–è¿‡å»Nå¤©çš„æ•°æ®
      for (let i = 0; i < daysCount; i++) {
        const date = new Date(today)
        date.setDate(date.getDate() - i)
        const dateStr = redis.getDateStringInTimezone(date)

        // è·å–è¿™ä¸€å¤©æ‰€æœ‰API Keyçš„æ•°æ®
        const pattern = `usage:daily:*:${dateStr}`
        const keys = await client.keys(pattern)

        const dayData = {
          date: dateStr,
          apiKeys: {}
        }

        // å…ˆæ”¶é›†åŸºç¡€æ•°æ®
        const apiKeyDataMap = new Map()
        for (const key of keys) {
          const match = key.match(/usage:daily:(.+?):\d{4}-\d{2}-\d{2}/)
          if (!match) {
            continue
          }

          const apiKeyId = match[1]
          const data = await client.hgetall(key)

          if (data && apiKeyMap.has(apiKeyId)) {
            const inputTokens = parseInt(data.inputTokens) || 0
            const outputTokens = parseInt(data.outputTokens) || 0
            const cacheCreateTokens = parseInt(data.cacheCreateTokens) || 0
            const cacheReadTokens = parseInt(data.cacheReadTokens) || 0
            const totalTokens = inputTokens + outputTokens + cacheCreateTokens + cacheReadTokens

            apiKeyDataMap.set(apiKeyId, {
              name: apiKeyMap.get(apiKeyId).name,
              tokens: totalTokens,
              requests: parseInt(data.requests) || 0,
              inputTokens,
              outputTokens,
              cacheCreateTokens,
              cacheReadTokens
            })
          }
        }

        // è·å–è¯¥å¤©çš„æ¨¡å‹çº§åˆ«æ•°æ®æ¥è®¡ç®—å‡†ç¡®è´¹ç”¨
        const modelPattern = `usage:*:model:daily:*:${dateStr}`
        const modelKeys = await client.keys(modelPattern)
        const apiKeyCostMap = new Map()

        for (const modelKey of modelKeys) {
          const match = modelKey.match(/usage:(.+?):model:daily:(.+?):\d{4}-\d{2}-\d{2}/)
          if (!match) {
            continue
          }

          const apiKeyId = match[1]
          const model = match[2]
          const modelData = await client.hgetall(modelKey)

          if (modelData && apiKeyDataMap.has(apiKeyId)) {
            const usage = {
              input_tokens: parseInt(modelData.inputTokens) || 0,
              output_tokens: parseInt(modelData.outputTokens) || 0,
              cache_creation_input_tokens: parseInt(modelData.cacheCreateTokens) || 0,
              cache_read_input_tokens: parseInt(modelData.cacheReadTokens) || 0
            }

            const costResult = CostCalculator.calculateCost(usage, model)
            const currentCost = apiKeyCostMap.get(apiKeyId) || 0
            apiKeyCostMap.set(apiKeyId, currentCost + costResult.costs.total)
          }
        }

        // ç»„åˆæ•°æ®
        for (const [apiKeyId, data] of apiKeyDataMap) {
          const cost = apiKeyCostMap.get(apiKeyId) || 0

          // å¦‚æœæ²¡æœ‰æ¨¡å‹çº§åˆ«æ•°æ®ï¼Œä½¿ç”¨é»˜è®¤æ¨¡å‹è®¡ç®—ï¼ˆé™çº§æ–¹æ¡ˆï¼‰
          let finalCost = cost
          let formattedCost = CostCalculator.formatCost(cost)

          if (cost === 0 && data.tokens > 0) {
            const usage = {
              input_tokens: data.inputTokens,
              output_tokens: data.outputTokens,
              cache_creation_input_tokens: data.cacheCreateTokens,
              cache_read_input_tokens: data.cacheReadTokens
            }
            const fallbackResult = CostCalculator.calculateCost(usage, 'claude-3-5-sonnet-20241022')
            finalCost = fallbackResult.costs.total
            formattedCost = fallbackResult.formatted.total
          }

          dayData.apiKeys[apiKeyId] = {
            name: data.name,
            tokens: data.tokens,
            requests: data.requests,
            cost: finalCost,
            formattedCost
          }
        }

        trendData.push(dayData)
      }
    }

    // æŒ‰æ—¶é—´æ­£åºæ’åˆ—
    if (granularity === 'hour') {
      trendData.sort((a, b) => new Date(a.hour) - new Date(b.hour))
    } else {
      trendData.sort((a, b) => new Date(a.date) - new Date(b.date))
    }

    // è®¡ç®—æ¯ä¸ªAPI Keyçš„æ€»tokenæ•°ï¼Œç”¨äºæ’åº
    const apiKeyTotals = new Map()
    for (const point of trendData) {
      for (const [apiKeyId, data] of Object.entries(point.apiKeys)) {
        apiKeyTotals.set(apiKeyId, (apiKeyTotals.get(apiKeyId) || 0) + data.tokens)
      }
    }

    // è·å–å‰10ä¸ªä½¿ç”¨é‡æœ€å¤šçš„API Key
    const topApiKeys = Array.from(apiKeyTotals.entries())
      .sort((a, b) => b[1] - a[1])
      .slice(0, 10)
      .map(([apiKeyId]) => apiKeyId)

    return res.json({
      success: true,
      data: trendData,
      granularity,
      topApiKeys,
      totalApiKeys: apiKeyTotals.size
    })
  } catch (error) {
    logger.error('âŒ Failed to get API keys usage trend:', error)
    return res
      .status(500)
      .json({ error: 'Failed to get API keys usage trend', message: error.message })
  }
})

// è®¡ç®—æ€»ä½“ä½¿ç”¨è´¹ç”¨
router.get('/usage-costs', authenticateAdmin, async (req, res) => {
  try {
    const { period = 'all' } = req.query // all, today, monthly, 7days

    logger.info(`ğŸ’° Calculating usage costs for period: ${period}`)

    // æ¨¡å‹åæ ‡å‡†åŒ–å‡½æ•°ï¼ˆä¸redis.jsä¿æŒä¸€è‡´ï¼‰
    const normalizeModelName = (model) => {
      if (!model || model === 'unknown') {
        return model
      }

      // å¯¹äºBedrockæ¨¡å‹ï¼Œå»æ‰åŒºåŸŸå‰ç¼€è¿›è¡Œç»Ÿä¸€
      if (model.includes('.anthropic.') || model.includes('.claude')) {
        // åŒ¹é…æ‰€æœ‰AWSåŒºåŸŸæ ¼å¼ï¼šregion.anthropic.model-name-v1:0 -> claude-model-name
        // æ”¯æŒæ‰€æœ‰AWSåŒºåŸŸæ ¼å¼ï¼Œå¦‚ï¼šus-east-1, eu-west-1, ap-southeast-1, ca-central-1ç­‰
        let normalized = model.replace(/^[a-z0-9-]+\./, '') // å»æ‰ä»»ä½•åŒºåŸŸå‰ç¼€ï¼ˆæ›´é€šç”¨ï¼‰
        normalized = normalized.replace('anthropic.', '') // å»æ‰anthropicå‰ç¼€
        normalized = normalized.replace(/-v\d+:\d+$/, '') // å»æ‰ç‰ˆæœ¬åç¼€ï¼ˆå¦‚-v1:0, -v2:1ç­‰ï¼‰
        return normalized
      }

      // å¯¹äºå…¶ä»–æ¨¡å‹ï¼Œå»æ‰å¸¸è§çš„ç‰ˆæœ¬åç¼€
      return model.replace(/-v\d+:\d+$|:latest$/, '')
    }

    // è·å–æ‰€æœ‰API Keysçš„ä½¿ç”¨ç»Ÿè®¡
    const apiKeys = await apiKeyService.getAllApiKeys()

    const totalCosts = {
      inputCost: 0,
      outputCost: 0,
      cacheCreateCost: 0,
      cacheReadCost: 0,
      totalCost: 0
    }

    const modelCosts = {}

    // æŒ‰æ¨¡å‹ç»Ÿè®¡è´¹ç”¨
    const client = redis.getClientSafe()
    const today = redis.getDateStringInTimezone()
    const tzDate = redis.getDateInTimezone()
    const currentMonth = `${tzDate.getUTCFullYear()}-${String(tzDate.getUTCMonth() + 1).padStart(2, '0')}`

    let pattern
    if (period === 'today') {
      pattern = `usage:model:daily:*:${today}`
    } else if (period === 'monthly') {
      pattern = `usage:model:monthly:*:${currentMonth}`
    } else if (period === '7days') {
      // æœ€è¿‘7å¤©ï¼šæ±‡æ€»dailyæ•°æ®
      const modelUsageMap = new Map()

      // è·å–æœ€è¿‘7å¤©çš„æ‰€æœ‰dailyç»Ÿè®¡æ•°æ®
      for (let i = 0; i < 7; i++) {
        const date = new Date()
        date.setDate(date.getDate() - i)
        const currentTzDate = redis.getDateInTimezone(date)
        const dateStr = `${currentTzDate.getUTCFullYear()}-${String(currentTzDate.getUTCMonth() + 1).padStart(2, '0')}-${String(currentTzDate.getUTCDate()).padStart(2, '0')}`
        const dayPattern = `usage:model:daily:*:${dateStr}`

        const dayKeys = await client.keys(dayPattern)

        for (const key of dayKeys) {
          const modelMatch = key.match(/usage:model:daily:(.+):\d{4}-\d{2}-\d{2}$/)
          if (!modelMatch) {
            continue
          }

          const rawModel = modelMatch[1]
          const normalizedModel = normalizeModelName(rawModel)
          const data = await client.hgetall(key)

          if (data && Object.keys(data).length > 0) {
            if (!modelUsageMap.has(normalizedModel)) {
              modelUsageMap.set(normalizedModel, {
                inputTokens: 0,
                outputTokens: 0,
                cacheCreateTokens: 0,
                cacheReadTokens: 0
              })
            }

            const modelUsage = modelUsageMap.get(normalizedModel)
            modelUsage.inputTokens += parseInt(data.inputTokens) || 0
            modelUsage.outputTokens += parseInt(data.outputTokens) || 0
            modelUsage.cacheCreateTokens += parseInt(data.cacheCreateTokens) || 0
            modelUsage.cacheReadTokens += parseInt(data.cacheReadTokens) || 0
          }
        }
      }

      // è®¡ç®—7å¤©ç»Ÿè®¡çš„è´¹ç”¨
      logger.info(`ğŸ’° Processing ${modelUsageMap.size} unique models for 7days cost calculation`)

      for (const [model, usage] of modelUsageMap) {
        const usageData = {
          input_tokens: usage.inputTokens,
          output_tokens: usage.outputTokens,
          cache_creation_input_tokens: usage.cacheCreateTokens,
          cache_read_input_tokens: usage.cacheReadTokens
        }

        const costResult = CostCalculator.calculateCost(usageData, model)
        totalCosts.inputCost += costResult.costs.input
        totalCosts.outputCost += costResult.costs.output
        totalCosts.cacheCreateCost += costResult.costs.cacheWrite
        totalCosts.cacheReadCost += costResult.costs.cacheRead
        totalCosts.totalCost += costResult.costs.total

        logger.info(
          `ğŸ’° Model ${model} (7days): ${usage.inputTokens + usage.outputTokens + usage.cacheCreateTokens + usage.cacheReadTokens} tokens, cost: ${costResult.formatted.total}`
        )

        // è®°å½•æ¨¡å‹è´¹ç”¨
        modelCosts[model] = {
          model,
          requests: 0, // 7å¤©æ±‡æ€»æ•°æ®æ²¡æœ‰è¯·æ±‚æ•°ç»Ÿè®¡
          usage: usageData,
          costs: costResult.costs,
          formatted: costResult.formatted,
          usingDynamicPricing: costResult.usingDynamicPricing
        }
      }

      // è¿”å›7å¤©ç»Ÿè®¡ç»“æœ
      return res.json({
        success: true,
        data: {
          period,
          totalCosts: {
            ...totalCosts,
            formatted: {
              inputCost: CostCalculator.formatCost(totalCosts.inputCost),
              outputCost: CostCalculator.formatCost(totalCosts.outputCost),
              cacheCreateCost: CostCalculator.formatCost(totalCosts.cacheCreateCost),
              cacheReadCost: CostCalculator.formatCost(totalCosts.cacheReadCost),
              totalCost: CostCalculator.formatCost(totalCosts.totalCost)
            }
          },
          modelCosts: Object.values(modelCosts)
        }
      })
    } else {
      // å…¨éƒ¨æ—¶é—´ï¼Œå…ˆå°è¯•ä»Redisè·å–æ‰€æœ‰å†å²æ¨¡å‹ç»Ÿè®¡æ•°æ®ï¼ˆåªä½¿ç”¨monthlyæ•°æ®é¿å…é‡å¤è®¡ç®—ï¼‰
      const allModelKeys = await client.keys('usage:model:monthly:*:*')
      logger.info(`ğŸ’° Total period calculation: found ${allModelKeys.length} monthly model keys`)

      if (allModelKeys.length > 0) {
        // å¦‚æœæœ‰è¯¦ç»†çš„æ¨¡å‹ç»Ÿè®¡æ•°æ®ï¼Œä½¿ç”¨æ¨¡å‹çº§åˆ«çš„è®¡ç®—
        const modelUsageMap = new Map()

        for (const key of allModelKeys) {
          // è§£ææ¨¡å‹åç§°ï¼ˆåªå¤„ç†monthlyæ•°æ®ï¼‰
          const modelMatch = key.match(/usage:model:monthly:(.+):(\d{4}-\d{2})$/)
          if (!modelMatch) {
            continue
          }

          const model = modelMatch[1]
          const data = await client.hgetall(key)

          if (data && Object.keys(data).length > 0) {
            if (!modelUsageMap.has(model)) {
              modelUsageMap.set(model, {
                inputTokens: 0,
                outputTokens: 0,
                cacheCreateTokens: 0,
                cacheReadTokens: 0
              })
            }

            const modelUsage = modelUsageMap.get(model)
            modelUsage.inputTokens += parseInt(data.inputTokens) || 0
            modelUsage.outputTokens += parseInt(data.outputTokens) || 0
            modelUsage.cacheCreateTokens += parseInt(data.cacheCreateTokens) || 0
            modelUsage.cacheReadTokens += parseInt(data.cacheReadTokens) || 0
          }
        }

        // ä½¿ç”¨æ¨¡å‹çº§åˆ«çš„æ•°æ®è®¡ç®—è´¹ç”¨
        logger.info(`ğŸ’° Processing ${modelUsageMap.size} unique models for total cost calculation`)

        for (const [model, usage] of modelUsageMap) {
          const usageData = {
            input_tokens: usage.inputTokens,
            output_tokens: usage.outputTokens,
            cache_creation_input_tokens: usage.cacheCreateTokens,
            cache_read_input_tokens: usage.cacheReadTokens
          }

          const costResult = CostCalculator.calculateCost(usageData, model)
          totalCosts.inputCost += costResult.costs.input
          totalCosts.outputCost += costResult.costs.output
          totalCosts.cacheCreateCost += costResult.costs.cacheWrite
          totalCosts.cacheReadCost += costResult.costs.cacheRead
          totalCosts.totalCost += costResult.costs.total

          logger.info(
            `ğŸ’° Model ${model}: ${usage.inputTokens + usage.outputTokens + usage.cacheCreateTokens + usage.cacheReadTokens} tokens, cost: ${costResult.formatted.total}`
          )

          // è®°å½•æ¨¡å‹è´¹ç”¨
          modelCosts[model] = {
            model,
            requests: 0, // å†å²æ±‡æ€»æ•°æ®æ²¡æœ‰è¯·æ±‚æ•°
            usage: usageData,
            costs: costResult.costs,
            formatted: costResult.formatted,
            usingDynamicPricing: costResult.usingDynamicPricing
          }
        }
      } else {
        // å¦‚æœæ²¡æœ‰è¯¦ç»†çš„æ¨¡å‹ç»Ÿè®¡æ•°æ®ï¼Œå›é€€åˆ°API Keyæ±‡æ€»æ•°æ®
        logger.warn('No detailed model statistics found, falling back to API Key aggregated data')

        for (const apiKey of apiKeys) {
          if (apiKey.usage && apiKey.usage.total) {
            const usage = {
              input_tokens: apiKey.usage.total.inputTokens || 0,
              output_tokens: apiKey.usage.total.outputTokens || 0,
              cache_creation_input_tokens: apiKey.usage.total.cacheCreateTokens || 0,
              cache_read_input_tokens: apiKey.usage.total.cacheReadTokens || 0
            }

            // ä½¿ç”¨åŠ æƒå¹³å‡ä»·æ ¼è®¡ç®—ï¼ˆåŸºäºå½“å‰æ´»è·ƒæ¨¡å‹çš„ä»·æ ¼åˆ†å¸ƒï¼‰
            const costResult = CostCalculator.calculateCost(usage, 'claude-3-5-haiku-20241022')
            totalCosts.inputCost += costResult.costs.input
            totalCosts.outputCost += costResult.costs.output
            totalCosts.cacheCreateCost += costResult.costs.cacheWrite
            totalCosts.cacheReadCost += costResult.costs.cacheRead
            totalCosts.totalCost += costResult.costs.total
          }
        }
      }

      return res.json({
        success: true,
        data: {
          period,
          totalCosts: {
            ...totalCosts,
            formatted: {
              inputCost: CostCalculator.formatCost(totalCosts.inputCost),
              outputCost: CostCalculator.formatCost(totalCosts.outputCost),
              cacheCreateCost: CostCalculator.formatCost(totalCosts.cacheCreateCost),
              cacheReadCost: CostCalculator.formatCost(totalCosts.cacheReadCost),
              totalCost: CostCalculator.formatCost(totalCosts.totalCost)
            }
          },
          modelCosts: Object.values(modelCosts).sort((a, b) => b.costs.total - a.costs.total),
          pricingServiceStatus: pricingService.getStatus()
        }
      })
    }

    // å¯¹äºä»Šæ—¥æˆ–æœ¬æœˆï¼Œä»Redisè·å–è¯¦ç»†çš„æ¨¡å‹ç»Ÿè®¡
    const keys = await client.keys(pattern)

    for (const key of keys) {
      const match = key.match(
        period === 'today'
          ? /usage:model:daily:(.+):\d{4}-\d{2}-\d{2}$/
          : /usage:model:monthly:(.+):\d{4}-\d{2}$/
      )

      if (!match) {
        continue
      }

      const model = match[1]
      const data = await client.hgetall(key)

      if (data && Object.keys(data).length > 0) {
        const usage = {
          input_tokens: parseInt(data.inputTokens) || 0,
          output_tokens: parseInt(data.outputTokens) || 0,
          cache_creation_input_tokens: parseInt(data.cacheCreateTokens) || 0,
          cache_read_input_tokens: parseInt(data.cacheReadTokens) || 0
        }

        const costResult = CostCalculator.calculateCost(usage, model)

        // ç´¯åŠ æ€»è´¹ç”¨
        totalCosts.inputCost += costResult.costs.input
        totalCosts.outputCost += costResult.costs.output
        totalCosts.cacheCreateCost += costResult.costs.cacheWrite
        totalCosts.cacheReadCost += costResult.costs.cacheRead
        totalCosts.totalCost += costResult.costs.total

        // è®°å½•æ¨¡å‹è´¹ç”¨
        modelCosts[model] = {
          model,
          requests: parseInt(data.requests) || 0,
          usage,
          costs: costResult.costs,
          formatted: costResult.formatted,
          usingDynamicPricing: costResult.usingDynamicPricing
        }
      }
    }

    return res.json({
      success: true,
      data: {
        period,
        totalCosts: {
          ...totalCosts,
          formatted: {
            inputCost: CostCalculator.formatCost(totalCosts.inputCost),
            outputCost: CostCalculator.formatCost(totalCosts.outputCost),
            cacheCreateCost: CostCalculator.formatCost(totalCosts.cacheCreateCost),
            cacheReadCost: CostCalculator.formatCost(totalCosts.cacheReadCost),
            totalCost: CostCalculator.formatCost(totalCosts.totalCost)
          }
        },
        modelCosts: Object.values(modelCosts).sort((a, b) => b.costs.total - a.costs.total),
        pricingServiceStatus: pricingService.getStatus()
      }
    })
  } catch (error) {
    logger.error('âŒ Failed to calculate usage costs:', error)
    return res
      .status(500)
      .json({ error: 'Failed to calculate usage costs', message: error.message })
  }
})

// ğŸ“‹ è·å–æ‰€æœ‰è´¦å·çš„ Claude Code headers ä¿¡æ¯
router.get('/claude-code-headers', authenticateAdmin, async (req, res) => {
  try {
    const allHeaders = await claudeCodeHeadersService.getAllAccountHeaders()

    // è·å–æ‰€æœ‰ Claude è´¦å·ä¿¡æ¯
    const accounts = await claudeAccountService.getAllAccounts()
    const accountMap = {}
    accounts.forEach((account) => {
      accountMap[account.id] = account.name
    })

    // æ ¼å¼åŒ–è¾“å‡º
    const formattedData = Object.entries(allHeaders).map(([accountId, data]) => ({
      accountId,
      accountName: accountMap[accountId] || 'Unknown',
      version: data.version,
      userAgent: data.headers['user-agent'],
      updatedAt: data.updatedAt,
      headers: data.headers
    }))

    return res.json({
      success: true,
      data: formattedData
    })
  } catch (error) {
    logger.error('âŒ Failed to get Claude Code headers:', error)
    return res
      .status(500)
      .json({ error: 'Failed to get Claude Code headers', message: error.message })
  }
})

// ğŸ—‘ï¸ æ¸…é™¤æŒ‡å®šè´¦å·çš„ Claude Code headers
router.delete('/claude-code-headers/:accountId', authenticateAdmin, async (req, res) => {
  try {
    const { accountId } = req.params
    await claudeCodeHeadersService.clearAccountHeaders(accountId)

    return res.json({
      success: true,
      message: `Claude Code headers cleared for account ${accountId}`
    })
  } catch (error) {
    logger.error('âŒ Failed to clear Claude Code headers:', error)
    return res
      .status(500)
      .json({ error: 'Failed to clear Claude Code headers', message: error.message })
  }
})

// ğŸ”„ ç‰ˆæœ¬æ£€æŸ¥
router.get('/check-updates', authenticateAdmin, async (req, res) => {
  // è¯»å–å½“å‰ç‰ˆæœ¬
  const versionPath = path.join(__dirname, '../../VERSION')
  let currentVersion = '1.0.0'
  try {
    currentVersion = fs.readFileSync(versionPath, 'utf8').trim()
  } catch (err) {
    logger.warn('âš ï¸ Could not read VERSION file:', err.message)
  }

  try {
    // ä»ç¼“å­˜è·å–
    const cacheKey = 'version_check_cache'
    const cached = await redis.getClient().get(cacheKey)

    if (cached && !req.query.force) {
      const cachedData = JSON.parse(cached)
      const cacheAge = Date.now() - cachedData.timestamp

      // ç¼“å­˜æœ‰æ•ˆæœŸ1å°æ—¶
      if (cacheAge < 3600000) {
        // å®æ—¶è®¡ç®— hasUpdateï¼Œä¸ä½¿ç”¨ç¼“å­˜çš„å€¼
        const hasUpdate = compareVersions(currentVersion, cachedData.latest) < 0

        return res.json({
          success: true,
          data: {
            current: currentVersion,
            latest: cachedData.latest,
            hasUpdate, // å®æ—¶è®¡ç®—ï¼Œä¸ç”¨ç¼“å­˜
            releaseInfo: cachedData.releaseInfo,
            cached: true
          }
        })
      }
    }

    // è¯·æ±‚ GitHub API
    const githubRepo = 'wei-shaw/claude-relay-service'
    const response = await axios.get(`https://api.github.com/repos/${githubRepo}/releases/latest`, {
      headers: {
        Accept: 'application/vnd.github.v3+json',
        'User-Agent': 'Claude-Relay-Service'
      },
      timeout: 10000
    })

    const release = response.data
    const latestVersion = release.tag_name.replace(/^v/, '')

    // æ¯”è¾ƒç‰ˆæœ¬
    const hasUpdate = compareVersions(currentVersion, latestVersion) < 0

    const releaseInfo = {
      name: release.name,
      body: release.body,
      publishedAt: release.published_at,
      htmlUrl: release.html_url
    }

    // ç¼“å­˜ç»“æœï¼ˆä¸ç¼“å­˜ hasUpdateï¼Œå› ä¸ºå®ƒåº”è¯¥å®æ—¶è®¡ç®—ï¼‰
    await redis.getClient().set(
      cacheKey,
      JSON.stringify({
        latest: latestVersion,
        releaseInfo,
        timestamp: Date.now()
      }),
      'EX',
      3600
    ) // 1å°æ—¶è¿‡æœŸ

    return res.json({
      success: true,
      data: {
        current: currentVersion,
        latest: latestVersion,
        hasUpdate,
        releaseInfo,
        cached: false
      }
    })
  } catch (error) {
    // æ”¹è¿›é”™è¯¯æ—¥å¿—è®°å½•
    const errorDetails = {
      message: error.message || 'Unknown error',
      code: error.code,
      response: error.response
        ? {
            status: error.response.status,
            statusText: error.response.statusText,
            data: error.response.data
          }
        : null,
      request: error.request ? 'Request was made but no response received' : null
    }

    logger.error('âŒ Failed to check for updates:', errorDetails.message)

    // å¤„ç† 404 é”™è¯¯ - ä»“åº“æˆ–ç‰ˆæœ¬ä¸å­˜åœ¨
    if (error.response && error.response.status === 404) {
      return res.json({
        success: true,
        data: {
          current: currentVersion,
          latest: currentVersion,
          hasUpdate: false,
          releaseInfo: {
            name: 'No releases found',
            body: 'The GitHub repository has no releases yet.',
            publishedAt: new Date().toISOString(),
            htmlUrl: '#'
          },
          warning: 'GitHub repository has no releases'
        }
      })
    }

    // å¦‚æœæ˜¯ç½‘ç»œé”™è¯¯ï¼Œå°è¯•è¿”å›ç¼“å­˜çš„æ•°æ®
    if (error.code === 'ECONNREFUSED' || error.code === 'ETIMEDOUT' || error.code === 'ENOTFOUND') {
      const cacheKey = 'version_check_cache'
      const cached = await redis.getClient().get(cacheKey)

      if (cached) {
        const cachedData = JSON.parse(cached)
        // å®æ—¶è®¡ç®— hasUpdate
        const hasUpdate = compareVersions(currentVersion, cachedData.latest) < 0

        return res.json({
          success: true,
          data: {
            current: currentVersion,
            latest: cachedData.latest,
            hasUpdate, // å®æ—¶è®¡ç®—
            releaseInfo: cachedData.releaseInfo,
            cached: true,
            warning: 'Using cached data due to network error'
          }
        })
      }
    }

    // å…¶ä»–é”™è¯¯è¿”å›å½“å‰ç‰ˆæœ¬ä¿¡æ¯
    return res.json({
      success: true,
      data: {
        current: currentVersion,
        latest: currentVersion,
        hasUpdate: false,
        releaseInfo: {
          name: 'Update check failed',
          body: `Unable to check for updates: ${error.message || 'Unknown error'}`,
          publishedAt: new Date().toISOString(),
          htmlUrl: '#'
        },
        error: true,
        warning: error.message || 'Failed to check for updates'
      }
    })
  }
})

// ç‰ˆæœ¬æ¯”è¾ƒå‡½æ•°
function compareVersions(current, latest) {
  const parseVersion = (v) => {
    const parts = v.split('.').map(Number)
    return {
      major: parts[0] || 0,
      minor: parts[1] || 0,
      patch: parts[2] || 0
    }
  }

  const currentV = parseVersion(current)
  const latestV = parseVersion(latest)

  if (currentV.major !== latestV.major) {
    return currentV.major - latestV.major
  }
  if (currentV.minor !== latestV.minor) {
    return currentV.minor - latestV.minor
  }
  return currentV.patch - latestV.patch
}

// ğŸ¨ OEMè®¾ç½®ç®¡ç†

// è·å–OEMè®¾ç½®ï¼ˆå…¬å¼€æ¥å£ï¼Œç”¨äºæ˜¾ç¤ºï¼‰
router.get('/oem-settings', async (req, res) => {
  try {
    const client = redis.getClient()
    const oemSettings = await client.get('oem:settings')

    // é»˜è®¤è®¾ç½®
    const defaultSettings = {
      siteName: 'Claude Relay Service',
      siteIcon: '',
      siteIconData: '', // Base64ç¼–ç çš„å›¾æ ‡æ•°æ®
      updatedAt: new Date().toISOString()
    }

    let settings = defaultSettings
    if (oemSettings) {
      try {
        settings = { ...defaultSettings, ...JSON.parse(oemSettings) }
      } catch (err) {
        logger.warn('âš ï¸ Failed to parse OEM settings, using defaults:', err.message)
      }
    }

    return res.json({
      success: true,
      data: settings
    })
  } catch (error) {
    logger.error('âŒ Failed to get OEM settings:', error)
    return res.status(500).json({ error: 'Failed to get OEM settings', message: error.message })
  }
})

// æ›´æ–°OEMè®¾ç½®
router.put('/oem-settings', authenticateAdmin, async (req, res) => {
  try {
    const { siteName, siteIcon, siteIconData } = req.body

    // éªŒè¯è¾“å…¥
    if (!siteName || typeof siteName !== 'string' || siteName.trim().length === 0) {
      return res.status(400).json({ error: 'Site name is required' })
    }

    if (siteName.length > 100) {
      return res.status(400).json({ error: 'Site name must be less than 100 characters' })
    }

    // éªŒè¯å›¾æ ‡æ•°æ®å¤§å°ï¼ˆå¦‚æœæ˜¯base64ï¼‰
    if (siteIconData && siteIconData.length > 500000) {
      // çº¦375KB
      return res.status(400).json({ error: 'Icon file must be less than 350KB' })
    }

    // éªŒè¯å›¾æ ‡URLï¼ˆå¦‚æœæä¾›ï¼‰
    if (siteIcon && !siteIconData) {
      // ç®€å•éªŒè¯URLæ ¼å¼
      try {
        new URL(siteIcon)
      } catch (err) {
        return res.status(400).json({ error: 'Invalid icon URL format' })
      }
    }

    const settings = {
      siteName: siteName.trim(),
      siteIcon: (siteIcon || '').trim(),
      siteIconData: (siteIconData || '').trim(), // Base64æ•°æ®
      updatedAt: new Date().toISOString()
    }

    const client = redis.getClient()
    await client.set('oem:settings', JSON.stringify(settings))

    logger.info(`âœ… OEM settings updated: ${siteName}`)

    return res.json({
      success: true,
      message: 'OEM settings updated successfully',
      data: settings
    })
  } catch (error) {
    logger.error('âŒ Failed to update OEM settings:', error)
    return res.status(500).json({ error: 'Failed to update OEM settings', message: error.message })
  }
})

// ğŸ¤– OpenAI è´¦æˆ·ç®¡ç†

// OpenAI OAuth é…ç½®
const OPENAI_CONFIG = {
  BASE_URL: 'https://auth.openai.com',
  CLIENT_ID: 'app_EMoamEEZ73f0CkXaXp7hrann',
  REDIRECT_URI: 'http://localhost:1455/auth/callback',
  SCOPE: 'openid profile email offline_access'
}

// ç”Ÿæˆ PKCE å‚æ•°
function generateOpenAIPKCE() {
  const codeVerifier = crypto.randomBytes(64).toString('hex')
  const codeChallenge = crypto.createHash('sha256').update(codeVerifier).digest('base64url')

  return {
    codeVerifier,
    codeChallenge
  }
}

// ç”Ÿæˆ OpenAI OAuth æˆæƒ URL
router.post('/openai-accounts/generate-auth-url', authenticateAdmin, async (req, res) => {
  try {
    const { proxy } = req.body

    // ç”Ÿæˆ PKCE å‚æ•°
    const pkce = generateOpenAIPKCE()

    // ç”Ÿæˆéšæœº state
    const state = crypto.randomBytes(32).toString('hex')

    // åˆ›å»ºä¼šè¯ ID
    const sessionId = crypto.randomUUID()

    // å°† PKCE å‚æ•°å’Œä»£ç†é…ç½®å­˜å‚¨åˆ° Redis
    await redis.setOAuthSession(sessionId, {
      codeVerifier: pkce.codeVerifier,
      codeChallenge: pkce.codeChallenge,
      state,
      proxy: proxy || null,
      platform: 'openai',
      createdAt: new Date().toISOString(),
      expiresAt: new Date(Date.now() + 10 * 60 * 1000).toISOString()
    })

    // æ„å»ºæˆæƒ URL å‚æ•°
    const params = new URLSearchParams({
      response_type: 'code',
      client_id: OPENAI_CONFIG.CLIENT_ID,
      redirect_uri: OPENAI_CONFIG.REDIRECT_URI,
      scope: OPENAI_CONFIG.SCOPE,
      code_challenge: pkce.codeChallenge,
      code_challenge_method: 'S256',
      state,
      id_token_add_organizations: 'true',
      codex_cli_simplified_flow: 'true'
    })

    const authUrl = `${OPENAI_CONFIG.BASE_URL}/oauth/authorize?${params.toString()}`

    logger.success('ğŸ”— Generated OpenAI OAuth authorization URL')

    return res.json({
      success: true,
      data: {
        authUrl,
        sessionId,
        instructions: [
          '1. å¤åˆ¶ä¸Šé¢çš„é“¾æ¥åˆ°æµè§ˆå™¨ä¸­æ‰“å¼€',
          '2. ç™»å½•æ‚¨çš„ OpenAI è´¦æˆ·',
          '3. åŒæ„åº”ç”¨æƒé™',
          '4. å¤åˆ¶æµè§ˆå™¨åœ°å€æ ä¸­çš„å®Œæ•´ URLï¼ˆåŒ…å« code å‚æ•°ï¼‰',
          '5. åœ¨æ·»åŠ è´¦æˆ·è¡¨å•ä¸­ç²˜è´´å®Œæ•´çš„å›è°ƒ URL'
        ]
      }
    })
  } catch (error) {
    logger.error('ç”Ÿæˆ OpenAI OAuth URL å¤±è´¥:', error)
    return res.status(500).json({
      success: false,
      message: 'ç”Ÿæˆæˆæƒé“¾æ¥å¤±è´¥',
      error: error.message
    })
  }
})

// äº¤æ¢ OpenAI æˆæƒç 
router.post('/openai-accounts/exchange-code', authenticateAdmin, async (req, res) => {
  try {
    const { code, sessionId } = req.body

    if (!code || !sessionId) {
      return res.status(400).json({
        success: false,
        message: 'ç¼ºå°‘å¿…è¦å‚æ•°'
      })
    }

    // ä» Redis è·å–ä¼šè¯æ•°æ®
    const sessionData = await redis.getOAuthSession(sessionId)
    if (!sessionData) {
      return res.status(400).json({
        success: false,
        message: 'ä¼šè¯å·²è¿‡æœŸæˆ–æ— æ•ˆ'
      })
    }

    // å‡†å¤‡ token äº¤æ¢è¯·æ±‚
    const tokenData = {
      grant_type: 'authorization_code',
      code: code.trim(),
      redirect_uri: OPENAI_CONFIG.REDIRECT_URI,
      client_id: OPENAI_CONFIG.CLIENT_ID,
      code_verifier: sessionData.codeVerifier
    }

    logger.info('Exchanging OpenAI authorization code:', {
      sessionId,
      codeLength: code.length,
      hasCodeVerifier: !!sessionData.codeVerifier
    })

    // é…ç½®ä»£ç†ï¼ˆå¦‚æœæœ‰ï¼‰
    const axiosConfig = {
      headers: {
        'Content-Type': 'application/x-www-form-urlencoded'
      }
    }

    // é…ç½®ä»£ç†ï¼ˆå¦‚æœæœ‰ï¼‰
    const proxyAgent = ProxyHelper.createProxyAgent(sessionData.proxy)
    if (proxyAgent) {
      axiosConfig.httpsAgent = proxyAgent
    }

    // äº¤æ¢ authorization code è·å– tokens
    const tokenResponse = await axios.post(
      `${OPENAI_CONFIG.BASE_URL}/oauth/token`,
      new URLSearchParams(tokenData).toString(),
      axiosConfig
    )

    const { id_token, access_token, refresh_token, expires_in } = tokenResponse.data

    // è§£æ ID token è·å–ç”¨æˆ·ä¿¡æ¯
    const idTokenParts = id_token.split('.')
    if (idTokenParts.length !== 3) {
      throw new Error('Invalid ID token format')
    }

    // è§£ç  JWT payload
    const payload = JSON.parse(Buffer.from(idTokenParts[1], 'base64url').toString())

    // è·å– OpenAI ç‰¹å®šçš„å£°æ˜
    const authClaims = payload['https://api.openai.com/auth'] || {}
    const accountId = authClaims.chatgpt_account_id || ''
    const chatgptUserId = authClaims.chatgpt_user_id || authClaims.user_id || ''
    const planType = authClaims.chatgpt_plan_type || ''

    // è·å–ç»„ç»‡ä¿¡æ¯
    const organizations = authClaims.organizations || []
    const defaultOrg = organizations.find((org) => org.is_default) || organizations[0] || {}
    const organizationId = defaultOrg.id || ''
    const organizationRole = defaultOrg.role || ''
    const organizationTitle = defaultOrg.title || ''

    // æ¸…ç† Redis ä¼šè¯
    await redis.deleteOAuthSession(sessionId)

    logger.success('âœ… OpenAI OAuth token exchange successful')

    return res.json({
      success: true,
      data: {
        tokens: {
          idToken: id_token,
          accessToken: access_token,
          refreshToken: refresh_token,
          expires_in
        },
        accountInfo: {
          accountId,
          chatgptUserId,
          organizationId,
          organizationRole,
          organizationTitle,
          planType,
          email: payload.email || '',
          name: payload.name || '',
          emailVerified: payload.email_verified || false,
          organizations
        }
      }
    })
  } catch (error) {
    logger.error('OpenAI OAuth token exchange failed:', error)
    return res.status(500).json({
      success: false,
      message: 'äº¤æ¢æˆæƒç å¤±è´¥',
      error: error.message
    })
  }
})

// è·å–æ‰€æœ‰ OpenAI è´¦æˆ·
router.get('/openai-accounts', authenticateAdmin, async (req, res) => {
  try {
    const { platform, groupId } = req.query
    let accounts = await openaiAccountService.getAllAccounts()

    // æ ¹æ®æŸ¥è¯¢å‚æ•°è¿›è¡Œç­›é€‰
    if (platform && platform !== 'all' && platform !== 'openai') {
      // å¦‚æœæŒ‡å®šäº†å…¶ä»–å¹³å°ï¼Œè¿”å›ç©ºæ•°ç»„
      accounts = []
    }

    // å¦‚æœæŒ‡å®šäº†åˆ†ç»„ç­›é€‰
    if (groupId && groupId !== 'all') {
      if (groupId === 'ungrouped') {
        // ç­›é€‰æœªåˆ†ç»„è´¦æˆ·
        accounts = accounts.filter((account) => !account.groupInfo)
      } else {
        // ç­›é€‰ç‰¹å®šåˆ†ç»„çš„è´¦æˆ·
        accounts = accounts.filter(
          (account) => account.groupInfo && account.groupInfo.id === groupId
        )
      }
    }

    // ä¸ºæ¯ä¸ªè´¦æˆ·æ·»åŠ ä½¿ç”¨ç»Ÿè®¡ä¿¡æ¯
    const accountsWithStats = await Promise.all(
      accounts.map(async (account) => {
        try {
          const usageStats = await redis.getAccountUsageStats(account.id)
          return {
            ...account,
            usage: {
              daily: usageStats.daily,
              total: usageStats.total,
              monthly: usageStats.monthly
            }
          }
        } catch (error) {
          logger.debug(`Failed to get usage stats for OpenAI account ${account.id}:`, error)
          return {
            ...account,
            usage: {
              daily: { requests: 0, tokens: 0, allTokens: 0 },
              total: { requests: 0, tokens: 0, allTokens: 0 },
              monthly: { requests: 0, tokens: 0, allTokens: 0 }
            }
          }
        }
      })
    )

    logger.info(`è·å– OpenAI è´¦æˆ·åˆ—è¡¨: ${accountsWithStats.length} ä¸ªè´¦æˆ·`)

    return res.json({
      success: true,
      data: accountsWithStats
    })
  } catch (error) {
    logger.error('è·å– OpenAI è´¦æˆ·åˆ—è¡¨å¤±è´¥:', error)
    return res.status(500).json({
      success: false,
      message: 'è·å–è´¦æˆ·åˆ—è¡¨å¤±è´¥',
      error: error.message
    })
  }
})

// åˆ›å»º OpenAI è´¦æˆ·
router.post('/openai-accounts', authenticateAdmin, async (req, res) => {
  try {
    const {
      name,
      description,
      openaiOauth,
      accountInfo,
      proxy,
      accountType,
      groupId,
      rateLimitDuration,
      priority
    } = req.body

    if (!name) {
      return res.status(400).json({
        success: false,
        message: 'è´¦æˆ·åç§°ä¸èƒ½ä¸ºç©º'
      })
    }
    // åˆ›å»ºè´¦æˆ·æ•°æ®
    const accountData = {
      name,
      description: description || '',
      accountType: accountType || 'shared',
      priority: priority || 50,
      rateLimitDuration:
        rateLimitDuration !== undefined && rateLimitDuration !== null ? rateLimitDuration : 60,
      openaiOauth: openaiOauth || {},
      accountInfo: accountInfo || {},
      proxy: proxy || null,
      isActive: true,
      schedulable: true
    }

    // åˆ›å»ºè´¦æˆ·
    const createdAccount = await openaiAccountService.createAccount(accountData)

    // å¦‚æœæ˜¯åˆ†ç»„ç±»å‹ï¼Œæ·»åŠ åˆ°åˆ†ç»„
    if (accountType === 'group' && groupId) {
      await accountGroupService.addAccountToGroup(createdAccount.id, groupId, 'openai')
    }

    logger.success(`âœ… åˆ›å»º OpenAI è´¦æˆ·æˆåŠŸ: ${name} (ID: ${createdAccount.id})`)

    return res.json({
      success: true,
      data: createdAccount
    })
  } catch (error) {
    logger.error('åˆ›å»º OpenAI è´¦æˆ·å¤±è´¥:', error)
    return res.status(500).json({
      success: false,
      message: 'åˆ›å»ºè´¦æˆ·å¤±è´¥',
      error: error.message
    })
  }
})

// æ›´æ–° OpenAI è´¦æˆ·
router.put('/openai-accounts/:id', authenticateAdmin, async (req, res) => {
  try {
    const { id } = req.params
    const updates = req.body

    // éªŒè¯accountTypeçš„æœ‰æ•ˆæ€§
    if (updates.accountType && !['shared', 'dedicated', 'group'].includes(updates.accountType)) {
      return res
        .status(400)
        .json({ error: 'Invalid account type. Must be "shared", "dedicated" or "group"' })
    }

    // å¦‚æœæ›´æ–°ä¸ºåˆ†ç»„ç±»å‹ï¼ŒéªŒè¯groupId
    if (updates.accountType === 'group' && !updates.groupId) {
      return res.status(400).json({ error: 'Group ID is required for group type accounts' })
    }

    // è·å–è´¦æˆ·å½“å‰ä¿¡æ¯ä»¥å¤„ç†åˆ†ç»„å˜æ›´
    const currentAccount = await openaiAccountService.getAccount(id)
    if (!currentAccount) {
      return res.status(404).json({ error: 'Account not found' })
    }

    // å¤„ç†åˆ†ç»„çš„å˜æ›´
    if (updates.accountType !== undefined) {
      // å¦‚æœä¹‹å‰æ˜¯åˆ†ç»„ç±»å‹ï¼Œéœ€è¦ä»åŸåˆ†ç»„ä¸­ç§»é™¤
      if (currentAccount.accountType === 'group') {
        const oldGroup = await accountGroupService.getAccountGroup(id)
        if (oldGroup) {
          await accountGroupService.removeAccountFromGroup(id, oldGroup.id)
        }
      }
      // å¦‚æœæ–°ç±»å‹æ˜¯åˆ†ç»„ï¼Œæ·»åŠ åˆ°æ–°åˆ†ç»„
      if (updates.accountType === 'group' && updates.groupId) {
        await accountGroupService.addAccountToGroup(id, updates.groupId, 'openai')
      }
    }

    // å‡†å¤‡æ›´æ–°æ•°æ®
    const updateData = { ...updates }

    // å¤„ç†æ•æ„Ÿæ•°æ®åŠ å¯†
    if (updates.openaiOauth) {
      updateData.openaiOauth = updates.openaiOauth
      if (updates.openaiOauth.idToken) {
        updateData.idToken = updates.openaiOauth.idToken
      }
      if (updates.openaiOauth.accessToken) {
        updateData.accessToken = updates.openaiOauth.accessToken
      }
      if (updates.openaiOauth.refreshToken) {
        updateData.refreshToken = updates.openaiOauth.refreshToken
      }
      if (updates.openaiOauth.expires_in) {
        updateData.expiresAt = new Date(
          Date.now() + updates.openaiOauth.expires_in * 1000
        ).toISOString()
      }
    }

    // æ›´æ–°è´¦æˆ·ä¿¡æ¯
    if (updates.accountInfo) {
      updateData.accountId = updates.accountInfo.accountId || currentAccount.accountId
      updateData.chatgptUserId = updates.accountInfo.chatgptUserId || currentAccount.chatgptUserId
      updateData.organizationId =
        updates.accountInfo.organizationId || currentAccount.organizationId
      updateData.organizationRole =
        updates.accountInfo.organizationRole || currentAccount.organizationRole
      updateData.organizationTitle =
        updates.accountInfo.organizationTitle || currentAccount.organizationTitle
      updateData.planType = updates.accountInfo.planType || currentAccount.planType
      updateData.email = updates.accountInfo.email || currentAccount.email
      updateData.emailVerified =
        updates.accountInfo.emailVerified !== undefined
          ? updates.accountInfo.emailVerified
          : currentAccount.emailVerified
    }

    const updatedAccount = await openaiAccountService.updateAccount(id, updateData)

    logger.success(`ğŸ“ Admin updated OpenAI account: ${id}`)
    return res.json({ success: true, data: updatedAccount })
  } catch (error) {
    logger.error('âŒ Failed to update OpenAI account:', error)
    return res.status(500).json({ error: 'Failed to update account', message: error.message })
  }
})

// åˆ é™¤ OpenAI è´¦æˆ·
router.delete('/openai-accounts/:id', authenticateAdmin, async (req, res) => {
  try {
    const { id } = req.params

    const account = await openaiAccountService.getAccount(id)
    if (!account) {
      return res.status(404).json({
        success: false,
        message: 'è´¦æˆ·ä¸å­˜åœ¨'
      })
    }

    // å¦‚æœè´¦æˆ·åœ¨åˆ†ç»„ä¸­ï¼Œä»åˆ†ç»„ä¸­ç§»é™¤
    if (account.accountType === 'group') {
      const group = await accountGroupService.getAccountGroup(id)
      if (group) {
        await accountGroupService.removeAccountFromGroup(id, group.id)
      }
    }

    await openaiAccountService.deleteAccount(id)

    logger.success(`âœ… åˆ é™¤ OpenAI è´¦æˆ·æˆåŠŸ: ${account.name} (ID: ${id})`)

    return res.json({
      success: true,
      message: 'è´¦æˆ·åˆ é™¤æˆåŠŸ'
    })
  } catch (error) {
    logger.error('åˆ é™¤ OpenAI è´¦æˆ·å¤±è´¥:', error)
    return res.status(500).json({
      success: false,
      message: 'åˆ é™¤è´¦æˆ·å¤±è´¥',
      error: error.message
    })
  }
})

// åˆ‡æ¢ OpenAI è´¦æˆ·çŠ¶æ€
router.put('/openai-accounts/:id/toggle', authenticateAdmin, async (req, res) => {
  try {
    const { id } = req.params

    const account = await redis.getOpenAiAccount(id)
    if (!account) {
      return res.status(404).json({
        success: false,
        message: 'è´¦æˆ·ä¸å­˜åœ¨'
      })
    }

    // åˆ‡æ¢å¯ç”¨çŠ¶æ€
    account.enabled = !account.enabled
    account.updatedAt = new Date().toISOString()

    // TODO: æ›´æ–°æ–¹æ³•
    // await redis.updateOpenAiAccount(id, account)

    logger.success(
      `âœ… ${account.enabled ? 'å¯ç”¨' : 'ç¦ç”¨'} OpenAI è´¦æˆ·: ${account.name} (ID: ${id})`
    )

    return res.json({
      success: true,
      data: account
    })
  } catch (error) {
    logger.error('åˆ‡æ¢ OpenAI è´¦æˆ·çŠ¶æ€å¤±è´¥:', error)
    return res.status(500).json({
      success: false,
      message: 'åˆ‡æ¢è´¦æˆ·çŠ¶æ€å¤±è´¥',
      error: error.message
    })
  }
})

// åˆ‡æ¢ OpenAI è´¦æˆ·è°ƒåº¦çŠ¶æ€
router.put(
  '/openai-accounts/:accountId/toggle-schedulable',
  authenticateAdmin,
  async (req, res) => {
    try {
      const { accountId } = req.params

      const result = await openaiAccountService.toggleSchedulable(accountId)

      // å¦‚æœè´¦å·è¢«ç¦ç”¨ï¼Œå‘é€webhooké€šçŸ¥
      if (!result.schedulable) {
        // è·å–è´¦å·ä¿¡æ¯
        const account = await redis.getOpenAiAccount(accountId)
        if (account) {
          await webhookNotifier.sendAccountAnomalyNotification({
            accountId: account.id,
            accountName: account.name || 'OpenAI Account',
            platform: 'openai',
            status: 'disabled',
            errorCode: 'OPENAI_MANUALLY_DISABLED',
            reason: 'è´¦å·å·²è¢«ç®¡ç†å‘˜æ‰‹åŠ¨ç¦ç”¨è°ƒåº¦',
            timestamp: new Date().toISOString()
          })
        }
      }

      return res.json({
        success: result.success,
        schedulable: result.schedulable,
        message: result.schedulable ? 'å·²å¯ç”¨è°ƒåº¦' : 'å·²ç¦ç”¨è°ƒåº¦'
      })
    } catch (error) {
      logger.error('åˆ‡æ¢ OpenAI è´¦æˆ·è°ƒåº¦çŠ¶æ€å¤±è´¥:', error)
      return res.status(500).json({
        success: false,
        message: 'åˆ‡æ¢è°ƒåº¦çŠ¶æ€å¤±è´¥',
        error: error.message
      })
    }
  }
)

// ğŸŒ Azure OpenAI è´¦æˆ·ç®¡ç†

// è·å–æ‰€æœ‰ Azure OpenAI è´¦æˆ·
router.get('/azure-openai-accounts', authenticateAdmin, async (req, res) => {
  try {
    const accounts = await azureOpenaiAccountService.getAllAccounts()
    res.json({
      success: true,
      data: accounts
    })
  } catch (error) {
    logger.error('Failed to fetch Azure OpenAI accounts:', error)
    res.status(500).json({
      success: false,
      message: 'Failed to fetch accounts',
      error: error.message
    })
  }
})

// åˆ›å»º Azure OpenAI è´¦æˆ·
router.post('/azure-openai-accounts', authenticateAdmin, async (req, res) => {
  try {
    const {
      name,
      description,
      accountType,
      azureEndpoint,
      apiVersion,
      deploymentName,
      apiKey,
      supportedModels,
      proxy,
      groupId,
      priority,
      isActive,
      schedulable
    } = req.body

    // éªŒè¯å¿…å¡«å­—æ®µ
    if (!name) {
      return res.status(400).json({
        success: false,
        message: 'Account name is required'
      })
    }

    if (!azureEndpoint) {
      return res.status(400).json({
        success: false,
        message: 'Azure endpoint is required'
      })
    }

    if (!apiKey) {
      return res.status(400).json({
        success: false,
        message: 'API key is required'
      })
    }

    if (!deploymentName) {
      return res.status(400).json({
        success: false,
        message: 'Deployment name is required'
      })
    }

    // éªŒè¯ Azure endpoint æ ¼å¼
    if (!azureEndpoint.match(/^https:\/\/[\w-]+\.openai\.azure\.com$/)) {
      return res.status(400).json({
        success: false,
        message:
          'Invalid Azure OpenAI endpoint format. Expected: https://your-resource.openai.azure.com'
      })
    }

    // æµ‹è¯•è¿æ¥
    try {
      const testUrl = `${azureEndpoint}/openai/deployments/${deploymentName}?api-version=${apiVersion || '2024-02-01'}`
      await axios.get(testUrl, {
        headers: {
          'api-key': apiKey
        },
        timeout: 5000
      })
    } catch (testError) {
      if (testError.response?.status === 404) {
        logger.warn('Azure OpenAI deployment not found, but continuing with account creation')
      } else if (testError.response?.status === 401) {
        return res.status(400).json({
          success: false,
          message: 'Invalid API key or unauthorized access'
        })
      }
    }

    const account = await azureOpenaiAccountService.createAccount({
      name,
      description,
      accountType: accountType || 'shared',
      azureEndpoint,
      apiVersion: apiVersion || '2024-02-01',
      deploymentName,
      apiKey,
      supportedModels,
      proxy,
      groupId,
      priority: priority || 50,
      isActive: isActive !== false,
      schedulable: schedulable !== false
    })

    res.json({
      success: true,
      data: account,
      message: 'Azure OpenAI account created successfully'
    })
  } catch (error) {
    logger.error('Failed to create Azure OpenAI account:', error)
    res.status(500).json({
      success: false,
      message: 'Failed to create account',
      error: error.message
    })
  }
})

// æ›´æ–° Azure OpenAI è´¦æˆ·
router.put('/azure-openai-accounts/:id', authenticateAdmin, async (req, res) => {
  try {
    const { id } = req.params
    const updates = req.body

    const account = await azureOpenaiAccountService.updateAccount(id, updates)

    res.json({
      success: true,
      data: account,
      message: 'Azure OpenAI account updated successfully'
    })
  } catch (error) {
    logger.error('Failed to update Azure OpenAI account:', error)
    res.status(500).json({
      success: false,
      message: 'Failed to update account',
      error: error.message
    })
  }
})

// åˆ é™¤ Azure OpenAI è´¦æˆ·
router.delete('/azure-openai-accounts/:id', authenticateAdmin, async (req, res) => {
  try {
    const { id } = req.params

    await azureOpenaiAccountService.deleteAccount(id)

    res.json({
      success: true,
      message: 'Azure OpenAI account deleted successfully'
    })
  } catch (error) {
    logger.error('Failed to delete Azure OpenAI account:', error)
    res.status(500).json({
      success: false,
      message: 'Failed to delete account',
      error: error.message
    })
  }
})

// åˆ‡æ¢ Azure OpenAI è´¦æˆ·çŠ¶æ€
router.put('/azure-openai-accounts/:id/toggle', authenticateAdmin, async (req, res) => {
  try {
    const { id } = req.params

    const account = await azureOpenaiAccountService.getAccount(id)
    if (!account) {
      return res.status(404).json({
        success: false,
        message: 'Account not found'
      })
    }

    const newStatus = account.isActive === 'true' ? 'false' : 'true'
    await azureOpenaiAccountService.updateAccount(id, { isActive: newStatus })

    res.json({
      success: true,
      message: `Account ${newStatus === 'true' ? 'activated' : 'deactivated'} successfully`,
      isActive: newStatus === 'true'
    })
  } catch (error) {
    logger.error('Failed to toggle Azure OpenAI account status:', error)
    res.status(500).json({
      success: false,
      message: 'Failed to toggle account status',
      error: error.message
    })
  }
})

// åˆ‡æ¢ Azure OpenAI è´¦æˆ·è°ƒåº¦çŠ¶æ€
router.put(
  '/azure-openai-accounts/:accountId/toggle-schedulable',
  authenticateAdmin,
  async (req, res) => {
    try {
      const { accountId } = req.params

      const result = await azureOpenaiAccountService.toggleSchedulable(accountId)

      // å¦‚æœè´¦å·è¢«ç¦ç”¨ï¼Œå‘é€webhooké€šçŸ¥
      if (!result.schedulable) {
        // è·å–è´¦å·ä¿¡æ¯
        const account = await azureOpenaiAccountService.getAccount(accountId)
        if (account) {
          await webhookNotifier.sendAccountAnomalyNotification({
            accountId: account.id,
            accountName: account.name || 'Azure OpenAI Account',
            platform: 'azure-openai',
            status: 'disabled',
            errorCode: 'AZURE_OPENAI_MANUALLY_DISABLED',
            reason: 'è´¦å·å·²è¢«ç®¡ç†å‘˜æ‰‹åŠ¨ç¦ç”¨è°ƒåº¦',
            timestamp: new Date().toISOString()
          })
        }
      }

      return res.json({
        success: true,
        schedulable: result.schedulable,
        message: result.schedulable ? 'å·²å¯ç”¨è°ƒåº¦' : 'å·²ç¦ç”¨è°ƒåº¦'
      })
    } catch (error) {
      logger.error('åˆ‡æ¢ Azure OpenAI è´¦æˆ·è°ƒåº¦çŠ¶æ€å¤±è´¥:', error)
      return res.status(500).json({
        success: false,
        message: 'åˆ‡æ¢è°ƒåº¦çŠ¶æ€å¤±è´¥',
        error: error.message
      })
    }
  }
)

// å¥åº·æ£€æŸ¥å•ä¸ª Azure OpenAI è´¦æˆ·
router.post('/azure-openai-accounts/:id/health-check', authenticateAdmin, async (req, res) => {
  try {
    const { id } = req.params
    const healthResult = await azureOpenaiAccountService.healthCheckAccount(id)

    res.json({
      success: true,
      data: healthResult
    })
  } catch (error) {
    logger.error('Failed to perform health check:', error)
    res.status(500).json({
      success: false,
      message: 'Failed to perform health check',
      error: error.message
    })
  }
})

// æ‰¹é‡å¥åº·æ£€æŸ¥æ‰€æœ‰ Azure OpenAI è´¦æˆ·
router.post('/azure-openai-accounts/health-check-all', authenticateAdmin, async (req, res) => {
  try {
    const healthResults = await azureOpenaiAccountService.performHealthChecks()

    res.json({
      success: true,
      data: healthResults
    })
  } catch (error) {
    logger.error('Failed to perform batch health check:', error)
    res.status(500).json({
      success: false,
      message: 'Failed to perform batch health check',
      error: error.message
    })
  }
})

// è¿ç§» API Keys ä»¥æ”¯æŒ Azure OpenAI
router.post('/migrate-api-keys-azure', authenticateAdmin, async (req, res) => {
  try {
    const migratedCount = await azureOpenaiAccountService.migrateApiKeysForAzureSupport()

    res.json({
      success: true,
      message: `Successfully migrated ${migratedCount} API keys for Azure OpenAI support`
    })
  } catch (error) {
    logger.error('Failed to migrate API keys:', error)
    res.status(500).json({
      success: false,
      message: 'Failed to migrate API keys',
      error: error.message
    })
  }
})

module.exports = router
