#!/usr/bin/env node

/**
 * æ•°æ®å¯¼å‡º/å¯¼å…¥å·¥å…·
 *
 * ä½¿ç”¨æ–¹æ³•ï¼š
 * å¯¼å‡º: node scripts/data-transfer.js export --output=backup.json [options]
 * å¯¼å…¥: node scripts/data-transfer.js import --input=backup.json [options]
 *
 * é€‰é¡¹ï¼š
 * --types: è¦å¯¼å‡º/å¯¼å…¥çš„æ•°æ®ç±»å‹ï¼ˆapikeys,accounts,admins,allï¼‰
 * --sanitize: å¯¼å‡ºæ—¶è„±æ•æ•æ„Ÿæ•°æ®
 * --force: å¯¼å…¥æ—¶å¼ºåˆ¶è¦†ç›–å·²å­˜åœ¨çš„æ•°æ®
 * --skip-conflicts: å¯¼å…¥æ—¶è·³è¿‡å†²çªçš„æ•°æ®
 */

const fs = require('fs').promises
const redis = require('../src/models/redis')
const logger = require('../src/utils/logger')
const readline = require('readline')

// è§£æå‘½ä»¤è¡Œå‚æ•°
const args = process.argv.slice(2)
const command = args[0]
const params = {}

args.slice(1).forEach((arg) => {
  const [key, value] = arg.split('=')
  params[key.replace('--', '')] = value || true
})

// åˆ›å»º readline æ¥å£
const rl = readline.createInterface({
  input: process.stdin,
  output: process.stdout
})

async function askConfirmation(question) {
  return new Promise((resolve) => {
    rl.question(`${question} (yes/no): `, (answer) => {
      resolve(answer.toLowerCase() === 'yes' || answer.toLowerCase() === 'y')
    })
  })
}

// æ•°æ®è„±æ•å‡½æ•°
function sanitizeData(data, type) {
  const sanitized = { ...data }

  switch (type) {
    case 'apikey':
      // éšè— API Key çš„å¤§éƒ¨åˆ†å†…å®¹
      if (sanitized.apiKey) {
        sanitized.apiKey = `${sanitized.apiKey.substring(0, 10)}...[REDACTED]`
      }
      break

    case 'claude_account':
    case 'gemini_account':
      // éšè— OAuth tokens
      if (sanitized.accessToken) {
        sanitized.accessToken = '[REDACTED]'
      }
      if (sanitized.refreshToken) {
        sanitized.refreshToken = '[REDACTED]'
      }
      if (sanitized.claudeAiOauth) {
        sanitized.claudeAiOauth = '[REDACTED]'
      }
      // éšè—ä»£ç†å¯†ç 
      if (sanitized.proxyPassword) {
        sanitized.proxyPassword = '[REDACTED]'
      }
      break

    case 'admin':
      // éšè—ç®¡ç†å‘˜å¯†ç 
      if (sanitized.password) {
        sanitized.password = '[REDACTED]'
      }
      break
  }

  return sanitized
}

// å¯¼å‡ºæ•°æ®
async function exportData() {
  try {
    const outputFile = params.output || `backup-${new Date().toISOString().split('T')[0]}.json`
    const types = params.types ? params.types.split(',') : ['all']
    const shouldSanitize = params.sanitize === true

    logger.info('ğŸ”„ Starting data export...')
    logger.info(`ğŸ“ Output file: ${outputFile}`)
    logger.info(`ğŸ“‹ Data types: ${types.join(', ')}`)
    logger.info(`ğŸ”’ Sanitize sensitive data: ${shouldSanitize ? 'YES' : 'NO'}`)

    // è¿æ¥ Redis
    await redis.connect()
    logger.success('âœ… Connected to Redis')

    const exportDataObj = {
      metadata: {
        version: '1.0',
        exportDate: new Date().toISOString(),
        sanitized: shouldSanitize,
        types
      },
      data: {}
    }

    // å¯¼å‡º API Keys
    if (types.includes('all') || types.includes('apikeys')) {
      logger.info('ğŸ“¤ Exporting API Keys...')
      const keys = await redis.client.keys('apikey:*')
      const apiKeys = []

      for (const key of keys) {
        if (key === 'apikey:hash_map') {
          continue
        }

        // ä½¿ç”¨ hgetall è€Œä¸æ˜¯ getï¼Œå› ä¸ºæ•°æ®å­˜å‚¨åœ¨å“ˆå¸Œè¡¨ä¸­
        const data = await redis.client.hgetall(key)

        if (data && Object.keys(data).length > 0) {
          apiKeys.push(shouldSanitize ? sanitizeData(data, 'apikey') : data)
        }
      }

      exportDataObj.data.apiKeys = apiKeys
      logger.success(`âœ… Exported ${apiKeys.length} API Keys`)
    }

    // å¯¼å‡º Claude è´¦æˆ·
    if (types.includes('all') || types.includes('accounts')) {
      logger.info('ğŸ“¤ Exporting Claude accounts...')
      // æ³¨æ„ï¼šClaude è´¦æˆ·ä½¿ç”¨ claude:account: å‰ç¼€ï¼Œä¸æ˜¯ claude_account:
      const keys = await redis.client.keys('claude:account:*')
      logger.info(`Found ${keys.length} Claude account keys in Redis`)
      const accounts = []

      for (const key of keys) {
        // ä½¿ç”¨ hgetall è€Œä¸æ˜¯ getï¼Œå› ä¸ºæ•°æ®å­˜å‚¨åœ¨å“ˆå¸Œè¡¨ä¸­
        const data = await redis.client.hgetall(key)

        if (data && Object.keys(data).length > 0) {
          // è§£æ JSON å­—æ®µï¼ˆå¦‚æœå­˜åœ¨ï¼‰
          if (data.claudeAiOauth) {
            try {
              data.claudeAiOauth = JSON.parse(data.claudeAiOauth)
            } catch (e) {
              // ä¿æŒåŸæ ·
            }
          }
          accounts.push(shouldSanitize ? sanitizeData(data, 'claude_account') : data)
        }
      }

      exportDataObj.data.claudeAccounts = accounts
      logger.success(`âœ… Exported ${accounts.length} Claude accounts`)

      // å¯¼å‡º Gemini è´¦æˆ·
      logger.info('ğŸ“¤ Exporting Gemini accounts...')
      const geminiKeys = await redis.client.keys('gemini_account:*')
      logger.info(`Found ${geminiKeys.length} Gemini account keys in Redis`)
      const geminiAccounts = []

      for (const key of geminiKeys) {
        // ä½¿ç”¨ hgetall è€Œä¸æ˜¯ getï¼Œå› ä¸ºæ•°æ®å­˜å‚¨åœ¨å“ˆå¸Œè¡¨ä¸­
        const data = await redis.client.hgetall(key)

        if (data && Object.keys(data).length > 0) {
          geminiAccounts.push(shouldSanitize ? sanitizeData(data, 'gemini_account') : data)
        }
      }

      exportDataObj.data.geminiAccounts = geminiAccounts
      logger.success(`âœ… Exported ${geminiAccounts.length} Gemini accounts`)
    }

    // å¯¼å‡ºç®¡ç†å‘˜
    if (types.includes('all') || types.includes('admins')) {
      logger.info('ğŸ“¤ Exporting admins...')
      const keys = await redis.client.keys('admin:*')
      const admins = []

      for (const key of keys) {
        if (key.includes('admin_username:')) {
          continue
        }

        // ä½¿ç”¨ hgetall è€Œä¸æ˜¯ getï¼Œå› ä¸ºæ•°æ®å­˜å‚¨åœ¨å“ˆå¸Œè¡¨ä¸­
        const data = await redis.client.hgetall(key)

        if (data && Object.keys(data).length > 0) {
          admins.push(shouldSanitize ? sanitizeData(data, 'admin') : data)
        }
      }

      exportDataObj.data.admins = admins
      logger.success(`âœ… Exported ${admins.length} admins`)
    }

    // å†™å…¥æ–‡ä»¶
    await fs.writeFile(outputFile, JSON.stringify(exportData, null, 2))

    // æ˜¾ç¤ºå¯¼å‡ºæ‘˜è¦
    console.log(`\n${'='.repeat(60)}`)
    console.log('âœ… Export Complete!')
    console.log('='.repeat(60))
    console.log(`Output file: ${outputFile}`)
    console.log(`File size: ${(await fs.stat(outputFile)).size} bytes`)

    if (exportDataObj.data.apiKeys) {
      console.log(`API Keys: ${exportDataObj.data.apiKeys.length}`)
    }
    if (exportDataObj.data.claudeAccounts) {
      console.log(`Claude Accounts: ${exportDataObj.data.claudeAccounts.length}`)
    }
    if (exportDataObj.data.geminiAccounts) {
      console.log(`Gemini Accounts: ${exportDataObj.data.geminiAccounts.length}`)
    }
    if (exportDataObj.data.admins) {
      console.log(`Admins: ${exportDataObj.data.admins.length}`)
    }
    console.log('='.repeat(60))

    if (shouldSanitize) {
      logger.warn('âš ï¸  Sensitive data has been sanitized in this export.')
    }
  } catch (error) {
    logger.error('ğŸ’¥ Export failed:', error)
    process.exit(1)
  } finally {
    await redis.disconnect()
    rl.close()
  }
}

// å¯¼å…¥æ•°æ®
async function importData() {
  try {
    const inputFile = params.input
    if (!inputFile) {
      logger.error('âŒ Please specify input file with --input=filename.json')
      process.exit(1)
    }

    const forceOverwrite = params.force === true
    const skipConflicts = params['skip-conflicts'] === true

    logger.info('ğŸ”„ Starting data import...')
    logger.info(`ğŸ“ Input file: ${inputFile}`)
    logger.info(
      `âš¡ Mode: ${forceOverwrite ? 'FORCE OVERWRITE' : skipConflicts ? 'SKIP CONFLICTS' : 'ASK ON CONFLICT'}`
    )

    // è¯»å–æ–‡ä»¶
    const fileContent = await fs.readFile(inputFile, 'utf8')
    const importDataObj = JSON.parse(fileContent)

    // éªŒè¯æ–‡ä»¶æ ¼å¼
    if (!importDataObj.metadata || !importDataObj.data) {
      logger.error('âŒ Invalid backup file format')
      process.exit(1)
    }

    logger.info(`ğŸ“… Backup date: ${importDataObj.metadata.exportDate}`)
    logger.info(`ğŸ”’ Sanitized: ${importDataObj.metadata.sanitized ? 'YES' : 'NO'}`)

    if (importDataObj.metadata.sanitized) {
      logger.warn('âš ï¸  This backup contains sanitized data. Sensitive fields will be missing!')
      const proceed = await askConfirmation('Continue with sanitized data?')
      if (!proceed) {
        logger.info('âŒ Import cancelled')
        return
      }
    }

    // æ˜¾ç¤ºå¯¼å…¥æ‘˜è¦
    console.log(`\n${'='.repeat(60)}`)
    console.log('ğŸ“‹ Import Summary:')
    console.log('='.repeat(60))
    if (importDataObj.data.apiKeys) {
      console.log(`API Keys to import: ${importDataObj.data.apiKeys.length}`)
    }
    if (importDataObj.data.claudeAccounts) {
      console.log(`Claude Accounts to import: ${importDataObj.data.claudeAccounts.length}`)
    }
    if (importDataObj.data.geminiAccounts) {
      console.log(`Gemini Accounts to import: ${importDataObj.data.geminiAccounts.length}`)
    }
    if (importDataObj.data.admins) {
      console.log(`Admins to import: ${importDataObj.data.admins.length}`)
    }
    console.log(`${'='.repeat(60)}\n`)

    // ç¡®è®¤å¯¼å…¥
    const confirmed = await askConfirmation('âš ï¸  Proceed with import?')
    if (!confirmed) {
      logger.info('âŒ Import cancelled')
      return
    }

    // è¿æ¥ Redis
    await redis.connect()
    logger.success('âœ… Connected to Redis')

    const stats = {
      imported: 0,
      skipped: 0,
      errors: 0
    }

    // å¯¼å…¥ API Keys
    if (importDataObj.data.apiKeys) {
      logger.info('\nğŸ“¥ Importing API Keys...')
      for (const apiKey of importDataObj.data.apiKeys) {
        try {
          const exists = await redis.client.exists(`apikey:${apiKey.id}`)

          if (exists && !forceOverwrite) {
            if (skipConflicts) {
              logger.warn(`â­ï¸  Skipped existing API Key: ${apiKey.name} (${apiKey.id})`)
              stats.skipped++
              continue
            } else {
              const overwrite = await askConfirmation(
                `API Key "${apiKey.name}" (${apiKey.id}) exists. Overwrite?`
              )
              if (!overwrite) {
                stats.skipped++
                continue
              }
            }
          }

          // ä½¿ç”¨ hset å­˜å‚¨åˆ°å“ˆå¸Œè¡¨
          const pipeline = redis.client.pipeline()
          for (const [field, value] of Object.entries(apiKey)) {
            pipeline.hset(`apikey:${apiKey.id}`, field, value)
          }
          await pipeline.exec()

          // æ›´æ–°å“ˆå¸Œæ˜ å°„
          if (apiKey.apiKey && !importDataObj.metadata.sanitized) {
            await redis.client.hset('apikey:hash_map', apiKey.apiKey, apiKey.id)
          }

          logger.success(`âœ… Imported API Key: ${apiKey.name} (${apiKey.id})`)
          stats.imported++
        } catch (error) {
          logger.error(`âŒ Failed to import API Key ${apiKey.id}:`, error.message)
          stats.errors++
        }
      }
    }

    // å¯¼å…¥ Claude è´¦æˆ·
    if (importDataObj.data.claudeAccounts) {
      logger.info('\nğŸ“¥ Importing Claude accounts...')
      for (const account of importDataObj.data.claudeAccounts) {
        try {
          const exists = await redis.client.exists(`claude_account:${account.id}`)

          if (exists && !forceOverwrite) {
            if (skipConflicts) {
              logger.warn(`â­ï¸  Skipped existing Claude account: ${account.name} (${account.id})`)
              stats.skipped++
              continue
            } else {
              const overwrite = await askConfirmation(
                `Claude account "${account.name}" (${account.id}) exists. Overwrite?`
              )
              if (!overwrite) {
                stats.skipped++
                continue
              }
            }
          }

          // ä½¿ç”¨ hset å­˜å‚¨åˆ°å“ˆå¸Œè¡¨
          const pipeline = redis.client.pipeline()
          for (const [field, value] of Object.entries(account)) {
            // å¦‚æœæ˜¯å¯¹è±¡ï¼Œéœ€è¦åºåˆ—åŒ–
            if (field === 'claudeAiOauth' && typeof value === 'object') {
              pipeline.hset(`claude_account:${account.id}`, field, JSON.stringify(value))
            } else {
              pipeline.hset(`claude_account:${account.id}`, field, value)
            }
          }
          await pipeline.exec()
          logger.success(`âœ… Imported Claude account: ${account.name} (${account.id})`)
          stats.imported++
        } catch (error) {
          logger.error(`âŒ Failed to import Claude account ${account.id}:`, error.message)
          stats.errors++
        }
      }
    }

    // å¯¼å…¥ Gemini è´¦æˆ·
    if (importDataObj.data.geminiAccounts) {
      logger.info('\nğŸ“¥ Importing Gemini accounts...')
      for (const account of importDataObj.data.geminiAccounts) {
        try {
          const exists = await redis.client.exists(`gemini_account:${account.id}`)

          if (exists && !forceOverwrite) {
            if (skipConflicts) {
              logger.warn(`â­ï¸  Skipped existing Gemini account: ${account.name} (${account.id})`)
              stats.skipped++
              continue
            } else {
              const overwrite = await askConfirmation(
                `Gemini account "${account.name}" (${account.id}) exists. Overwrite?`
              )
              if (!overwrite) {
                stats.skipped++
                continue
              }
            }
          }

          // ä½¿ç”¨ hset å­˜å‚¨åˆ°å“ˆå¸Œè¡¨
          const pipeline = redis.client.pipeline()
          for (const [field, value] of Object.entries(account)) {
            pipeline.hset(`gemini_account:${account.id}`, field, value)
          }
          await pipeline.exec()
          logger.success(`âœ… Imported Gemini account: ${account.name} (${account.id})`)
          stats.imported++
        } catch (error) {
          logger.error(`âŒ Failed to import Gemini account ${account.id}:`, error.message)
          stats.errors++
        }
      }
    }

    // æ˜¾ç¤ºå¯¼å…¥ç»“æœ
    console.log(`\n${'='.repeat(60)}`)
    console.log('âœ… Import Complete!')
    console.log('='.repeat(60))
    console.log(`Successfully imported: ${stats.imported}`)
    console.log(`Skipped: ${stats.skipped}`)
    console.log(`Errors: ${stats.errors}`)
    console.log('='.repeat(60))
  } catch (error) {
    logger.error('ğŸ’¥ Import failed:', error)
    process.exit(1)
  } finally {
    await redis.disconnect()
    rl.close()
  }
}

// æ˜¾ç¤ºå¸®åŠ©ä¿¡æ¯
function showHelp() {
  console.log(`
Data Transfer Tool for Claude Relay Service

This tool allows you to export and import data between environments.

Usage:
  node scripts/data-transfer.js <command> [options]

Commands:
  export    Export data from Redis to a JSON file
  import    Import data from a JSON file to Redis

Export Options:
  --output=FILE        Output filename (default: backup-YYYY-MM-DD.json)
  --types=TYPE,...     Data types to export: apikeys,accounts,admins,all (default: all)
  --sanitize           Remove sensitive data from export

Import Options:
  --input=FILE         Input filename (required)
  --force              Overwrite existing data without asking
  --skip-conflicts     Skip conflicting data without asking

Examples:
  # Export all data
  node scripts/data-transfer.js export

  # Export only API keys with sanitized data
  node scripts/data-transfer.js export --types=apikeys --sanitize

  # Import data, skip conflicts
  node scripts/data-transfer.js import --input=backup.json --skip-conflicts

  # Export specific data types
  node scripts/data-transfer.js export --types=apikeys,accounts --output=prod-data.json
`)
}

// ä¸»å‡½æ•°
async function main() {
  if (!command || command === '--help' || command === 'help') {
    showHelp()
    process.exit(0)
  }

  switch (command) {
    case 'export':
      await exportData()
      break

    case 'import':
      await importData()
      break

    default:
      logger.error(`âŒ Unknown command: ${command}`)
      showHelp()
      process.exit(1)
  }
}

// è¿è¡Œ
main().catch((error) => {
  logger.error('ğŸ’¥ Unexpected error:', error)
  process.exit(1)
})
